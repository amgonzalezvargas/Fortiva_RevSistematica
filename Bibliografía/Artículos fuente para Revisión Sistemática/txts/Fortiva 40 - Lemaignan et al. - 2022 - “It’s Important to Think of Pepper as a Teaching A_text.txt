International Journal of Social Robotics https://doi.org/10.1007/s12369-022-00928-4 ® Check for updates “It’s Important to Think of Pepper as a Teaching Aid or Resource External to the Classroom”: A Social Robot in a School for Autistic Children Séverin Lemaignan'@ - Nigel Newbutt?“ - Louis Rice? - Joe Daly! Accepted: 8 September 2022 © The Author(s) 2022 Abstract For a period of 3 weeks in June 2021, we embedded a social robot (Softbank Pepper) in a Special Educational Needs (SEN) school for autistic children. The robot’s behaviours and integration into the school were co-designed with the children and teachers, with a focus on improving the well-being of the pupils. Using a mix-method approach, we studied the robot’s adoption over the course of the study, and the impact of the robot’s presence on the children well-being and the school ecosystem. We found that the robot successfully integrated within the school; it fostered and maintained a steady level of interactions (330 interactions, 16 h of continuous use over 3 weeks) with a small yet meaningful group of children with a positive impact on their well-being; and it led to a nuanced conversation with the students and school staff about the role and impact of such a social technology in a SEN school. Keywords Social robotics - Responsible AI - Autism - Child—robot interaction - Participatory design - Well-being 1 Introduction 1.1 Well-Being in SEN Schools and Interdisciplinary Research Autism is a lifelong neurodevelopmental condition that affects how a person perceives, communicates and interacts with the world. This is characterised by significant and lasting differences (compared to typical development) in social com- ><] Louis Rice louis.rice @uwe.ac.uk Séverin Lemaignan severin.lemaignan @ pal-robotics.com Nigel Newbutt nigel. newbutt @coe.ufl.edu Joe Daly joe.daly @ brl.ac.uk ' Bristol Robotics Lab, University of the West of England, Bristol, UK PAL Robotics, Barcelona, Spain 3 University of the West of England, Bristol, UK Institute of Advanced Learning Technologies, University of Florida, Gainesville, USA Published online: 31 October 2022 munications and interaction, restricted and repetitive patterns of behaviour, interests or activities and sensory perception and responses [1]. Current data suggest that as many as | in 54 children in the United States of America are on the autism spectrum [2] while other studies suggest a figure of between 1 in 68 to | in 100 in the general population [3]. The well-being and emotional regulation of autistic peo- ple has been central in supporting meaningful educational experiences [4]. In comparison to their typically-developing peers, autistic children experience greater mental health problems, such as anxiety, depression, anger, and possess lower self-concept and these can impact education and other factors [5]. There have been a range of studies that have implemented technology to assist autistic children in this regard [6-8]. However, these studies have often focused on deficit-based models and do not often include users in their design. Other strategies have also been used to support the well-being of autistic pupils. For example, recent work has highlighted that focusing on autistic intense or ‘special’ interests in the classroom may be linked to improved well- being [9]. While the well-being of autistic groups is not well understood or defined, increasing awareness of its impact on students’ academic performance and their adult outcomes is well acknowledged [10]. With greater attention applied to the well-being of autistic pupils, improvements in areas of D Springer education and adulthood are often observed [11]. Therefore, considering well-being from an early age and in a setting where this can be supported (i.e. education) represents an important are of enquiry. This project was established to approach issues in this field that can lack interdisciplinary perspectives and can be limited by siloed working [12]. As a result, to investigate the potential of a social robot in a school setting for autistic children, we built a team consisting of education, robotics and architecture. Thus bringing key interdisciplinary expertise together to explore the role of social robots in a UK-based SEN school which hosts about 145 autistic children. A note on terminology. The authors take very seriously the use terminology in this field as it relates to person first and/or identity first language and framing. We acknowledge that this can sometimes represent a contentious issue. In this article, we choose to use ‘autistic children’ instead of ‘children with autism‘. The authors consulted, and sought input from, an autistic researcher who helped to guide us in our adoption and use of language. Our position draws as well on the work of [13,14], and as such we we adopt language that that is currently considered inclusive (i.e. ‘autistic’ and in places, ‘autism’ ). 2 Related Literature and Derived Hypotheses Our project is an interdisciplinary investigation of the follow- ing overarching aim: How can a social robot integrate into the ecosystem of a special educational needs (SEN) school, and effectively support the development and well-being of the children, in complement to the day-to-day work of the school staff? Extensive prior art related to social robots in the school environment can be found [15]; we focus our analy- sis of literature to research looking specifically at (1) robots for/with autistic children; (2) the impact of (social) robots on the school ecosystem. 2.1 Robots and Autistic Children Research in the field of child—robot interaction has already shown that, compared to other technologies, the use of robots can bring unique opportunities for autistic children (and neu- rotypical populations), including having a powerful impact on their behaviour and development [16,17]. This is under- stood to come from the embodied nature of robots [18—20] in addition to the unique characteristics that robotic tech- nology has for autistic populations; for example, simplified interactions, safe, predictable and reliable behaviours [21]. Previous research on robotics and autism has predomi- nately focused on using robots to support the acquisition of social skills (like joint attention or mutual gazing) [e.g. 22— Q) Springer International Journal of Social Robotics 26]. In these previous studies, the robot interaction design is typically a top-down process: experts (typically SEN teachers or autism specialists) suggest age- and development- appropriate activities, implemented on the robots by engi- neers, and deployed in schools. Our focus was instead on understanding, from the children themselves, their ambitions for using a social robot in their school, without preconcep- tions or bias towards designing a robot to specifically ‘teach’ social skills. Despite the potential of social robots in classrooms, research on robots in special educational needs (SEN) set- tings has highlighted several on-going challenges that can generate barriers to successful adoption. For example, [27] found that the main reasons why special needs schools do not normally use robots in their classrooms include (1) price or availability; (2) difficulty of use; (3) the limited range of activities offered; (4) limited interactions on offer; and (5) the inability to use different robots with the same software. They note that these findings are further compounded by a lack of “involving end users in the design and development of new systems [...] using a user-centred design approach for all the components, including methods of interaction, learn- ing activities and the most suitable type of robots” (p. 59). As such, the lack of user-centred design (at the very least, including school children in deciding the types of interaction they might want or enjoy via a robot in their school) means that uptake, deployment and successful integration is difficult to achieve. Note that, while the co-design process is a key aspect of this project and is critical to understand our design choices, it is not the main focus of this article. While we briefly outline our approach to participatory design in Sect. 3.1, this arti- cle primarily concerns itself with the setup and outcomes of the main three-weeks study, and its eventual impact on the childrens’ well-being. A detailed account of our co-design methodology is provided in [28]. In addition to the barriers to uptake, an increasing body of research has started exploring the possible emerging risks and ethical considerations that could arise and thus should be addressed in the design process of robotic interventions for autistic children [29]. Specifically in this work, we have adopted the ethical framework set out in the UNICEF report on artificial intelligence and children Policy guidance on AI for children (30]. This report lays out nine guidelines that should be considered when designing and building AI sys- tems aimed at children. We discuss in greater details how we applied each of these guidelines to research on social robotics with vulnerable children in [31]. 2.2 Impact of Social Robots on School Ecosystems Robots have now been deployed and studied in the school environment for a significant period of time, initially as International Journal of Social Robotics non-social tools that support (predominantly STEM) teach- ing [32], and more recently, as social agents embedded in the classroom environment [15]. While non-social robots were already reported to “play a positive role’, “develop creative thinking”, “increase motiva- tion, engagement and attitude towards learning” [32], the role and impact of social robots in education is specifically inves- tigated by Belpaeme et al. in their 2018 survey [15]. They identify two main roles for social robots in educational set- tings (tutors and peer learners), and show that, when focused on arestricted set of well-defined tasks, studies in child—robot interactions for education typically find learning outcomes similar to what is achieved by humans. In their conclusions, they acknowledge the open challenges linked to the need for beyond-state-of-art “fluent and contingent” interactions with the children; but they also underline the potential for social robots to “deliver a learning experience tailored to the learner, supporting and challenging students in ways unavail- able in current resource-limited educational environments” while freeing up time for teachers to focus on what they do best: “providing a comprehensive, empathic, and rewarding educational experience’. Specifically looking at long-term deployments in schools [33], pioneering work by Kanda [34,35], who deployed in 2004 and 2007 their Robovie robot in Japanese primary schools for two months each, evidenced the difficulty of sustaining the children’ interest and engagement beyond the first two weeks. Similar difficulties were encountered in much more recent studies like [36] (with a steep decrease of engagement after the first three weeks). A five-months deployment of a small humanoid robot in a toddler environ- ment by Tanaka et al. [37] did however evidence long-term engagement of children with the robot, albeit through teleop- erated toy-like interactions (touching, dancing) with limited social richness. The researchers highlighted that robots can sustain attention of children and found that after 45 days of immersion in a childcare center over a 5-month period, long- term bonding and socialization occurred between toddlers and a social robot. In addition, they also found that “rather than losing interest, the interaction between children and the robot improved over time [and] children exhibited a vari- ety of social and care-taking behaviors toward the robot and progressively treated it more as a peer than as a toy”. To date, however, the research on social robot in educa- tion primarily focuses on explicit, tailored learning sessions with robots, with less spotlight on the broader impact of the robot’s presence on the school ecosystem at large. We aim to investigate this gap (in the specific context of a special needs school). Similiar to Mondada et al.’s approach to looking at the impact of robots on the home ecosystem [38], our research focuses on the impact of a social robot on the school ecosys- tem, a dynamic fabric comprised of students, teachers, other member of staff, parents, as well as the physical environ- ment of the school. As such, this work feeds into the recent efforts by Charisi et al. [39] to frame the ethical principles that should guide the design of child—robot interactions in the future. Importantly, most prior research focuses on one-to-one interactions [15] and neglects the social dimension of learn- ing which happen during unstructured groups activities, for instance during the recess or in corridors (Vygotskian social constructivism)—with few noteworthy exceptions like the research on group interactions conducted with the KeepOn robot [22] or the research conducted by Bjérling and col- leagues on participatory design of robots with teens [40]. Following this line of work, our social robot is consequently located in the school corridors, and it interacts autonomously with the children in a non-planned, mostly unstructured way, rather than pre-arranged, in-classroom interactions. This leads to a diversity of interaction patterns, ranging from large groups (6+ children together) who purposefully decide to ‘visit’ the robot and interact for 10-15 min at a time, to short, one-to-one impromptu interactions with a child on their way to e.g. the toilets. To date, only limited literature explores the impact of such a range of types of interaction with a social robot on the dynamics of a school ecosystem; our research provides here some initial insights. 2.3 Aim and Research Questions Based on this prior art, and the identified limitations, we set out to specifically answer two questions: (1) What are the social & spatial underpinnings of a successful integration of a social robot in a SEN school ecosystem? (in contrast to controlled one-to-one child—robot interventions) (2) Can a social robot deliver a net gain for the well-being of pupils? (in contrast to the traditional focus on quantitative improve- ment of select cognitive metrics). In particular, to what extent a thorough co-design process supports this goal? The two research questions themselves were guided and informed by a participatory co-design methodology that focused on gathering autistic children’s views and perspec- tives of what a social robot might do in their school [28]. We also ensured teachers’ perspectives were included, helping to support the integration of a social robot into their school ecosystem. The co-design approach allowed us to identify the potential roles and behavioural characteristics for the social robot in addition to understanding which locations within the school were preferable. The key, and therein innovations of this work, lie in this participatory co-design methodology as the social robot was entirely designed and developed based by working in collaboration with autistic children and their teachers; this included what the robot should do, where and the types of interactions. Q) Springer Hypotheses From our research questions, we derive two hypotheses that drive our investigation: H1: A co-design approach (with chil- dren and teachers) supports the creation of a robot that successfully integrates into a school ecosystem; H2: The co- design process leads to the robot having a positive impact on the well-being of the children. While our work is indeed driven by these hypotheses, we also acknowledge that the level of generality that would be required to firmly support or reject either of these can not be reached with a single study. We explicitly discuss this limita- tion in the Methodology section (Sect. 3.1). We nevertheless aim to test these hypotheses along several dimensions of the integration and adoption of the robot within the school. For H1, we assess: (a) to what extent the co-design process influenced the inter- action design, including the choice of activities and the physical location of the robot; (b) whether the robot successfully integrates into the school ecosystem, by recording the robot’s usage patterns over a meaningful period of time (3 weeks); (c) whether the robot maintains a sustained level of inter- actions once the initial novelty fades, with a meaningful group of children. This can be measured from the quan- titative recordings of daily interactions; (d) whether the pupils perceive and interact with the robot as a social agent, and not merely as a ‘tablet on wheels’. This is analysed using both quantitative data based on in- situ observations, and qualitative data from the children’s and teachers’ questionnaires; For H2 (about the impact on well-being), we look into: (a) quantitative pre-/post-mood self-reports by the children, recorded everytime they interact with the robot; (b) behavioural data logs of student emotional well-being compiled by the school; (c) the reported acceptance of robot in the school by the teachers and pupils, from the questionnaire data; (d) qualitative feedback from teachers and pupils. In particu- lar, the feedback on the impact of the robot on particular children provided by the school staff reveal important insights. 3 Methodology and Material 3.1 Methodology Overview We follow a mixed-method experimental protocol, with a primary focus on building qualitative insights on the design D Springer International Journal of Social Robotics Stage 1 Pre-study meetings Ethical approval sought and received Meeting with school leadership team Research team visit to the school Planning focus groups and wider study Stage 2 Focus group with pupils Testing Pepper in school Evaluating pupil feedback Dp Focus group with school staff Testing Pepper in staff room Evaluating staff feedback Stage 3 Interface design (iterative) Testing in Lab Testing in school with users Further interface design / testing Feedback from autistic adult/mentor Stage 4 Deployment in school Evaluation in-situ Automated data collection (number of interactions with Pepper, types of interactions, etc..) Observation of Pepper being used in the school Feedback from pupils and teachers Fig.1 Our complete research process and journey. Stages | to 3 are the co-design phases, and are presented in detail in [28]. The present paper focuses on Stage 4 and the outcomes of the in-school study and adoption of a social robot in a special education needs school. As such, we do not make strong claim on how general- isable our results are. Instead, we aim at forming an in-depth understanding of the social and technical underpinnings of a robot-supported intervention on the well-being of autistic children. Our methodology has two main phases (Fig. 1): (1) the iterative and participatory design of the robot behaviours and context of use; (2) a three-weeks in-situ deployment of the final robot in the school, and the observations of its use and impact on the complex and dynamic context of the school. The research methods employed during the first phase comprise of: (1) a half-day workshop at the school, with two focus groups with the target population, as well as unstruc- tured interactions with other pupils; (2) a one-day workshop among the research team, with an external invited academic, expert in child—robot interactions and responsible AI. This workshop was focused on mind-mapping the outcomes of the children focus groups (Fig. 2); (3) a two hour focus group with the school’s teachers, where the results of the children’s focus group were discussed and built upon; (4) a half-day workshop with an autistic academic, to better account for the autistic community perspective on this line of research and accordingly refine the project framing and interaction design. The detailed methodology and findings of our co-design pro- cess are detailed and presented elsewhere in [28]. As previously discussed, one of the key outcomes of this first co-design phase is the focus and framing of our research on the well-being of autistic pupils in their school, rather than robot-supported cognitive development. As a result, we have International Journal of Social Robotics | tle, | | tle, | rock paper _ scissor hi everyone! | z= [choose BR shall we do? activity] a activities only how do you Feel OTHER ACTIVITES MOOD FEEDBACK (not implemented) ~ | apa hoppy —_ | _ tired now? YY (show __ ll angry | aoa tbe ee _—— knowledge a eq; tell me —_ — Fie | cricket rules —— | don't re seek | (c) 2021 University of the West of England robots4sen project (N Newbutt, L Rice, S Lemaignan) Fig. 2 Muind-map of the robot’s behaviours based on the results of the focus groups designed an experimental protocol that allows for loosely structured interactions: no scheduled interaction time slots, robot located ina common space, and available to any passing children, eliciting both one-to-one and group interactions. In addition, the robot is designed to be autonomous (no ‘wizard- of-Oz’ or teleoperation), with interactions that are however always led by the children (i.e. the robot is mainly reacting to the children’s interactions). The second phase consists in a 3-week-long robot deploy- ment in the school. No dedicated interaction time was scheduled for the pupils, as we wanted to see whether and how robot usage patterns would emerge from within the school ecosystem. As such, the robot was used and observed in a naturalistic context. We argue that this indeed helped formed a better understanding of the actual impact of the robot on a school dynamics compared to e.g. structured and scheduled face-to-face child—robot interactions. The robot was positioned in a part of the school where only the secondary pupils could engage. This meant that the pupils in this study were aged between 12 and 16 and all pupils had a formal autism diagnosis. The methods used during this phase comprise of obser- vations made by the researcher, while observing the robot from a distance, children’s self-reported mood before and after interacting with the robot, quantitative measurements of the interactions as experienced by the robot (robot’s logs), post-hoc questionnaires administered to the children, and additional feedback provided by the teachers, school staff, and parents, both qualitative (unstructured interviews, unprompted feedback) and quantitative (behavioural inci- dents reports). Details of each of the measures are provided hereafter, in Sect. 3.3.2. Before starting this study and working with the pupils and teachers, we gained ethical approval from the Univer- sity of the West of England ethical board, under reference ACE.20.10.014. This was granted before any interactions or data collection started. As part of the ethical review pro- cess we carefully (and completely) considered, and designed protocols, to ensure the safety of the pupils, both physical and emotional/psychological. We worked in collaboration with the school leadership team to ensure that we located our practices around those in the school. All pupils and their parents/carers provided their consent. Teachers also provided their consent before engaging in data collection. 3.2 Robot Capabilities and Interactions We used a Softbank Pepper humanoid robot (pictured in Fig. 4). Pepper is a 1.2 m-tall anthropomorphic robot, designed to be safe and approachable [41]. While the robot is mobile, its displacements were mostly limited to turning in place (to face or visually follow children), and the robot remained otherwise in its initial location (see Sect. 3.3.1). The robot’s arms were used for lexical gestures (1.e. ges- ture to support and accompany the verbal interactions), for choreographed dance sequences, as well as, in one partic- ular activity, for physical interaction (hugging). No object manipulation or deictic gestures were performed. The robot is also equipped with a tablet, used by the chil- dren to initiate an interaction, and answer the robot’s prompts (see below). Q) Springer > (a) Mood selection screen, modelled after the school’s own colour-coding scheme. ‘he screen is only presented during one-to-one interaction, first before the first activity, and then after the last one. i 0 (b) Activity selection screen. In practice, only 2 or 3 were randomly offered at a time. The presentation order is always randomised. Fig.3 Screenshots of the Pepper’s tablet interface 3.2.1 Interaction Design Choice of interaction modalities We decided early on in the design process to avoid speech recognition, as it is notoriously difficult to achieve robust child speech recognition on a robot like Pepper, especially in a lively school environment with group interactions [42]. In addition, some of the children are non-verbal. However, an entirely non-verbal robot would have signif- icantly limited the range of possible activities. After the first focus group, where it was found that the robot’s voice was easy to understand for the children, we eventually decided to use an hybrid approach, with the robot talking to the chil- dren, and the children responding by clicking on large icons displayed on Pepper’s tablet (Fig. 3). Foster the ascription of social agency to the robot and to avoid it being only used as an (expensive) ‘tablet on wheels’, Q) Springer International Journal of Social Robotics we ensured that: (1) the tablet would be used exclusively to answer the robot’s prompts (e.g. no tablet-focused activities like tablet-based games); (2) the icons would be displayed synchronously with the robot voice, encouraging the chil- dren to pay attention to what the robot would say, instead of ‘skipping’ the robot by clicking an icon before the robot has finished speaking; (3) the activities were partially ran- domised: only a maximum of 2 or 3 random (yet related to the child’s mood) activities would be offered at a given time; the presentation order was random; the content of the activ- ities themselves was partially random (e.g. random jokes), thus always generating slightly different situations. While these simple strategies would not be sufficient for the child to ascribe complex mental state to the robot (like ‘the robot likes that activity better’ or ‘the robot does not want me to play that game’), they would avoid the system to be perceived as fully static and predictable, supporting the ascription of agency, and shifting the view of the robot by the children from a design stance to an intentional stance [43]. Robot Autonomy and Children—Led Interactions In order to keep the children in control of the interaction (and thus fully maintain their agency), we decided to let the children (1) initiate the interactions themselves (following the UNICEF recommandations); (2) let them choose what they wish to do with the robot. However, to ensure the robot is not perceived as an entirely passive system controlled by the children, the robot does automatically start addressing the child/children as soon as they are detected to be engaging (with prompts like “Hi! Good to see you’ or ‘Nice to see you! How are you?’).! Engagement detection was not performed automatically by the robot. We initially implemented an automatic engage- ment state machine that worked robustly in lab conditions. The system however proved unreliable when deployed (due to the number of children, and how dynamic they were). Accordingly, starting on Day 2 of the study, the number of children interacting with the robot at any given time was manually entered by the researcher observing the inter- action, providing us with a much more reliable detection of engagement, including group engagement (see details below). Apart from the detection of how many children were interacting with the robot at a given time, the robot was fully autonomous. Structure of the Interaction Once detected as engaging, the robot greets the child (or group of children). If the child is alone, their initial ‘mood’ is recorded by showing on the tablet a mood selection screen (Fig. 3a). The child can also skip that step by pressing the ' The full list of prompts used in the study can be found here: https:// bit.ly/3DiwxZN. International Journal of Social Robotics blue arrow in the bottom-right corner. If a group of children are detected, the ‘mood’ selection screen 1s skipped entirely. The child (or group of children) is then presented with a list of possible activities, whose presentation order is randomised (as explained above). The children also have the possibility to see more activities if the 2 or 3 randomly chosen activities do not satisfy them. The child taps on the desired activity, which then starts. Activities last between 30 s and 3 min. At the end of each activity, the robot asks the child if they want to continue. If yes, they are taken back to the activ- ity selection screen. Otherwise, the mood selection screen is displayed to record their emotional state at the end of the interaction. 3.2.2 Activities Based on the outcomes of the co-design process, we imple- mented a set of eight activities on the robot (visible on Fig. 3b): e Calm dance atai-shi inspired dance accompanied by calm music; e Calm music arandom calm music out of five atmospheric tunes, lasting between 1’ 30” and 2’ 45”; e Relaxing sound: a randomly chosen continuous calm sound (sea side, birds, rain, cricket chirping, village) plays until stopped by the child or until the end of the sound file; e Cuddle the robot slowly hugs the child by opening its arm, and closing them in a loose hug for a few seconds. The arms are configured with a low stiffness; e Listening (labelled as ‘Chat’ in Fig. 3b) in this activity, the robot prompts the child to speak (for instance: “What do you want to tell me? I’m listening!”’), and then simply wait for the child to stop the interaction by pressing the tablet. The robot does not attempt to process the child’s speech or to respond; e Story the story activity is adapted with authorisation from the Lunii* interactive story telling system. A total of 48 stories can be generated, by asking the child who should be the hero of the story (a boy or a girl), where the story takes place, who does the hero meet, and one special object. The decision tree and generated stories come from the Lunii system, while the voice is generated by the robot, using naoqi’s animated speech API. The stories last about 4 min each; e Fun dance a more energetic dance, randomly chosen from the ‘macarena’, a ‘disco’ dance, and a ‘saxophone player’ dance; e Jokes the robot tells two or three jokes randomly picked from a list of 50 primary-school-age jokes. The jokes * https://lunii.com/en- gb/my-fabulous-storyteller/. Fig.4 Photo of the physical location of the robot, here depicted while interacting with one child. In the foreground, the researcher observ- ing the interaction, and recording on the tablet how many children are engaged, as well as observations on the interaction are non-interactive, the robot simply pausing before the joke’s resolution. 3.3 Study Protocol and Measures 3.3.1 Setup Figures 4 and 5 show the general setup of the study. The robot was placed in a communal area and was available to interact with from 8:30 (15 min before the normal start of the school day) until 15:15 G.e. end of school day) each day, with the exception of about 30 min at approximately 12:30 when the researcher would have a break and the robot would be put on charge in a room inaccessible to pupils. As previously discussed, no dedicated interaction time was scheduled for the pupils, as we wanted to see whether and how robot usage patterns would emerge from within the school ecosystem. 3.3.2 Measures We laid out in Sect. 2.3 how we intend to test our hypotheses. Accordingly, this section presents all the required quantita- tive and qualitative measures that we recorded during the study. In-Situ Measures Three main types of in-situ measures are recorded during the study: quantitative interaction measures (number of children engaged with the robot at a given time; log of the performed activities), children’s self-reported mood and feelings, and qualitative observations by the researchers. D) Springer sd ta garden (nat used) Wipes e. are researcher a @ ee pupils’ lockers a classroom classroom Fig. 5 Physical setup of the study at the Mendip school. The robot is placed in the middle of the Secondary corridor, in a 4 mx4 m space. Pupils pass-by the robot, and are free to interact with the robot at any time. The researcher is sitting nearby, observing the interactions from outside the main interaction zone Quantitative Interaction Measures Our main quantitative interaction measures consist in detailed log of the interactions with the robot: every time a child (or group of children) starts an interaction, the exact activities and time spend on each of them is logged (anonymously, as our protocol did not allow for the tracking of individual pupils). While we attempted to use Pepper’s human detection features to automatically track behavioural data (people’s distance to the robot, trajectories, gaze direction), the poor reliability of this data (as explained in the previous section on automatic engagement detection) led to excluding it from our analysis. Children’s Self-reported Mood The children were invited by the robot to self-report their mood and feels before and after interacting, through a screen displayed on the robot’s tablet, and pictured on Fig. 3a. The four, colour-coded cate- gories of feelings were suggested during the teachers’ focus group to match the emotion self-reporting charts already used in the school, and familiar to the pupils. It must be noted that these four categories do not strictly follow traditional valence/arousal emotional scales, the ‘yel- low’ mood including for instance constructs with both positive (Excited) and negative (Frustrated) valence. Qualitative Observations The researcher’s tablet also featured buttons to quickly record different categories of timestamped audio notes (children’s questions, unexpected events, general observations). A total of about 280 notes were recorded over the 13 days of the study (M = 21.8 per day). Notes were transcribed verbatim, and coded using thematic analysis. From this the following categories emerged: 1. observations relating to a child’s Mood modulation/ reflection while interacting with the robot; D Springer International Journal of Social Robotics 2. Unstructured, playful interaction with or around the robot; 3. observation evidencing Social ascriptions onto the robot (e.g. treating the robot as a social agent); 4. Group interactions (with other students and/or staff); 5. ‘Hidden’ interactions (e.g. watching the robot from a distance that would not trigger the robot’s interactive behaviours); 6. notes of General comments about the robot (e.g. things they liked/disliked about Pepper, interpretations of the robot’s behaviour); 7. observations of Sensory interactions (e.g. holding Pep- per’s hand, moving Pepper, stroking Pepper’s head, hugs); 8. Questions asked by the children about the robot; and finally 9. Meta-observation about the study, including events impacting the data collection (e.g. media days, test- ing/demonstrating things, robot errors, unresponsive interface). Where appropriate, notes would be coded with multiple categories (e.g. two children reflecting on their mood with the robot would be coded as categories | and 4). Questionnaires Post-hoc questionnaires were administered to the children by the researchers to assess three main constructs: Perception of the robot, Role ascription and Reasons for interaction. The construct Perception of the robot was measured using 5-points Likert scales (adapted for use with the chil- dren, using sad to happy emojis, based on consultation with teachers to ensure the children could articulate to suit their communication needs). The 8 questions were adapted from [44]: (1) How much do you like robots in general (not just Pepper)?; (2) How much do you like our Pepper?; (3) Do you want Pepper to stay longer at school?; (4) Do you think Pepper was useful to you?; (5) Do you think Pepper is useful for the school?; (6) I think Pepper is... very boring to very entertaining; (7) I think Pepper is... very mean to very friendly; (8) Do you think Pepper could become your friend ?. Role ascription was measured similarly to [45]: after the prompt Interacting with Pepper is like..., children could circle as many answers as wished amongst Playing with a friend, Playing with a teacher, Playing with a toy, Playing with a pet. They were also free to write down additional answers. The assessment of the children’s Reasons for interaction is based on a behavioural scheme employed by the school to analyse the motives of observed children behaviours. In col- laboration with the school, we designed questions to assess the four families of behaviours: Sensory behaviours (e.g.“I liked touching Pepper’, “I liked holding Pepper’s hands”, “I liked listening to Pepper”); Escape behaviours (e.g.““I went International Journal of Social Robotics to see Pepper because my work was hard”, “I went to see Pep- per because the teacher asked me to do something I didn’t want to”, “When I am bored, I like to play with Pepper’); Attention behaviours (e.g.“I knew Pepper would play with me, listen to me’, “I knew my teacher / teaching assistant would come and get me if I was with Pepper’, “I knew my friends would play with me if Pepper was with me’’); Tangi- ble behaviours (e.g.“If I completed my work, I could spend time with Pepper’, “If I completed my work, I could spend time with Pepper and my friends’). Children were asked to circle sentences they agreed with, amongst 21 ‘speech bubbles’ (see Fig. 6). We purposefully used speech bubbles, uttered by a genderless child emoji: by asking the children to simply agree with a neutral, third-party character’s statements, instead of themselves verbalising (as thus, owning) their own statements, we mitigate the norma- tive pressure that could have otherwise biased some of the answers. In addition to administering questionnaires to the chil- dren, we also captured post-hoc views of the school staff. We sent out questionnaires to all the teachers and staff who had the chance to interact with Pepper and who had pupils in the secondary corridor who were part of the study. The questionnaire was distributed the week after the study ended and all questionnaires were returned within 3 days. The ques- tionnaires were designed to better understand the views and perspectives of the teachers with a total of 12, mostly open- ended questions. This included for instance their views on: “the impact of Pepper on their pupils, either at an indi- vidual level or on a group level”; if they “interacted with Pepper?’; whether or not “they observed any impact on the school itself? (e.g. positive and/or negative impact on the school routines or on the children’ routines)’; “If it were possible, would you like for Pepper to stay in your school?”; “Would you change anything about Pepper?’’; “Would you say that Pepper has had an impact on your teaching prac- tice or routine? If so, how did you use or integrate Pepper in your teaching and why’?”’; and “Would you recommend other colleagues/schools to use a robot like Pepper?”’. 4 Results We present hereafter our main results, in the order intro- duced in the Hypothesis testing (Sect. 2.3) and Measures (Sect. 3.3.2) sections. 4.1 In-Situ Quantitative Measures 4.1.1 Robot Usage The study lasted 13 days school days. The first day involved initial robot setup and introduction, and therefore behavioural data recorded during that day was discarded. Therefore, results reported hereafter only cover the following 12 days. Figure 7 shows the total daily time the robot interacts with children. While the robot is actively used more than 100 min a day in the first few days, it quickly diminishes to between 40 min and 60 min a day. This interaction profile was expected and corresponds to the typical novelty effect generated by the robot when first introduced in the school. After Day 7, the interaction time appears to stabilise to about 45-50 min of interaction per day, e.g. between 10 and 20% of the time spent in the school with the robot in the corridor. In terms of number of interactions, children interacted M = 25.4, stddev = 8.5 times a day over the whole 13 days, M = 30.7, stddev = 7.6 during the first 7 days, and M = 19.2, stddev = 4.2 during the last 6 days. Based on this data, we consider to be past novelty starting on Day 8, and consequently our subsequent analyses and discussion about the actual impact of the robot on the school ecosystem are based on the data collected over the last 6 days of the intervention only. Figure 8 provides insights on the group dynamics. The novelty effect phase (until Day 8) is an initial exploration phase, and we observe that the children mostly interacted | knew my friends would play with me if Pepper was with me 1| Ate holding < eoper s hand f | completed my wor © 3 Icould spend tirne with Pepper and my friends ~~ \ \ , Il went to see ‘4 Pepper because my work was hard Fig.6 Examples of post-hoc questions asked to the children. Children were ask to circle the speech bubbles they agreed with. Question | is an example of Sensory behaviour motive; Q2 of Attention behaviour; Q3 of Tangible behaviour; Q4 of Escape behaviour Duration (min) c c c i= Cc c c c c c Cc Cc — J =] = P= ] =) s P=] J a a J J PJ = = = = = = = = = = = = = w © ~ «© a N m + wo o o a4 N os — + a N N N N N N mo o o Fig.7 Daily interaction duration (in min) and percentage of interaction time vs total robot presence time. After Day 7 (23 June), the percentage of interaction time stabilises between 10% and 20% of the total time at school D) Springer # children mz 1 mum 2 mm 3 mm 4+ Duration (min) 3 8 & \ er ot oF ®t Xr Ot op™ ow Fig.8 Daily interaction time, split by children groups size: interactions are mostly one-to-one, especially after the novelty period # children Ww a= N we (e) 09:00 10:00 11:00 12:00 13:00 14:00 15:00 Time of the day Fig.9 Number of children interacting with the robot over 10min-long periods, averaged over the full study. Shaded area represents the 95% confidence interval # of runs % @ Rx > uw Re on © e SS - e@ Fig. 10 Distribution of daily activities performed with the robot, after the novelty period. Activities calm dances, calm music and relaxing sounds are grouped under calm activities with the robot in groups. This dynamic changes in the second half of the study, where most of the interaction are one-to-one or, less often, two-to-one. Finally, Fig. 9 shows the average number of children inter- acting with the robot over a day, when split into 10 min periods. 4.1.2 Activities Figure 10 shows the activities performed with the robot after the initial 7-day novelty phase. During that period, an average of M = 46.3 (std=19.2) activities were performed per day (compared to M = 59.3 (std=9.0) during the novelty phase). Over half of these activities were fun dances, while the other activities were performed a similar number of times each, about 5 times per day. Q) Springer International Journal of Social Robotics ——><—, a... oo COT: — — before interacting SuNOvIOUL JOR Fig. 11 Sankey diagram representing changes of self-reported mood before and after interacting with the robot. The scale of each mood state reflects the proportion of answers entered by the children 4.2 Children Self-reported Mood and Feelings At the start and end of their interactions with the robot, the children were asked to self-report their mood on a ‘mood board’ (Fig. 3a). This was only recorded for one-to-one inter- actions (we did not record the mood of a group), and the children could skip it if they wished (in order to reduce ran- dom responses if the children were not sure or did not want to report their feelings). We recorded 105 interactions (out of a total of 325) where a child reported both pre- and post-interaction mood, enabling in-the-moment assessment of their change of mood. Fig- ure 11 represents these changes of mood before and after interacting with the robot. In 14 of these interactions (13.3% of interactions with self- report), the child’s mood improved over the interaction, to be ‘Happy’ (green color) at the end. In a meaningful amount of cases, however, (9 interactions, 8.6%), children self-reported as being ‘happy’ at the start of the interaction, but ‘angry’ at the end. Qualitative observations (reported in next section) showed that these situations were usually due to the robot malfunctioning or can be attributed to one student who would select the angry response, but verbally confirmed without prompting to the on-site researcher that this was an accident. 4.3 Qualitative In-Situ Observations As explained in Sect. 3.3.2, one researcher was observing and annotating the interactions during the whole study. 283 notes were recorded over the 13 days of the study, coded following the methodology presented in Sect. 3.3.2. International Journal of Social Robotics The complete list of transcribed and coded notes is avail- able online: https://bit.ly/3nVUX5y. Table | summarizes the distribution. In this section, notes relating to the hypotheses will be prioritised. In particular this section notes how the robot was used by pupils and staff (H1b, c, the extent to which the robot was perceived as a social entity (H1d), and the impact of the robot on pupils’ well-being (H2). 4.3.1 Mood Modulation/Reflection There were several observations of children using the robot as a means to reflect or modulate their mood. One pupil, Student L, often interacted with the robot in an initially agitated state and would specifically select calming sounds or music. There were instances where pupils selected an emotion that did not match their actual state. For example Stu- dent M choosing angry because he liked the way the robot responded, but verbally confirming to the researcher that he felt happy. Another instance was Student L choosing yellow to express excitement, but the robot responded negatively e.g. “Oh you’re not feeling so good?’”. Student L then ver- bally responded “no no delete I’m excited again’. In another instance pupils “approached the robot [and one of them] clicked happy on the mood board despite being very clearly angry and stating explicitly that he was feeling angry. There was another student at the same time who responded [...] on behalf of the first student as angry at the final emotion check... These cases suggest that even when the robot’s response is not reflective of the children’s actual mood, they are still taking time to reflect on their, and sometimes other’s, emotions because of the robot’s presence. For some children, Pepper’s presence offered a way to discuss and express their thoughts without having to interact with a person. There was an occasion where a child went to the robot and talked to it about his feelings. A member of staff watching from a distance remarked that this pupil would not normally talk about his emotions to staff. In a similar instance, a child approached the robot and said “I’m actually getting a little bit angry” while interacting with the mood board he selected just listen and when a second child approached he said “go away I’m having private chat with pepper’. On other occasions a member of staff prompted a child to talk to Pepper, and he then “told Pepper about his day and it was never a great day then proceeded with couple of other activities but left the interaction seemingly a lot calmer than he initially started it.” 4.3.2 Unstructured, Playful Other children tended to interact with the robot in a more playful manner, and treated it as a source of entertainment. The majority of these interactions involved the ‘fun dance’ activity which was the most popular of the activities (see Fig. 10). Notall playful interactions with the robot directly involved the programmed activities. For example, a group of girls interacted with the robot then “decorated it with a rubber snake to make it look like Pepper had hair.’”’ Similarly another student began “play boxing with Pepper, but specifically behind it in effort so as not to engage with the robot”. On another occasion children in a group were trying to “encour- age others to join in and daring each other to hug the robot.” 4.3.3 Social Ascriptions The social status of the robot varied. Some students would regularly interact with Pepper and say “hello” and “good- bye” much like any other social interaction. Some would ask Pepper “how are you?”’. Some students ascribed proto mental states to Pepper, for example saying “she likes me” if the robot looked towards them. There was a conversation between staff and older pupils concerning these greetings, with the observation that “they don’t say goodbye to Alexa and that is different to not saying goodbye to Pepper’. In this instance there was a clear dis- tinction between the social presence of Pepper compared to other technologies. For pupils, the robot was only partially regarded as a social entity as seen in the above examples with pupils disclosing to Pepper, but not to other people. This could have been because Pepper did not respond or judge, though this is open to inter- pretation. For other pupils, the robot afforded no social status what- soever, Pepper may as well not have existed for all the attention they gave it. 4.3.4 Group Interactions Many of the interactions with Pepper were as part of a group (see Fig. 8 where pupils were accompanied by either a mem- ber of staff or their peers. Most of the interactions with staff occurred early on in the study, as staff familiarised themselves and their students with the robot. The larger groups were observed in the first half of the study. The largest of these groups were when a class came to visit the robot. The teacher accompanying the class had “changed plan do a walk and see the robot” and commented that “the class had calmed far quicker than other methods... it was good to have something else for them to focus on”. In smaller groups of two or three the robot often acted as a focal point for the children’s interactions with each other. D Springer Table 1 Summary of the in-situ ; ; Construct # observations, after coding oo Mood modulation 22 Unstructured, playful 1] Social ascriptions 26 Group interactions 61 ‘Hidden’ interactions 23 General comments 39 Sensory Interactions 18 Questions 60 Meta-observations 63 International Journal of Social Robotics Examples “So about that last interaction that was Student X one of our regulars once again he says that the answering angry on the last thing wasn’t accident” “The girls were there interacting with the robot just before also decorated it with a rubber snake to make it look like pepper had hair” “Still getting people saying “Hi Pepper’ just in passing without necessarily engaging with the way thought or standing long enough to be a full engagement” “Last interaction was loosely guided; lots of commu- nication between staff and students about the story being told” “Penultimate interaction of the day was group inter- action with the girls, there were a few standing around observing while the others interacted with the robot” “Concerns about the future, becoming robots” “When asked about touching the robot’s head, Student F said she liked it a lot” “Explorations of whether the robot can actually see them or not” “Apparently the Duke of Edinburgh trips going on so there’s fewer kids in school today” Observations could be coded in more than one category. Eight observations are unclassified Examples included discussing what activity they wanted to do with the robot. One girl who had initially been unsure of the robot inter- acted with it in the company of friends and by the end of one interaction had become a lot more comfortable with the robot and spontaneously describing Pepper as “cool” and “beau- tiful’. Having the support of peers helped to facilitate her initial interactions with the robot. In one instance the presence of others halted an interaction of one boy “dancing alongside Pepper until a group of older children passed by and he stopped.” 4.3.5 ‘Hidden’ Interactions There were some ‘interactions’ with the robot that did not meet the criteria for triggering the robot’s behaviour. In these cases it was often because pupils were passing by in the corridor and only verbally greeting Pepper. For some pupils this became part of routine every time they passed by. There were also occasions where pupils would watch the robot from a distance, as they were reluctant to directly engage with the robot. 4.3.6 General Comments About the Robot One of the most frequent comments about the robot, partic- ularly at the start of the study, was that Pepper was “creepy”’. This comment was frequently accompanied by exclamations D Springer directed towards the robot asking “why is it looking at me?”’. One pupil “elaborated saying that it was [because] the robot doesn’t blink” that they found the robot creepy. Opinions varied with regards to the quality of some of Pepper’s behaviours. For example, “upon hearing the jokes the teens interacting with it decided the robot wasn’t very good.” In contrast, mere minutes later another “‘young teen, upon hearing the jokes ... declared [the robot] a legend.” Though there were many instances of children having positive interactions, there were some who had strong nega- tive feelings towards Pepper. One pupil avoided the corridor entirely. The other expressed to the on-site researcher how much he disliked the robot and wanted it to be moved on an almost daily basis. This pupil spent more time in the classroom than usual to avoid interacting with the robot. His teacher perceived this positively as the pupil was complet- ing more work than usual. There can be indirectly positive impacts of the robot, but this view is not always shared by the pupils. We further discuss this result in the Discussion section. 4.3.7 Sensory Interactions The physical aspect of the robot also presented opportunities for Sensory interactions with the robot. One pupil would regularly and deliberately place “his head into the robots hands asking for his head massage’. This pupil would also “insist on being very close to pepper and to the point of getting International Journal of Social Robotics Table 2 Descriptive statistics for the eight children questions related to the perception of the robot Mean Stddev Q1 How much do you like robots in 3.73 1.26 general (not just Pepper)? Q2 How much do you like our Pepper? 3.97 1.43 Q3 Do you want Pepper to stay longer at 3.97 1.47 school? Q4 Do you think Pepper was useful to 3.60 1.43 you? Q5 Do you think Pepper is useful for the 4.43 0.97 school? Q6 I think Pepper is... boring/entertaining 3.87 1.53 Q7 I think Pepper is... mean/friendly 4.40 1.25 Q8 Do you think Pepper could become 3.67 1.58 your friend? Scores from | (low) to 5 (high) headbutted repeatedly”. One girl “was initially quite scared I think at the start of the week maybe even earlier today, but by the end of this interaction was kind of spontaneously saying things like ... “[it] is beautiful” and petting the robot on the head saying that [it] likes to be stroked on the head and other things giving it lots of cuddles being generally quite affectionate towards the robot’. 15 Count 5 1 2 3 4 3 1 2 3 4 3 Q1 How much do you like robots in general (not just Pepper)? Q2 How much do you like our Pepper? Count ra o 1 2 3 4 5 1 2 3 4 5 Q6 | think Pepper is... boring/entertaining Q5 Do you think Pepper is useful for the school? One comment from a member of staff noted that a pupil “holding the hand of the robot ... normally they have no phys- ical touch.” 4.3.8 Questions The majority of questions directed at and about Pepper concerned how the robot worked. They frequently centred around how the robot was controlled, and the connection between the robot and the tablet. In these instances the on- site researcher would explain that the tablet ran code that controlled Pepper, and that they (the researcher) were not using the tablet to directly control the robot. 4.4 Questionnaires and Other Post-hoc Measures 4.4.1 Children Questionnaires After removing data from children for which no data sharing consent was obtained, and two incomplete questionnaires, n = 30 questionnaires were collected and analysed. Table 2 and Fig. 12 reports the questionnaire results for the perception of the robot, from 1 (low/negative) to 5 (high/positive). Generally, the robot was perceived positively. We can specifically observe that, compared to their general per- ception of robots, the Pepper robot deployed in the school | 2 3 4 5 1 2 3 4 5 Q3 Do you want Pepper to stay longer at school? Q4 Do you think Pepper was useful to you? 1 2 3 4 5 1 2 3 4 5 Q7 | think Pepper is... mean/friendly Q8 Do you think Pepper could become your friend? Fig. 12 Perception of the robot; responses are on 5-points Likert scales (labelled from not at all to very much except for Q6: very boring to very entertaining and Q7: very mean to very friendly) Q) Springer 12 10 Count oy les) £ NO 2 N e <& Fig. 13 Perception of the robot’s social role. Children could choose multiple options was well liked. It was generally considered entertaining and friendly. While the children were uncertain whether or not the robot could be useful to themselves in particular (18 out of 30 thought that it would, 7 that it would not), they were much more confident that it would be useful to the school in general (27 out of 30 positive opinions). Finally, the students were split regarding whether or not the robot “could become their friend”’, 21 thinking that it may, and 8 thinking that it would not. Figure 13 presents the results of the role ascription ques- tion. While the robot was only seldom perceived as a teacher, it was roughly equally often seen as a peer, a pet or a toy. Table 3 and Fig. 14 presents the results related to the underlying motives of the children. These statements each belong to one of the four behaviours categories identified by the school (presented in Sect. 3.3.2). Because each behaviour does not have the same number of available statements to cir- cle, we normalise the number of responses for each behaviour by the number of statement available for this behaviour. We found that the first reason for children to interact with the robot was a need for a sensory interaction (for instance, holding hands or stroking the robot), followed by a need for attention. The three most-selected statements related to attention were “I knew my teacher/TA would come and get me if I was with Pepper” (selected 8 times), “I go and see Pepper when I want someone to listen to me” (6 times) and “T knew my friends would play with me if Pepper was with me” (6 times). D Springer International Journal of Social Robotics Table 3 Number of children-selected statements explaining their rea- sons for interacting with the robot, grouped by category Motive category Total Normalised Attention 35 5.8 Escape 28 4.0 Sensory 56 9.3 Tangible 11 5.5 (normalised) eS # of selected statements N Fig. 14 Motives leading to interaction 4.4.2 Teacher’s Questionnaires After the study ended we surveyed the teachers, teaching assistants and leaders in the school. Responses were received from teachers (n = 2), teaching assistants (1 = 1), and school leaders (n = 3). The data revealed insights to their views and perspectives. These were mixed, but shed light on what they felt Pepper could offer in their setting, based on 3-week of activity. We first consider the teachers’ feedback. When asked about the impact of Pepper on their pupils, responses included: “Some pupils completely engaged with it [...] some pupils actively didn’t like it being in the corridor” and “Ini- tially my students were very engaged in seeing Pepper”. Asked about the impact of Pepper in the school, they sug- gested that: “The corridor was quieter as certain pupils kept away from it” and “50/50, for some children Pepper caused anxiety and for others joy!”. Leading on this, one of the teachers felt Pepper had an impact on their teaching prac- tice, saying that: “Only a couple of times, seeing Pepper was used as an incentive”. However, they felt that Pepper International Journal of Social Robotics aroused curiosity in some of their pupils and also enjoyed saying “good morning” to Pepper. The only thing the teachers would change about Pepper would have been “more person- alised interaction’. The sole teaching assistant that responded felt that Pep- per was popular, stating: “Some pupils seemed to not want to go to lessons but spend time with pepper’. They also observed/reported some benefits to including technology like Pepper: “Pupils interacting with each other, that would not normally do so”, but also warned of some possible issues: “Some pupils found it scary. The older pupils didn’t want anything to do with it”. Responses from the leaders of the school suggest a range of impacts on the pupils. One said: “I have seen an increased amount of groups working around Pepper, but these are stu- dents who previously would not of interacted with each other. This has been pleasing to see. Individual pupils who are also on a sensory curriculum also appear to have benefited from having a sensory experience from Pepper e.g. holding hands, cuddling, dancing”, while another suggested that: “Individ- uals have been able to use pepper as a calming activity when arriving at school’. Another mentioned they had observed both “positive and negative interactions with Pepper”. In rela- tion to the overall school, they reported that: “[the] secondary corridor has seemed calmer, more positive” with another sug- gesting: “initially the excitement meant some pupils used Pepper as an excuse not to be in class [...] later it [Pepper] was able to be used as a motivator to stay in class and be used at reward time”. When asked about what they would change about Pepper (and what Pepper did), they reported: “refine the activities Pepper offers so they are specific to the emotion, e.g. Angry—breathing exercises, counting to 10, visualisations, Low mood—music, jokes etc...perhaps linked to zones of regulation and the strategies that students use themselves—e.g. personalised to each pupil by visual or voice recognition” and “Potentially the ability to differenti- ate between the feelings within zones”. Asked about the role of technology like Pepper, feedback included: “It’s important to think of Pepper as a teaching aid or resource external to the classroom. It has accessibility where pupils can use it, I still do not believe it is a class room resource” and “Ability to help regulate pupils”. When the Leaders responded to how they personally felt about robots in their school/class, they reported feeling sceptical at first, but “now think there’s lots of potential to develop their ability to support students” and “af refined to link directly to the strategies taught by staff could be a useful tool”. Taken together, and when asked about recommending Pepper (“Would you recommend other colleagues/schools to use a robot like Pepper’?’’), all the respondents reported recommend using Pepper to other colleagues and schools (n = 6). In addition, they all stated that Pepper/social robots could be used in schools, like theirs, to support their pupils. K NO Mm Student L Mm Student | @@m Rest of the group _ Oo oO # of reported incidents fe) ) 2@ i! f Sa = Rn ww S s @ @ s Fig. 15 Behavioural incidents reported by the teachers, on the week they occurred. Students J and L are presented separately as, together, they were responsible for about half of the reported behavioural inci- dents. However the evolution of their behaviour over the study does not significantly deviate from the rest of the group However, one of the School Leaders commented that: “I do believe it is a niche field, that isn’t necessarily something all schools need. However from what I have seen, their use in SEND/ASD is valuable’, also that social robots: “can’t be in isolation it [Pepper] needs to be part of the wider school strategies and supports”. Noticeably, all of the respondents, apart from the Teaching Assistant, reported interacting and spending time with Pepper. They all reported “missing Pep- per” and one of the school leaders reported that: “Our pupils on a sensory curriculum were gaining additional support through an aid we didn’t need to be with. This had immense benefits for them and their school day. From my own teach- ing, on reflection I can say key pupils who struggle in the afternoon were generally calmer if they had seen Pepper at lunch time”. 4.5 Behavioural Data from School Within the school they have mechanisms to report and doc- ument the pupils behaviour. In doing so, behaviours noted in school are written by class teachers or teaching assistants into an online system that is use to track and monitor indi- viduals, classes and cohorts. Behaviours are separated into ‘incidents’ (negative behaviours) and ‘information’ (changes to behaviour support plans to help make positive changes). Data are collected in real-time so the school are able to track and monitor across the school day, peak times etc, as opposed to ‘when a report is written’. During the study and time that Pepper was in the school, data related to incidents were continued to be captured as they would have been any other week(s) described above. Figure 15 shows the ‘incident’ data for two specific children, as well as the whole secondary corridor (so all pupils who Q) Springer were able to engage with Pepper in the secondary part of the school). These results highlight a clear reduction in recorded incidents during the time Pepper was positioned in their cor- ridors. Recorded incidents did increase the week after Pepper left the school and, for one child (L), returned higher than his baseline the week before Pepper arrived. 5 Discussion We next discuss the findings in-line with the original hypothe- ses. The hypotheses were outlined as: e H1 A co-design approach (with children and teachers) supports the creation of a robot that successfully inte- grates into a school ecosystem; e H2 The co-design process leads to the robot having a positive impact on the well-being of the children. Within each hypotheses we gathered a range of data which we discuss next, following the structure outlined in Sect. 2.3. 5.1 H1: Co-design Leads to Successful Integration into School Evidence and data support this hypothesis. We captured data from child—robot interactions based on co-designed interac- tions, the robot usage patterns, sustained level of interactions, in-situ observations, and post-study pupil and teacher ques- tionnaires. 5.1.1 Interaction Design and Location of the Robot As data in Fig. 10 highlight, the pupils engaged success- fully with all the planned/programmed child-robot activities. The Listening activity was perceived as limited, as the robot would never answer. Children, when asking for instance “how are you?” would not get an answer. A chatbot-like interaction should be investigated in future work. Other potential activities were suggested by the teaching staff, including Mackaton (a simplified sign language used by e.g. speech therapists in the school). We had one particular instance where a non-verbal primary-school age child indeed tried to teach the robot the sign for ‘more’, and adding support for using and learning expressive gestures would certainly be an interesting development. The school has a variety of different architectural spaces, from formal classrooms to informal social spaces; the dif- fering characteristics of which affect the emotional states of individuals and play various roles for social relationships. The space within which the social robot occupies is therefore an important factor to consider in the successful deploy- ment of these technologies. In the focus groups, the children D Springer International Journal of Social Robotics expressed a clear preference for the corridor space as a loca- tion. At this particular school, the corridor is primarily used for circulation but is also often a place used for emotional regulation by the children. When the classroom becomes a space in which children are overstimulated, for example angry or frustrated, the children may leave the classroom and use the corridor as a space in which to self-regulate (often to calm down and chill out). The corridor is also a space for informal social interaction outside of the formal classroom settings as children pass by each other between lessons or during breaks. The use of the robot in the corridor contin- ued the existing ‘culture’ of behaviours in this non-formal teaching space. The results stated above reveal that the robot was often used to facilitate children to shift from e.g. an angry zone to a happier mental space. The relative quietude of the corridor also enabled children to reveal their emotions and feelings to the robot (in the absence of fellow humans). Teachers also used the robot in this space to facilitate infor- mal social interactions between children (including children who might otherwise not come into contact during formal classroom activities). There was no attempt by teachers to undertake formal teaching activities in the corridor with the robot. The robot maintained a presence in the school corridor space that a human would not typically undertake for such long durations; this enhanced durational time frame offers future potential for enhancing and enriching a space within the school ecosystem beyond that which is currently afforded by human interactions in the school. 5.1.2 Usage Patterns and Sustained Interactions We also found that the robot was successfully integrated into the school ecosystem through the robot’s usage patterns. By working with the children from the outset, and co-designing what Pepper did, we saw an initial (and expected) interest in Pepper (week | and 2), but also sustained activity across the final week. So, while the interest/activities reduced by nearly half over the first 10 days, as expected from the vanishing novelty effect [46], they did stabilise to a meaningful level of daily interactions (more than 19 unique interactions per day in average, either one-to-one or group interactions). The intra-day usage pattern (Fig. 7) also evidence that the robot was used throughout the day, following the overall structure of the daily school routine (recess, lunch breaks, in-class periods). 5.1.3 Ascription of Agency We also evidenced Pepper being engaged with as a social agent. Evidence from the pupil and teacher questionnaires, directly after the study concluded, suggested that observed behaviours included social ascription’s, group interactions, sensory interactions, and asking questions. So more than International Journal of Social Robotics merely a ‘tablet on wheels’, the robot elicited a range of inter- action types, and ones that facilitated group activities while others involved clear child—robot engagement. The teachers reported their pupils “engaged with Pepper” and “aroused curiosity’. Data from the pupils revealed that they felt Pep- per was a “friend” more than any of the other options (pet, toy, teacher; Fig. 13), once again suggesting that they did not see Pepper as a tablet on wheels. There was a greater connection for some of the pupils than this. Indeed, when looking at the children motives for interaction (Fig. 14), sen- sory interactions are the often cited reason for interaction: The embodied, physical nature of Pepper was valuable and important to these pupils. 5.2 H2: Co-design Leads to Positive Impact on the Well-Being Evidence and data support this hypothesis as well. Data from the post-study data revealed mostly positive insight to Pep- per and the well-being of the pupils. It was certainly the case that not all pupils and teachers were positive, however. Pupils reported either really liking Pepper or disliking Pep- per. Reports from the teachers suggest that “some pupils completely engaged with it [while] some pupils actively didn’t like it being in the corridor” and at least one pupil was observed ‘hiding’ from Pepper by spending more time in the their class and verbally telling the researchers he didn’t want Pepper in the school. By carefully and sensitively work- ing with the pupil and teacher we proceeded with the study; conversely Pepper’s presence meant the pupil engaged with classroom activities with greater attention. However, and despite the mixed opinions, some of our data lead us to con- clude that taken together this hypothesis was supported. 5.2.1 Self-reported Mood Changes The Sankey diagram (Fig. 11) suggests that the reporting of their mood before and after interacting with Pepper either remained happy or transitioned more from frustrated, sad or angry to happy. Although these data are less conclusive to support a claim that Pepper managed their well-being. What the data started to provide us with, however, are insights to the nature of interactions pupils had with Pepper. Data on the specific activities performed with the robot (Fig. 10) revealed that fun dances and calm activities were the most popular activities engaging with Pepper, at least via the inter- face (touch screen). Cuddles were also popular, and taken together indicate that pupils engaged with mostly stimulat- ing and relaxing activities; all these were included due to the outcomes of the co-design sessions with the pupils. 5.2.2 Impact on Behaviour The social behaviour of the children in the corridor was often rowdy, for example play-fighting including grappling and wrestling. At times, children included Pepper in these play fights, for example grabbing Pepper around the neck, shov- ing or grabbing the robot’s arms. Mostly, this was harmless playful behaviour and the robot was not damaged. However, at times, the researcher or a passing teacher had to inter- vene for the safety of the robot (to stop it being damaged) or children (i.e. the robot falling and hurting a child). These behaviours evidently raise issues of health and safety when leaving robots unguarded in such contexts. School children being physically boisterous in certain school spaces would require careful consideration in terms of human supervision and intervention of a robot in future studies. The inclusion of Pepper in their physical play suggests the acceptance of robots by the children as a social agent. The robot’s physical presence as a humanoid gives affordance to its inclusion in play-fighting (which would not be the case if it were per- ceived as merely a tablet). Furthermore, the children do not include adults in this play-fighting, which tentatively sug- gests the children perceive the robot as a peer. Figure 15 presents the results of the staff-reported behavioural incidents in the secondary corridor of the school, where the robot was located. We found that the robot’s presence tended to support the reduction in behaviour inci- dents. This suggests some connection between the co-design approach and providing a resources that follows the input from users (pupils) and beneficiaries (teachers). This, in turn, led to a significant decrease of reported behavioural incidents —a change observed over the whole three weeks of the study, with a return to higher levels of behavioural incidents after the robot left the school. This finding is similar to that of [47] who suggest the main message from their co-design approach with autism professionals and autistic children was that “personalisation to the needs of the individual child at hand” (p. 3091) is paramount. We echo this, and by locating this personalisation through co-design sessions we able to go further than the work of [47], and articulate their views into practice and evaluate them in-situ (i.e. the school). 5.2.3 Acceptance of the Robot and Qualitative Feedback The majority of children who encountered Pepper responded with positive attitudes towards the robot. Itis worth contextu- alizing that any form of ‘change’ 1s often perceived negatively by the autistic children at this school, for example more dis- ruptive behaviour at the start/end of days and at start/end of week. Even in this context of a dislike of change, the intro- duction of the robot was favourable for most students. The D Springer increased levels of interaction during the first 6 days reflect- ing the popularity of the intervention. Results from the post-study children questionnaire (Table 2; Fig. 12) paint a positive picture of the robot’s acceptance by the children: the pupils overwhelmingly rated Pepper as being “useful for the school” in addition to finding Pepper to being “entertaining”. Despite this, data also suggested that the pupils were less positive about “Pepper becoming their friend” or that Pepper was “useful to them’. They finally reported that they preferred “our Pepper” over robots gen- erally. This insight perhaps reveals that due to “our Pepper” being designed to suit their needs and designed with them, might support the finding that they felt more positive towards “our Pepper” than robots per se. Despite the overwhelmingly positive response from stu- dents, it 1s important to note that a small group of students held negative attitudes towards the robot. Child J expressed concern and worry about the robot’s presence (although Child J held negative views on many aspects of his daily school life) on repeated occasions. His teacher’s reported that the robot presence in the corridor prompted child J to stay in the room, which ironically helped with his more formal learning. Another child had a generalized (but very strong) fear of dig- ital technology not working correctly and the robot fitted into this collection of technologies. It was clear from the data that a small minority of children had highly negative perceptions of the robot (or robots in general) and their future presence needs very careful management by the school to successfully manage the integration of robots into schools’ ecosystems. The assistant head teacher identified how the robot was creating interaction opportunities for groups of children to interact together, noting that even children who would not usually interact in groups, would take part. This effect seems to be mostly attributable to the initial novelty and apparent complexity of the robot, and the data revealed that the vast majority of interactions in the later stages of the study were one-to-one (Fig. 8). This highlighted that group interaction was seen as important by the head teacher (seeing this as a positive) but also that over time these interactions transfer to one-to-one. This could be interesting for two reasons. Firstly, as it could suggest that individual pupils grew in confidence to use/interface with Pepper as time went on. It might have been that the group interactions (or gatherings) helped to enable less confident pupils to use Pepper with their peers and then feel more confident towards the end of the three weeks to interact one-on-one. Second, this finding indicates that on some level (albeit only the initial two weeks) that a robot like Pepper can encourage collaborative skills and prolonging their attention span while mediating and encouraging social interaction and learning appropriate physical interactions. All of which are established in this field already; therefore our observations of social interactions of our pupils support previous findings [47,48] and helps to build greater under- D Springer International Journal of Social Robotics standing of interaction patterns over a sustained period of time; something not well reported in robot-autism research. 6 Conclusions 6.1 A Social Robot in a SEN School: What for? We presented in this paper the design and results of a three-weeks long deployment of a humanoid social robot in a school for autistic children. The robot was operating autonomously in a school corridor, engaging with the pupils in a range of activities co-designed with the children and the teachers. Over the course of these three weeks, the robot performed 330 interactions (most of the time one-to-one interactions), resulting in more than 16 h of continuous inter- action time. We recorded and analysed a range of different metrics, both quantitative and qualitative, including the detailed log of the activities performed with the robot, the number of children interacting with the robot at a given time, the self- reported mood and feelings of the children before and after interacting with the robot, children and teacher feedback via questionnaires, and finally, a large set of observations (more than 280 notes), that were coded post-hoc. This large amount of data was meant to answer two main questions: can we (co-)design a social robot that ends up being ‘adopted’ by the pupils and the school staff, and inte- grates nicely in the broader school ecosystem? and: does it have a positive impact on the well-being of the pupils? Our data and the qualitative feedback from the children and teachers support both of these hypotheses. The robot did integrate within the school ecosystem; it maintained a high level of usage; it was perceived as a social agent rather than a mechanistic tool; the children liked it; they thought the robot was useful the them and their school; it did have a positive impact on the well-being of several children. Of course, the picture needs to be nuanced: some children did not like the robot, and at time, expressed this dislike in explicit ways, including a handful of cases with physical or verbal violence. While we immediately suggested to stop the study, the school staff did ask us not to: beyond the fact that some pupils were well identified by the school staff for showing patterns of rough behaviours, teachers also saw the negative reactions to the robot as opportunities for them to work with the students on their emotional regulation. We did not anticipate that teachers would exploit negative feelings toward the robot in such a way. While it did cause at that time a level of un-easiness amongst the research team , it was also a strong testimony of how the end-users—and the context of use they bring with them—are ultimately the ones deciding and shaping the use of the technology, as part of a International Journal of Social Robotics mutual shaping [49] process, where the technology and the society influence each other, in a co-development process. We further reflect on the broader ethical framework of our study in [31]. Our study does bring some elements of answer to the broader question: “A social robot ina SEN school: what for?” First, unlike most previous research on robotics and autism where robots were used for cognitive training, the starting point of our study design was that social robots could also contribute to the wellbeing of children. Based on insights from our participatory approach, we opted for unstructured, child—led interactions taking place outside of the classroom. This choice was well-received by the children and the teach- ers: a social robot can effectively contribute to the well-being of the children. Second, the physical and social presence of the robot is important. The children engaged with numerous sensory interactions with the robot, and referred to it as a social agent that could provide them with psycho-social support. Those capabilities are permitted (and elicited) by embodied nature of the robot, and would not be possible with alternative tech- nologies like tablets. 6.2 Limitations and Future Work While we provide an account of a study involving the deploy- ment of Pepper the robot in a school for autistic pupils, it is important to highlight several limitations that exist within our study. One of the limitations of the study is that the spatial con- figuration of the school was already fixed during the research. It would have been beneficial if the children could have con- tributed suggestions and insights towards how the school space itself might be configured to facilitate and support the integration of the robot. This points towards the need for future research into the design of social-robot-enhanced architectural spaces from users’ perspectives. It also raises interesting and troublesome design challenges that situate the robot as a social agent with a need for school designers to consider social robots as one of the users (along with other human stakeholders such as teachers, students, cleaners etc) and the possible ‘right’ for robots to have their own space within the school. We also acknowledge that what we found is mostly con- textualised in the school we worked with and their practices. Other schools would most likely require a bespoke inter- face building to support their pupils. However, we do suggest that what we uncovered from the co-design sessions and the interface we designed (with the pupils and teachers) could be transferred and re-tested in a similar setting (SEN and autism) with similar results expected. We acknowledge that having a researcher present to help control Pepper, solve possible technical problems, and record data, might have influenced the interactions the pupils had. Despite the researcher not being central to the area where Pepper was based, they were close enough for the pupils to clearly see them. This may have had a bearing on what they did and when they did it. Future research might consider a way to reduce this presence to capture even more naturalistic data. Future work should also consider personalisation to create bespoke experiences; endow the robot with the ability to be taught by the children new behaviours (eg: one child wanted the robot to touch his head, he tried without success to show that to Pepper). We suggest that building up a personal inter- action history between a child and the robot would lead to a continuously refined interaction experience, always a bit dif- ferent, that would as well help sustain the interest over longer period of time. We also recommend that future work in this field continues to engage end users and do so in a meaningful and complete way. Simply testing solutions and ideas with users is not enough. We located new insights to child—robot interactions by working with children in meaningful ways to co-design and lead the design of interactions. This is vital if we are to (1) produce more focused and beneficial uses of robots in the future and (2) understand users needs from the ground up and to ensure they are included in decisions that impact how technology like this will behave. Finally, future work should liaise closer with teachers and professionals to better locate their needs. We did this though a focus group, but could have gone further. For example, one teacher suggested that we used Pepper in their speech and language therapy sessions (using the interactive story function), but we were not able to test this or build this into our project. Researchers need to find the time to work more closely and in a sustained manner with these individuals. 7 Notes on Results Replication The scripts used to control the robot, as well as all the interface elements (robot tablet interface, researcher tablet interface, verbal prompts) are available online: github.com/severin-lemaignan/robots4sen-supervisor. This source code repository also includes detailed explanations about the software architecture of the system. Robot logs, researcher notes, questionnaires and questionnaire results are available in this repository: github.com/severin-lemaignan/robots4sen-data-analysis. The repository also contains two 1Python notebooks that allows the reproduction of all our data analysis results. Acknowledgements We would like to thank all the children and staff at the school who shared their insights with us during the focus groups and fieldwork. We would also like to thank everyone at the school who provided such a welcoming, supportive and nurturing environment for us to undertake this project with particular thanks to lan Conley, Assis- D Springer tant Principal, who made it possible for this project to take place at the school. We would also like to thank Vicky Charisi from the Joint Research Commission of the European Commission for her support and helpful insights. Funding This work was funded by the University of the West of Eng- land, where the authors were affiliated at the time of the study. This project has received additional funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sktodowska-Curie grant agreement No 801342 (Tecniospring INDUS- TRY) and the Government of Catalonia’s Agency for Business Com- petitiveness (ACCIO). Declarations Conflict of interest The authors declare not to have any conflicts of interest with any possible third parties. One of the researcher is a mem- ber of the board of Governors of the school where the study took place. In order not to influence the final decision, he withdrew from the board’s discussions pertaining to accepting the study to take place at the school. Informed Consent As indicated in Sect. 3.1, the study was approved by the university’s ethics board before it started. Informed consent was sought from all the participants before their effective participation. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adap- tation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indi- cate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copy- right holder. To view a copy of this licence, visit http://creativecomm ons.org/licenses/by/4.0/. References 1. Association AP (2013) Diagnostic and statistical manual of mental disorders: DSM-5 2. Russell G, Rodgers LR, Ukoumunne OC, Ford T (2014) Prevalence of parent-reported ASD and ADHD in the UK: findings from the millennium cohort study. J Autism Dev Disord 44(1):31—40 3. Ozerk K (2016) The issue of prevalence of autism/ASD. Int Elec- tron J Elem Educ 9(2):263—306 4. Conner CM, White SW, Beck KB, Golt J, Smith IC, Mazefsky CA (2019) Improving emotion regulation ability in autism: the emo- tional awareness and skills enhancement (ease) program. Autism 23(5):1273-1287 5. Danker J, Strnadova I, Cumming TM (2016) School experiences of students with autism spectrum disorder within the context of student wellbeing: a review and analysis of the literature. Aust J Special Educ 40(1):59-78 6. Torrado JC, Gomez J, Montoro G (2017) Emotional self-regulation of individuals with autism spectrum disorders: smartwatches for monitoring and interaction. Sensors 17(6):1359 7. Vahabzadeh A, Keshav NU, Abdus-Sabur R, Huey K, Liu R, Sahin NT (2018) Improved socio-emotional and behavioral functioning Q) Springer 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. International Journal of Social Robotics in students with autism following school-based smartglasses inter- vention: multi-stage feasibility and controlled efficacy study. Behav Sci 8(10):85 Williams RM, Gilbert JE (2020) Perseverations of the academy: a survey of wearable technologies applied to autism intervention. Int J Hum Comput Stud 143:102485 Wood R (2021) Autism, intense interests and support in school: from wasted efforts to shared understandings. Educ Rev 73(1):34— 54 Aldridge JM, Fraser BJ, Fozdar F, Ala’i K, Earnest J, Afari E (2016) Students’ perceptions of school climate as determinants of wellbe- ing, resilience and identity. Improv Sch 19(1):5—26 Mazurek MO (2014) Loneliness, friendship, and well-being in adults with autism spectrum disorders. Autism 18(3):223—232 Leigh J, Brown N (2021) Researcher experiences in practice-based interdisciplinary research. Res Eval 30:421 Kenny L, Hattersley C, Molins B, Buckley C, Povey C, Pellicano E (2016) Which terms should be used to describe autism? Perspec- tives from the UK autism community. Autism 20(4):442—-462 Bottema-Beutel K, Kapp SK, Lester JN, Sasson NJ, Hand BN (2021) Avoiding Ableist language: suggestions for autism researchers. Autism Adulthood 3(1):18—29 Belpaeme T, Kennedy J, Ramachandran A, Scassellati B, Tanaka F (2018) Social robots for education: a review. Sci Robot. https:// doi.org/10.1126/scirobotics.aat5954 Dautenhahn K (2003) Roles and functions of robots in human society: implications from research in autism therapy. Robotica 21(4):443-452 Begum M, Serna RW, Yanco HA (2016) Are robots ready to deliver autism interventions? A comprehensive review. Int J Soc Robot 8(2):157-181 Jain S, Thiagarajan B, Shi Z, Clabaugh C, Matari¢ MJ (2020) Modeling engagement in long-term, in-home socially assistive robot interventions for children with autism spectrum disorders. Sci Robot. https://doi.org/10.1126/scirobotics.aaz3791 Clabaugh C, Mahajan K, Jain S, Pakkar R, Becerra D, Shi Z, Deng E, Lee R, Ragusa G, Matari¢é M (2019) Long-term personaliza- tion of an in-home socially assistive robot for children with autism spectrum disorders. Front Robot AI 6:110 Robins B, Dautenhahn K, Boekhorst RT, Billard A (2005) Robotic assistants in therapy and education of children with autism: Can a small humanoid robot help encourage social interaction skills? Univ Access Inf Soc 4(2):105—120. https://doi.org/10.1007/ s10209-005-0116-3 Good J, Parsons S, Yuill N, Brosnan M (2016) Virtual reality and robots for autism: moving beyond the screen. J Assist Technol 10:211 Kozima H, Michalowski MP, Nakagawa C (2008) Keepon, a playful robot for research, therapy, and entertainment. Int J Soc Robot 1(1):3-18. https://doi.org/10.1007/s 12369-008-0009-8 Scassellati B, Admoni H, Matari¢ M (2012) Robots for use in autism research. Annu Rev Biomed Eng 14(1):275—294. https:// doi.org/10.1146/annurev- bioeng-07181 1- 150036 Esteban PG, Baxter P, Belpaeme T, Billing E, Cai H, Cao H-L, Coeckelbergh M, Costescu C, David D, De Beir A et al (2017) How to build a supervised autonomous system for robot-enhanced ther- apy for children with autism spectrum disorder. Paladyn J Behav Robot 8(1):18—-38 Suzuki R, Lee J, Rudovic O (2017) NAO-dance therapy for chil- dren with ASD. In: Proceedings of the companion of the 2017 ACM/IEEE international conference on human-robot interaction. ACM. https://doi.org/10.1145/3029798.3038354 Cao H-L, Esteban PG, Bartlett M, Baxter P, Belpaeme T, Billing E, Cai H, Coeckelbergh M, Costescu C, David D, Beir AD, Hernandez D, Kennedy J, Liu H, Matu S, Mazel A, Pandey A, Richardson K, Senft E, Thill S, de Perre GV, Vanderborght International Journal of Social Robotics 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. AO. Al. 42. B, Vernon D, Wakanuma K, Yu H, Zhou X, Ziemke T (2019) Robot-enhanced therapy: development and validation of super- vised autonomous robotic system for autism spectrum disorders therapy. IEEE Robot Autom Mag 26(2):49-58. https://doi.org/10. 1109/mra.2019.2904121 Trigo MJG, Standen PJ, Cobb SVG (2019) Robots in special edu- cation: reasons for low uptake. J Enabl Technol Newbutt N, Rice L, Lemaignan S, Daly J, Charisi V, Conley I (2022) Co-designing a social robot in a special educational needs school: listening to the ambitions of autistic pupils and their teach- ers. Interact Stud (to appear) Coeckelbergh M, Pop C, Simut R, Peca A, Pintea S, David D, Van- derborght B (2016) A survey of expectations about the role of robots in robot-assisted therapy for children with ASD: ethical acceptabil- ity, trust, sociability, appearance, and attachment. Sci Eng Ethics 22(1):47-65 Dignum V, Penagos M, Pigmans K, Vosloo S (2020) Policy guidance on AI for children (draft). Technical report, UNICEF. https://www.unicef.org/globalinsight/reports/policy- guidance-ai- children Lemaignan S, Newbutt N, Rice L, Daly J, Charisi V (2021) UNICEF guidance on AI for children: application to the design of a social robot for and with autistic children. In: Proceedings of the IROS2021 workshop: the roles of robotics in achieving the UN’s social development goals Karim ME, Lemaignan S, Mondada F (2015) A review: Can robots reshape k-12 STEM education? In: Proceedings of the 2015 IEEE international workshop on advanced robotics and its social impacts Leite I, Martinho C, Paiva A (2013) Social robots for long-term interaction: a survey. Int J Soc Robot 5(2):291—308 Kanda T, Hirano T, Eaton D, Ishiguro H (2004) Interactive robots as social partners and peer tutors for children: a field trial. Hum Comput Interact 19(1—2):61-84 Kanda T, Sato R, Saiwaki N, Ishiguro H (2007) A two-month field trial in an elementary school for long-term human-—robot inter- action. IEEE Trans Rob 23(5):962—971. https://doi.org/10.1109/ TRO.2007.904904 Davison DP, Wijnen FM, Charisi V, Meij Jvd, Evers V, Reidsma D (2020) Working with a social robot in school: a long-term real-world unsupervised deployment. In: 2020 15th ACM/IEEE international conference on human-robot interaction (HRI), pp 63- 72. https://doi.org/10.1145/3319502.3374803 Tanaka F, Cicourel A, Movellan JR (2007) Socialization between toddlers and robots at an early childhood education center. Proc Natl Acad Sci 104(46):17954—-17958 Mondada F, Fink J, Lemaignan S, Mansolino D, Wille F, Franinovic K (2015) Ranger, an example of integration of robotics into the home ecosystem. In: New trends in medical and service robots, vol 38, Mechan. Machine Science, Springer. https://doi.org/10.1007/ 978-3-319-23832-6_15 Charisi V, Sabanovié S, Gasser U, Gomez R (2021) Social robots and children’s fundamental rights: a dynamic four-component framework for research, development, and deployment. In: WeR- obot 2021 Bjorling E, Rose E (2019) Participatory research principles in human-centered design: engaging teens in the co-design of a social robot. Multimodal Technol Interact 3(1):8. https://doi.org/10.3390/ mti3010008 Pandey AK, Gelin R (2018) A mass-produced sociable humanoid robot: pepper: the first machine of its kind. IEEE Robot Autom Mag 25(3):40-48. https://doi.org/10.1109/mra.2018.2833157 Kennedy J, Lemaignan S, Montassier C, Lavalade P, Irfan B, Papadopoulos F, Senft E, Belpaeme T (2017) Child speech recognition in human-robot interaction: evaluations and recom- mendations. In: Proceedings of the 2017 ACM/IEEE human-robot interaction conference. https://doi.org/10.1145/2909824.3020229 43. Dennett DC (1971) Intentional systems. J Philos 68(4):87—106 44. Fink J (2014) Dynamics of human-robot interaction in domes- tic environments. PhD thesis. https://doi.org/10.5075/EPFL- THESIS-6329 45. Belpaeme T, Baxter P, Read R, Wood R, Cuaydahuitl H, Kiefer B, Racioppa S, Kruijff-Korbayova I, Athanasopoulos G, Enescu V, Looe R, Neerincx M, Demiris Y, Ros-Espinoza R, Beck A, Canamero L, Hiolle A, Lewis M, Baroni I, Nalin M, Cosi P, Paci G, Tesser F, Sommavilla G, Humbert R (2013) Multimodal child— robot interaction: building social bonds. J Hum Robot Interact 1(2):33-53 46. Lemaignan S, Fink J, Dillenbourg P (2014) The dynamics of anthropomorphism in robotics. In: Proceedings of the 2014 ACM/IEEE human-robot interaction conference 47. Huijnen CA, Lexis MA, Jansens R, de Witte LP (2017) How to implement robots in interventions for children with autism? A co-creation study involving people with autism, parents and pro- fessionals. J Autism Dev Disord 47(10):3079-—3096 48. Wainer J, Robins B, Amirabdollahian F, Dautenhahn K (2014) Using the humanoid robot Kaspar to autonomously play triadic games and facilitate collaborative play among children with autism. IEEE Trans Auton Ment Dev 6(3):183—199 49. Sabanovié S (2010) Robots in society, society in robots. Int J Soc Robot 2(4):439-450. https://doi.org/10.1007/s 12369-010-0066-7 Publisher’s Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional affiliations. Dr. Séverin Lemaignan PhD. is Senior Scientist at Barcelona-based PAL Robotics. He leads the Social Intelligence team, in charge of designing and developing the socio-cognitive capabilities of robots like PAL TIAGo and PAL ARI. He was previously Associate Professor in Social Robotics and AI at the Bristol Robotics Laboratory, Uni- versity of the West of England, Bristol. He obtained in 2012 a joint PhD in Cognitive Robotics from the CNRS/LAAS (France) and the Technical University of Munich (Germany). He then joined the EPFL (Switzerland) and Plymouth University (UK) as post-doc, then lec- turer in Robotics until 2018, when he joined the Bristol Robotics Lab. His research interest primarily concerns socio-cognitive human-robot interaction, child-robot interaction and human-in-the-loop machine learn- ing for social robots. Dr Nigel Newbutt Ph.D. is currently an assistant professor in advanced learning technologies at the University of Florida. He is affiliated with the Institute of Advanced Learning Technologies (IALT) where he directs the Equitable Learning Technologies Lab (ELTL). His under- graduate work was in digital media, with postgraduate work in edu- cation and special needs. His research then focused on working with autistic communities to support technology applications addressing needs identified by this community. He conducts research on advanced learning technologies, and immersive technologies, with a view to supporting some of the challenges faced by autistic communities. He has led several projects on innovative technology for autism and has established lines of enquiry around wearable technology and sensory preferences for autistic users. Dr Louis Rice PhD. is Associate Professor at the Department of Archi- tecture & Built Environment at the University of the West of England, D Springer Bristol and Head of the World Health Organisation Collaborating Cen- tre for Healthy Urban Environments. Louis’ research involves inter- disciplinary collaborations examining healthier and more sustainable environment by focusing on the relationship between the design of the built environment and human health, particularly specializing in healthy architecture and healthy cities. Q) Springer International Journal of Social Robotics Joe Daly MSc. is a PhD student at the Bristol Robotics Labora- tory and received their master’s in psychology at University of Bristol. Their research focuses on human-robot interaction and the role and ethics of robots using emotion to gain assistance from people. They are also engagement manager for Alhub, a charity committed to pro- viding unbiased science communication about AI and robotics. 