See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/262379863 Multimodal Cognitive Nonverbal and Verbal Interactions: the Neurorehabilitation of Autistic Children Via Mobile Toy Robots Article in International Journal on Advances in Life Sciences - December 2013 CITATIONS READS 28 441 1 author: es lrini Giannopulu 86 PUBLICATIONS 733 CITATIONS SEE PROFILE All content following this page was uploaded by Irini Giannopulu on 18 May 2014. The user has requested enhancement of the downloaded file. ResearchGate 2013 vol. 5 nr. 3&4 rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ Multimodal Cognitive Nonverbal and Verbal Interactions: the Neurorehabilitation of Autistic Children Via Mobile Toy Robots Irini Giannopulu Cognitive Neuroscience Pierre & Marie Curie University email: igiannopulu@psycho-prat.fr Abstract—Miultimodal cognitive nonverbal processes could be thought as a building block from which emotional and verbal expressions could emerge. With the intention to explore this hypothesis, we studied the interaction between autistic children and mobile toy robots during free spontaneous game play both quantitatively and qualitatively. Cognitive nonverbal criteria (eye contact, touch, manipulation, and posture) were analyzed, firstly in a dyadic interaction and secondly in a triadic interaction. The frequency of nouns and verbs including those which express positive emotion was figured out only in dyadic interaction. Once the cognitive nonverbal state between the child and the robot established, the child interacts with a third person displaying positive emotion. A positive correlation exists between multimodal cognitive nonverbal processes and verbal expression when the free game play with the robot is possible. This data suggests that in free spontaneous game play (i.e., ecological situation) the mobile toy robots could be used as a neural orthesis to enhance severe, middle and moderate autistic children’s brain multimodal activity. The findings allow us to infer that this neural orthesis could pave the way for the development of synergistic dialogues between autistic children and human environment. Keywords-multimodal verbal and nonverbal interactions; autism; mobile toy robots; free game play; positive emotion; neural orthesis. I. INTRODUCTION Robots are utilized in training, and education of autistic children. The studies we develop aim to analyze the multimodal cognitive nonverbal and verbal interactions of autistic children, during free game play with mobile toy robots [1]. Autism spectrum disorder is a complex and heterogeneous neurological disorder that affects cognitive functioning but also emotional, social behavior and language development [2]. Language problems appear early and persist. Severe autistic children do not develop expressive language. However, when the children do acquire expressive language, it is often lacking any depth, it is echolalic and it 1s characterized by an absence of imagination [3]. Genetic studies have highlighted the complexity of the genetic architecture underlying autism. They consider autism as a complex multifactor disorder involving many genes [4], [5], [6]. These studies have given rise to new insights into neuronal circuits relevant to autism disorders. Post-modern analysis had demonstrated evidence of altered brain development, which strongly affects the formation of a multimodal neural network. The analysis shown that the neural substrate underlying cognitive, social, emotional and linguistic impairment involves multimodal areas such as the exterior superior temporal sulcus [6], the interior temporal lobe, amygdala included [7], as well as the ventral part of the prefrontal cortex, 1.e., orbitofrontal cortex [8]. The autistic brain is also characterized by aberrant brain connectivity and disruption of white matter tracts between temporal regions [9], which disrupt verbal and nonverbal acquisition, consolidation as well as social interaction [10], [11], [12], [13]. These functional studies provide the basis for concluding that in autism the more impaired cortical areas are those that are involved in complex cognitive functions such as perception, social interaction, emotion and language. Such complex expression of autism necessitates a more generic consideration of this disorder at the multimodal neural level. Developmentally speaking, the most widely accepted hypothesis in autism is the theory-of-mind deficit [14]. Even if this theory cannot account for the whole spectrum of autistic disorders, it raises many issues that not only involve mental representation of others but also social skills such as posture [15], eye contact [16], touching [9] and manipulation [17] that express social interaction [18]. Game play is a very important feature of early childhood and is of particular importance for children with autism. Play in children with autism is more like "learned routine" rather than "spontaneous" [19]. Autistic children show difficulty in their play activities, which could be associated with their deficit in cognitive, and emotional development, i.e., multimodal cognitive nonverbal and verbal interactions. Free game play characterized by spontaneity could allow children with autism the possibility to express themselves and engage in satisfying social activity, which in turn, could lead to development of their cognitive nonverbal and verbal skills [20], [21], [22]. Different approaches are being utilized to better understand the capacity of autistic children to interact with a robot [23]. The Aurora’s project aim was to create a tool based on an autonomous robot (e.g., Labo-1, Kaspar, Robota doll) that convinces autistic children to engage in a process of interaction [24], [25], [26] [27]. A sensitive robot named Tito was employed in social interaction [28], [29]. Keepon, a very small fixed robot, can capture and maintain visual contact with the child [30]. Roboto uses the form of an animated face (mouth, eyebrows, eyes) to cause behavior imitation [31]. The dinausor Pleo seems 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 214 reinforce social behavior [32]. All these studies have shown that animated robots, humanoid or not, using different stimulation encourage interaction in autistic children. Even if quantitative metrics of social response for autism diagnosis including robots were developed [33]; only one study has used a quantitative technique for analyzing dyadic (child-robot) interaction for autism therapy [34]. With the exception of Labo-1 in the Aurora project, and Roball in Michaud's project so far, only fixed robots have been utilized reducing the child’s spontaneity and self— expression in game play. We used a mobile toy robot named “GIPY 1” (Figure 1), which incites the child to engage in interaction. On the hypothesis that autistic children will be in quasi-constant interaction with the robot, the cognitive behavior of severe autistic children in interactive activities with a robot, L.e., dyadic interaction, during spontaneous game play using multimodal cognitive nonverbal criteria was analyzed. In addition, we hypothesized that once dyadic interaction is established, the child could use the robot as a mediator to initiate the interaction with the third person, an adult, and express emotion, 1.e., triadic interaction. This cognitive and emotional interaction of the autistic child with a third person was investigated, once again, 1n spontaneous, free game play by means of a multimodal approach. Under the hypothesis that multimodal cognitive nonverbal interactions could be thought of as the building block from which expressive language could emerge, we used a new mobile toy robot named “POL” (Figure 4), which incites the middle and moderate autistic children to engage in dyadic (1.e., child-robot) interaction and express language. The relationship between multimodal cognitive nonverbal criteria (visual, tactile, manipulation and posture) with verbal behavior (including positive or negative emotion) was analyzed “with” and “without” free game play. The present studies are part of our project actually in progress concerning multimodal interactions in typically and atypically developing children using natural and/or artificial environments. Beginning with the design of the studies, we will continue with the analysis of the results of both multimodal cognitive nonverbal interactions in dyadic and triadic situation. Then, we will describe the correlation between multimodal cognitive nonverbal and verbal interaction in dyadic interaction before discussing the embodiment of multimodal information during free spontaneous game play between mobile toy robots and autistic children. Il. METHOD A. Dyadic and triadic nonverbal interaction 1. Participants ¢ Dyadic nonverbal interaction Four severe autistic children (3 boys and 1 girl) participated in this study. Their chronological ages ranged from 7 to 9 years old (mean 8.3 years). Their developmental age ranged from 2 to 4 years old. The children were diagnosed according to the D.S.M. IV-TR criteria of autism [35]. The C.A.R.S [36] had been administered at the age of 6 years by an experienced rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ clinical psychologist. The C.D.I [37] was used to estimate intellectual disability (Table I). TABLE I. GENERAL CHARACTERISTICS OF POPULATION A) CHILDHOOD AUTISM RATING SCALE B) INTERNATIONAL CLASSIFICATION OF DISEASES Children Developmental Sex C.A.R.S C.D.I age (a) (b) ¢ Triadic nonverbal & emotional interaction: Case Study “A” is a right-handed young boy. He exhibits mental retardation as per the C.D.I. [37]. His chronological age is 8 years old and his developmental age is 2 years old. The child was diagnosed with autism when he was 3 years old and still displays all characteristics of autism according to the D.S.M IV-TR [35]. In addition, the C.A.R.S. [36] has shown severe autism with a score of 43 points. “A” has deficits in reciprocal social interactions and communication (speech and language), stereotyped behavior and restricted interests and activities. At the time of the experiment all of the children were attending special education classes of autism for both studies. The study was conducted in a day hospital outside of Paris. The experiment took place in a familiar room. The study was approved by the local ethics committee and was in accordance with the Helsinki convention. All the parents were formally informed and agreed to the participation of their children in this study. Anonymity was guaranteed. 2. Material ¢ Room The room was 4.56 m by 3.34 m. A chair, a small wardrobe and a table on which the equipment needed for the framework of the study was placed (laptop and joystick), were used. In order to reduce the presence of disruptive elements and so as to avoid autistic bend, the room was left bare [38]. ¢ Robot A mobile robot, called “GIPY-1”, which is cylindrical shaped with a diameter of 20 cm and a height of 30 cm, was created for use in the experiment. A representation of a neutral facial expression constitutes the cladding of the robot: the round eyes and nose triangle were dyed olive green and the elliptical mouth was dyed red (Figure 1). Everything was covered with a transparent plastic sheet. The simplicity of the robot was driven by the preference of autistic children for simple and predictable toy design [39]. An operator manipulated the robot via a wireless remote control using a joystick connected to a laptop. The robot could move forward, backward and turn on itself at low speed. These movements were constant. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 215 Figure 1. GIPY I * Protocol for the dyadic and the triadic interactions The duration of the session was 5 minutes. The robot was placed on the ground beforehand, in the center of the room, its stylized face toward the entrance. The game play session began as follows: when the child and the adult entered the room, the tele-operated robot carried out three movements (move forward, move back, 360° swivel). As in real social interaction, the child and the robot altered their responses. If the child approached, the robot moved back and conversely. If the child moved away from the robot, 1.e., ignored the robot, the robot followed the child in order to attract its attention. If the child remained motionless, the robot approached or turned itself around in order to focus the attention of the child. All movements were standardized. ¢ Analysis for the dyadic and the triadic interactions Two independent judges unfamiliar with the aim of the study completed the observations of the game play skills. Both performed the analyses of video sequences with Elan software [40]. Prior to assessing game play improvement, inter-judge reliability was assessed to ensure that both judges who analyzed videotapes were consistent in their analyses. Inter-judge reliability was assessed using intra-class coefficients to make the comparison between them. The inter-judge reliability was good (Cohen’s kappa=0.63). The dependent variable was the time of child-robot interaction for the dyadic interaction and the time of child- robot and adult for the triadic interaction. Accordingly, we calculated the duration of all the characteristics of each criterion. This was defined as the duration between the onset time and the offset time of each child’s behavior toward the robot. Four criteria were defined for the dyadic interaction: 1) eye contact, 2) touching, 3) manipulation, 4) posture. Based on the hypothesis that cognitive interaction could be lead to the expression of an emotional state, an additional fifth criterion (5) was defined for the triadic interaction. This criterion was: positive emotion (Table II). rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ TABLE II. CHARACTERIZATION OF EACH CRITERION . . . Positive Posture Touching Eyecontact Manipulation Emotion S/he seizes oihe sus and blocks the front S/he looks at tObot with the S/he smiles to of robot; | S/he puts the immobile oh. rans the adult; the left robot; € ilts 0 S/he bends hands on the robot; S/he laughs to towards the robot; S/he watches S/ ie Sos the the adult; the robot; the robot both h od gh S/he bends S/he puts turning; ol hands, € Expresses over the the right S/he catches tenderness to robot; handonthe S/he watches cr roPols the adult; robot; the robot ‘he ‘ob i S/he look S/he squats going away; € TODOL, e looks and bends S/he S/he tilts the happy with over the touches the S/he watches rool around the adult; robot; robot with the robot Ic “ rit S/he look both hands approaching “08S & 1S e Looks S/he steps wheel; pleased to the over the S/he puts back adult robot the robot upright The duration of each criterion was calculated in seconds and was considered independent of the others. Concerning, for example, the characteristic “s/he looks at the immobile robot” (“eye contact”) the onset time corresponded to the time when the child looked at the robot and the offset time to the moment when the child looked away from the robot. We calculated the duration of all the characteristics of each criterion. We summed up the duration corresponding to each criterion. Only the total duration is presented in the results section. 3. Results ¢ Dyadic interaction The mean time of dyadic interaction was 238.7 sec. In other words, the children spent nearly 80% of their time (156 seconds for the first, 289 seconds for the second, 269 seconds for the third and 241 seconds for the forth child) playing with the robot. The duration of each robot-child interaction 1s presented in Figure 2. The duration of “eye contact” is similar for all the children. However, the analysis of the duration of “touching”, “manipulating” and “posture” possibly reflects inter-individual differences related to different forms of autism. This analysis also showed how autistic children’s behavioral interaction with the robot changes over a period of time. As such, this analysis suggests that in free game play a mobile toy robot could help autistic children to reduce repetitive and stereotypical behavior. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 216 rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ seconds seconds fH child 1 [1 child 2 Mi child3 (J child4 110 0 eye contact touching manipulation posture Figure 2. Duration of dyadic interaction for each criterion [8 dyadic situation [triadic situation 90 80 70 60 50 40 eye contact 30 20 10 0 positive emotion touching posture Figure 3. Duration of dyadic and triadic interactions for each criterion ¢ Triadic nonverbal and emotional interaction The mean time of dyadic interaction was 25 sec; the mean time of triadic interaction was 30 sec. In other words, the child spends half the time playing with the robot and the half the time playing with the robot and the adult. The duration of dyadic and triadic interaction is presented in Figure 3. The duration of “eye contact” and of “touching” is similar in both situations. However, the duration of “manipulation”, of “posture” and of “positive emotion” differs between the two situations. As we can observe, positive emotion is more easily expressed when the child interacts with the adult and the robot than when the child interacts only with the robot. This difference reflective of the changes in autistic child behavior with the robot over a period of time also tells us that a mobile robot could be used as a mediator for social and emotional interaction. This is an encouraging conclusion with regard to the potential of human-to-human interaction. B. Dyadic verbal and nonverbal interaction 1. Participants Eleven children (8 boys and 3 girls) participated in this study. Their chronological ages ranged from 7 to 8 years old (mean 7.3 years; sd 6 months); their developmental age ranged from 5 to 6 years old (mean 6 years; sd 4 months). The mean age when first words appeared was 38 months (sd 5 months). The children were diagnosed according to the DSM IV-TR criteria of autism [20]. The Childhood Autism Rating Scale [21] had been administrated at the age of 6 years by an experienced psychiatrist. The present population is composed by middle and moderate autistic children. They were all verbal (Table III). The study was approved by the local ethics committee and was in accordance with the Helsinki convention. All the parents were formally informed and agreed to the participation of their children in this study. Anonymity was guaranteed. TABLE II. GENERAL CHARACTERISTIC OF POPULATION A. CHILDHOOD AUTISM RATING SCALE ee ee < nn] oa Ald ITO TN N NN wlwfluwfwoflfwlw]w RLAITNTR LAT ATTN Oo Oo Oo N — — Ae ee Cr 2. Material « Robot A mobile robot, called “POL”, which is animal- shaped, was used: a mobile chicken (Figure 4). An operator manipulated the robot via a wireless control. « Protocol The study was conducted in two day hospitals: one outside and one inside of Paris. The experiment took place in a familiar room to all the children. We have defined two conditions: one “with” and another “without” game play. “Without game play”: Children’s observation behavior with the immobile robot placed on the ground beforehand, in the center of the room. There is no game play session. “With game play”: Children’s observation with the mobile robot. The robot was placed on the ground beforehand, in the center of the room. The game play session was unfolded as in the previous studies (see the protocol described previously). The two conditions were counterbalanced across the children. The inter-condition interval was about 2 minutes. The duration of each condition was 10 minutes. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 217 Figure 4. Child during game play with “POL robot ¢ Analysis In both conditions, two dependent variables (DV) were utilized: a) the duration of child-robot interaction; b) the frequency of nouns and verbs expressed by the children. For the first DV, four criteria defined as in the previous analysis (dyadic and triadic nonverbal interaction). As in the above studies, we have measured the duration of all the characteristics of each criterion (Table II). For the second DV, we have calculated the frequency of nouns and verbs, 1.e., expressive language. As in our previous studies, two independent judges unfamiliar with the aim of the study completed the observations of the whole protocol ( “with” and “without”’ game play) performing the analyses of video sequences with Elan software [40]. The inter-judge reliability was good (Cohen’s kappa =0.67). 3. Results The distribution of duration according to the criteria in the two conditions approximates a non parametric shape. With such distribution, the median has been chosen as a central index for the comparisons. The statistical comparisons have been conducted with the Chi-Square Test (v2 Test); relationship between cognitive nonverbal and verbal interactions was analyzed with the nonparametric Spearman rank correlation coefficient (Spearman’s p correlation coefficient). In “without game play” condition, the children interact less with the robot (1 minute and 57 sec) than in “with game play” (8 minutes and 40 seconds) (y2=6.89, p<0.01). The results show that the median duration of “eye contact” is longer in the “with game play” condition (4.27 sec) than in the “without game play” (1.48 sec) (v2=7.12, p<0.01). Similarly, the median duration of *touching”’, “manipulating” and “posture” is higher in “with game play” condition than in “without game play” condition, 1.e., 2.36 sec vs. 1.24 sec; 1.16 sec vs. 0.66 sec; 1.51 sec vs. 0.97 sec respectively; (y2=6.07, p<0.025; y2=4.7, p<0.05; y¥2=4.01, p<0.05 respectively) (Figure 5). rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ ™ without game play with game play median duration time and IQR / minutes NO eye contact touching manipulation posture Figure 5. Duration of multimodal cognitive nonverbal interactions ® without game play with game play median frequency and IQR verb nouns Figure 6. Median frequency of nouns and verbs As the Figure 6 shows verbal expression was more frequent in “with game play” condition (7.45 median frequency for nouns; 4.36 for verbs) than in “without game play” condition (0.73 median frequency for nouns; 0.64 for verbs) (y2=7.16, p<0.01 for the nouns; y2=6.99, p<0.01 for the verbs) (Figure 3). Only in “with game play” condition, the children express three nouns (nice, beautiful, good) and one verb (like), which involve positive emotion (y2=3.99, p<0.05 for the nouns; y2=3.88, p<0.05 for the verbs). 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 218 10 rang of multimodal cognitive interaction 0 2 3 5 6 8 rang of verbal expression Figure 7. Relation between multimodal cognitive nonverbal and verbal (positive and neutral) information A positive correlation exists between expressive language (nouns and verbs) and multimodal cognitive information in the “with game play” condition (Spearman’s p correlation coefficient=0.747, p=0.01 one- tailed Test) (Figure 7). In contrast, there is no positive correlation between expressive language (nouns and verbs) and multimodal cognitive information in “without game play” condition (Spearman’s p correlation coefficient=0.23, p >0.05 one- tailed Test). Ill. DISCUSSION ¢ Dyadic nonverbal interaction Consistent with our hypothesis, the children were quasi-constantly in interaction with the mobile robot using a variety of ways. As autism 1s a spectrum disorder where a large variation in abilities and interests among autistic children is apparent, the interaction of children and robots was evaluated on the level of each individual child. Coherent with various studies, the present study shows that the use of robots engages autistic children in interaction [25], [29-32], [41-44]. In our case, we have computed the duration of robot-child cognitive nonverbal interaction during free, spontaneous game play. By doing so, the behavior of autistic children vis-a-vis the robot based on four nonverbal criteria has been analyzed and a temporal quantification of dyadic interaction with respect to the duration was performed. The analysis revealed that the duration of “eye contact” behavior was similar for each child. Inter-individual differences were identified for the duration of “touching”, “manipulating” and “posture” behavior. These differences might be related to different expression of autism. The data demonstrated that the autistic children not only visually explored the robot [34] but also engaged in different kinds of play with the robot. In other words, the autistic children seem take an interest in playing with the mobile robot. It seems that free game play could be a relevant ecological situation, 1.e., near to everyday life, where an autistic child spontaneously rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ interacts with the robot. Moreover, mobile toy robot could help autistic children to reduce repetitive and stereotypical behavior. These findings also reveal that free, spontaneous game play with robots is possible with severe autistic children and could better facilitate the transfer of social and learnt abilities to everyday life. Nevertheless, what is important to demonstrate is whether and how autistic children could generalize learnt abilities during play with the robot to adults, 1.e., proving that the robot could be used as a neural mediator tool for the enrichment of child-human interaction. This later assumption has been analyzed using a triadic approach. ¢ Triadic nonverbal and emotional interaction In this case study, we analyzed the ingredients of child- robot two-pronged interaction and child-robot-adult three- pronged interaction. Consistent with our hypothesis, the child first establishes a relationship with the robot and then uses the robot as an “instrument” to initiate the interaction with the adult (study 3). At first glance, our results are compatible with recent findings according to which the presence of a robot, are more effective than other environments in allowing autistic children to express social interest towards the robot [27-28], [30], [39], [45-46]. In these studies, researchers have used robots for treating autistic children. However, the relationship between robot and child has been studied solely based on the analysis of a single mode of interaction. Furthermore, the studies have been conducted using fixed robots. Our results go beyond these findings because we have demonstrated, as far we know for the first time, that in spontaneous, free game play, an autistic child uses the robot to interact with the adult and to express positive emotion. As such, on the one hand, we have shown that the dyadic interaction is based on a cognitive state and, on the other, that the child uses the robot as a mediator to express positive emotion playing with the adult. More precisely, in this study, as in our previous studies [47-48], we have demonstrated that visual, haptic, tactile perception and posture, 1.e., multimodal perception, are on the basis of the interest the child displays towards the robot. This is because, in our approach (as in Quinn & Eimas approach [53]), perception and cognition are considered to be a single domain rather than two distinct entities. The criteria we have chosen are assumed to represent the state of the child's cognitive nonverbal processes, as expressed by the interest the child exhibits towards the robot in spontaneous, free game play. As the present study has shown, once this state is established, the child develops a triadic relation, 1.e., with the robot and the adult, thereby displaying enjoyment, which is a positive emotion. The expression of positive emotion could be related to the emergence of a cognitive state, which is multimodal in our case. This expression appears when the child interacts with the adult using the robot. In our study, the child “A” is in constant interaction with the robot, expressed by a multimodal cognitive state that, according to us, allows him to express positive emotion with the adult. When “A” interacts with both the robot and the adult, he changes his behavior. We think that the robot as a mediator could bring about neurocognitive improvements to the autistic child. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 219 In both studies, the findings seem indicate that free game play, i.e., near to everyday life, encourages an autistic child to interact with the robot in a spontaneous manner and could reduce repetitive and stereotypical behavior. They also reveal that free, spontaneous game play with robots is possible with autistic children and could better facilitate the transfer of learnt abilities to everyday life. One limitation of these studies is the small number of autistic children, which makes impossible inferential analysis. Additional studies are required with a substantial number of children. We also need to confirm the importance of free game play in improving children’s nonverbal but also verbal performances. In that context, we have explored the multimodal cognitive nonverbal and verbal interactions between a mobile toy robot and autistic children with and without free game play. e Dyadic verbal and nonverbal interaction In that study, our results indicated that the duration of multimodal cognitive nonverbal interactions (visual contact, manipulation, touching, posture) is longer when free spontaneous game play with the robot is possible (with game play condition) than when game play is impossible (without game play condition). Consistent with the studies presented here above, these new results show, once again, that a mobile toy robot engages autistic children in multimodal nonverbal interactions (visual, tactile, manipulation, posture). Taken together, these studies seem demonstrate that autistic children’s behavioral interaction with a mobile robot changes over a period of time. Free game play, which is very close to a everyday life situation, encourages autistic children to interact with the robot in a spontaneous manner [22]. Coherent with the above is the fact that language is expressed only during free game play. Even if the children of our study suffer from middle or moderate autism and are verbal, these results show that the expression of language is possible when the children interact with the robot (in free game play) using a multimodal mode. In the same vein, children produced three nouns and one verb, which connote positive emotion only during game play. Moreover, positive correlation between multimodal cognitive nonverbal information and verbal expression 1s significant when the children spontaneous interact with the mobile robot: the more the multimodal nonverbal interaction, the more the verbal expression. As such, these results are consistent with our hypothesis suggesting that multimodal cognitive nonverbal interactions could be considered as the basis of verbal expression. ¢ Dyadic, triadic verbal, nonverbal and emotional interaction The present three studies seem indicate that mobile robots could not only be used as a mediator for nonverbal [48] and emotional interaction ({1], [22], [50], [51]) but also for verbal expression ([52]), which is the distinguishing characteristic of the inter-human communication. This is a comforting issue with regard to the potential of human-robot interaction. As such, the data suggests, that more mobile that immobile robots could be efficient for training, education and neurorehabilitation of rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ autistic children. In other words, an artificial environment such as mobile toy robots could provide the source of emergence of multimodal cognitive nonverbal information, which in turn, could be combined with emotional [49], [50] and verbal information [52] in a coordinated manner. The mobile robots (which can be considered as a neural orthesis), could pave the root for the development of synergistic dialogues between autistic children and human environment. As our data has shown free game play (which is close to everyday life) is more auspicious than the absence of free game play to improve severe, middle and moderate autistic children’s brain multimodal activity. The reporting data converges to say that autistic behavior can be improved via mobile robots, 1.e., artificial environments. This is coherent with the assumption that cognitive nonverbal/verbal and emotional development is the result of a complex process with three foci at least, one in the central nervous system, one in the mind and one in the child’s dynamic interactions with the environment [22]. The human brain undoubtedly has its own dynamic that allows neurons to interact, which in turn, affects the development and function of the brain areas [21]. In the case of autism, the brain activity is characterized by an hypofunctioning. An artificial environment like a mobile robot, 1.e., neural orthesis seems improve the neural activity (and consequently) the behavior of autistic children: autistic children interact with the robot multimodally only in free game play (Figure 8). Artificial environment, i.e., mobile robot free game play~— Brain dysfunction, e.g., autistic brain Multimodal cognitive nonverbal/ verbal and emotional interactions Figure 8. Principle of Neurorehabilitation during free game play Our hypothesis is that this emerging brain multimodality is crucially shaped by the children’s interactions with the environment during free game play. Nonverbal cognition, language and emotion develop at the interface between neural processes. They arise from the dynamic interaction between the developing brain and the artificial environment, 1.e., the robot [22]. Our approach, actually in progress, attempts to understand "how" artificial environments could be considered as the root of neuronal organization and reorganization ([21], [22]). Based on the brain’s intrinsic properties, neuroplasticity and the fact that the brain is neurodynamic, our studies try to demonstrate that a mobile robot could be used as a neural orthesis with the 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 220 intention to support the embodiment of cognitive nonverbal, emotional and verbal information processing in free game play. To our knowledge, this data represents some of the first to analyze the relationship between multimodal cognitive nonverbal information and verbal expression during spontaneous free game play in severe, middle and moderate autistic children using mobile toy robots. IV. CONCLUSION With these studies (part of our project actually in progress), we have demonstrated evidence for the view that spontaneous free game play with toy robots could be a source from which the brain of autistic children can take advantage. This condition could become the beginning of most of one’s knowledge base for autistic children: visual, haptic, tactile perception, body posture as well as verbal expression. It is of great interest, particularly when considering that nonverbal information is probably at the origin of what is arguably one of the trademarks of human cognition: the capacity to generate thoughts and concepts for ourselves and for the others, which can be verbally expressed. To better understand the base and the nature of the verbal expression we observed, future studies should extend this work through systematic analyses within a larger sample of autistic children in a follow up design. ACKNOWLEDGMENT The author would like to thank all the children who participated to the studies, their parents, ANR's supporting, as well as the French Department of Education. REFERENCES [1] I. Giannopulu, “Multimodal Human-Robot Interactions: the Neurorehabilitation of Severe Autistic Children,” Proceedings of the Sixth International Conference on Advances in Computer- Human Interactions (ACHI), IARIA, 2013, pp. 68-73. [2] L. Crane, S.E. Lind, and D.M. Bowler, “Remembering the past and imaging the future in autism spectrum disorder,” Memory, vol. 21, no. 2, pp. 157-166, 2013. [3] J.B. Plavnick and S.J. Ferreri, “Establish verbal repertoires in children with autism using function- based video medeling’’, J Appl Beh Analysis, vol. 44, pp. 747-766, 2011. [4] L. Jorde et al. “Complex segregation analysis of autism,” Am. J. Hum. Genet., vol. 49, pp. 932-938, 199]. [5] N.H. Sykes and J.A. Lamb, “Autism: The quest for the genes,” Exp. Mol. Med., vol. 9, pp. 1-15, 2007. [6] P. Szatmari et al. “Mapping autism risk loci using genetic linkage and chromosomal rearrangements,” Nat. Genet., vol. 39, pp. 319-328, 2007. [7] K.A. Pelphrey and E.J. Caster, “Charting the typical and atypical development of the social brain,” Dev. Psychopathol., vol. 20, pp. 1081-1102, 2008. rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ [8] B.A. Corbett et al. “A functional and structural study of emotion and face processing in children with autism,” Psych. Res., vol. 30, 173, pp. 196-205, 2009. [9] L. Brothers, “The social brain: a project for integrating primate behaviour and neurophysiology in a new domain,” Concepts. Neurosc., vol. 1, pp. 27— 51, 1990. [10] U. Frith and C.D. Frith, “Development and neurophysiology of mentalizing,’ Philos. Trans. R. Soc. London, vol. 358, pp. 459-473, 2003. [11] A. Saitovitch et al. “Social cognition and the superior temporal sulcus: Implications in autism,” Rev. Neurol. (Paris), 2012 Sep 13. pit: S0035-3787(12)00902-2. doi: 10.1016/j.neurol.2012.07.017. [12] R. Adolphs and D. Tranel, «Intact recognition of emotional prosody following amygdala damage,” Neuropsychol., vol. 37, pp. 1285-1292, 1999. [13] J.P. Aggleton, The Amygdala: A Functional Analysis. Oxford: University Press, 2000. [14] B.M. Nacewicz et al. “Amygdala Volume and Nonverbal Social Impairment in Adolescent and Adult Males with Autism,” Arch. Gen. Psychiatry., vol. 63, pp. 1417-1428, 2006. [15] U. Frith, J. Morton, and A.M. Leslie, "The cognitive basis of a biological disorder: autism,” TIN14, pp. 433-438, 1991. [16] A.M. Leslie, “Pretending and believing: issues in the theory of ToMM," Cognition, vol. 50, pp. 211-238, 1994. [17] T. Reed and C. Peterson, “ A comparative study of autistic subjects’ performance at two levels of visual and cognition perspecctive taking,” J. Autism. Dev. Disord., vol. 20, pp. 555-567, 1990. [18] A. Escalona, T. Field, J. Nadel, and B. Lundy, “Brief report: Imitation effects on children with autism,” J. Autism. Dev. Disord., vol. 32, pp. 141-144, 2002. [19] B.A. Taylor et al. “Manipulating establishing operations to promote initiations toward peers in children with autism,” Res. Dev. Disabil., vol. 26, pp. 385-392, 2005. [20] E. Williams, V. Reddy, and A. Costal, “Taking a closer look at functional play in children with autism,” J. Autism. Dev. Disord., vol. 31, pp. 67-77, 2001. [21] I. Giannopulu, “Contribution a la comprehension des representations multimodales chez l’homme sein et chez des patients avec atteinte neuropsychologique: une approche life span’. H.D.R, UPMC-Paris VI, 2011. [22] I. Giannopulu, “Multimodal interactions in typically and atypically developing children: natural vs. artificial environments”, Cogn Proc., vol. 14, pp. 323-331, 2013. [23] B. Scassellati, H. Admoni, and M. Mataric, “Robots for use in autism research,” An. Rev. Biomed. Eng., vol. 14, pp. 275-294, 2012. [24] M. Davis, B. Robins, K. Dautenhahn, C.L. Nehaniv, and S. Powell editors. “A comparison of interactive and robotic systems in therapy and education for children with autism,” European Conference for the Advancement of Assistive Technology in Europe (AAATE’05), pp. 353-357, September 6-9 2005, IOS Press Lille. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 221 [25] F. Michaud and S. Caron, “Roball, the rolling robot,” Auto. Rob., vol. 12, pp. 211-222, 2002. [26] K. Dautenhahn, “Socially intelligent robots: dimensions of human-robot interaction,” Philos. Trans. R. Soc., vol. B.362, pp. 679- 704, 2007. [27] B. Robins, K. Dautenhahn, and K. Dubowski, “Robots as Isoalators or Mediators for children with autism ? A Cautionary Tale,” Proc's of the AISB 05 Symposium on Robot Companions, pp. 82-88, 2005. [28] A. Duquette, F. Michaud, and H. Mercier, “Exploring the use of a mobile robot as an imitation agent with children with low- functioning autism,” Auto. Rob. — Special Issue., vol. 2, pp. 147-157, 2004. [29] F. Michaud, T. Salter, A. Duquette, and J.F. Laplante, “Perspectives on mobile robots used as tools for pediatric rehabilitation,” Assist. Technol., vol. 19, pp. 14-19, 2007. [30] H, Kozima, C Nakagawa, and Y. Yasuda, “Children- robot interaction: a pilot study in autism therapy,” Prog. Brain. Res., vol. 164, pp. 385-400, 2007. [31] J. Nadel, A. Revel, P. Andry, and P. Gaussier, “Toward communication: first imitations in infants, low-functioning children with autism and robots,” Inter St: Soc. Beh. Commun. Biol. Syst., vol. 5, pp. 45-54, 2004. [32] E.S. Kim, L.D. Berkovits, E.P. Bernier, D. Leyzberg, F. Shic, R. Paul, B. Scassellati, “Social Robots as Embedded Reinforcers of Socail Behavior in Children with autism,” J Autim Dev Disord, DOI 10.1007/ $10803-012-1645-2, 2012. [33] B. Scassellati, “Quantitative metrics of social response for autism Diagnosis,” [EEE International Conference on Intelligent Robots and Systems, pp. 1134-1138 vol.2, 2002. [34] K. Dautenhahn, and I. Werry, “A quantitative technique for analysing robot-human interactions,” IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1132-1138, 2002. [35] DSM-IV-TR Manuel diagnostique et statistique des troubles mentaux, Paris, Editions Masson, 2003. [36] E. Schopler, R.J. Reichler, R.F. De Vellis, and K. Daly, “Toward objective classification of childhood autism: Childhood Autism Rating Scale (CARS),” JADD10, pp. 91-103, 1980. [37] International Classification of Diseases, Revision, 10, 1990. [38] P. Planche E. Lemonnier, K. Moalic, C. Labous, and A. Lazartigues, “Les modalités de traitement de information chez les enfants autistes,” Ann. Med. Psychol., vol. 160, pp. 559-564, 2002. [39] J. Pedersen and J. Schelde, “Behavioral aspects of infantile autism: an ethological description”, Lur. Child. Adolesc. Psy., vol. 6, pp. 96-100, 1997. [40] M. Tacchetti, Elan Linguistic Annotator. The Language Archive MPI for psycholinguistics Niymegen, The Netherlands. 2006. [41] K. Dautenhahn and I. Werry, “Towards interactive robots in autism therapy,” P & CT, 121, pp. 1-35, 2004. [42] H. Kozima and H. Yano, Designing a robot for contingency- detection game. Working Notes rnational Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www. iariajournals.org/life_sciences/ Workshop Robotic & Virtual Interactive Systems in Autism Therapy, 2001 27-28 September, U.K.Hatfield. University of Hertfordshire, 2001, Technical Report No 364. [43] J. Martineau, S. Cochin, R. Magne, and C. Barthelemy, “Impaired cortical activation in autistic children: Is the mirror neuron system involved?” Jnt. J. Psychophysiol., vol. 68, pp. 35-40, 2008. [44] T. Salter, I.P. Werry, and F. Michaud, “Going into the wild in child-robot interaction studies-Issues in social robotic development,” /nt. J. Robot., vol. 1, pp. 93-98, 2007. [45] Y. Yokoyama, “The Possibility of the Psychiatric Treatment with a Robot as an Intervention From the Viewpoint of Animal Therapy,” Proc. of Joint 1st International Conference on Soft Computing and Intelligent Systems and 34 International Symposium on Advanced Intelligent Systems, paper number 23Q1-1, in CD-ROM Proc. 2002. [46] C. Kozima and Y. Yasuda, “Children-robot interaction: a pilot study in autism therapy,” Prog. Brain. Res., vol. 164, pp. 385-400, 2007. [47] I. Giannopulu and G. Pradel, Mobile toy robots can be used in autism therapy: an example of application. IEEE Proceedings in the IROS 2009 paper number SuT8.pdf in the workshop CD Proc. 2009a. [48] I. Giannopulu and G. Pradel, “Interactions multimodales en situation de jeu libre entre enfants autistes et un robot mobile”. 7" Journée Nationale de la recherche en Robotique, http:// jnrr09.lms.sp2mi.univ poitiers.fr/IMG/pdf/ Giannopulu_Pradel. Novembre, Domaine de La Grande Garenne 18330 Neuvy-sur- Barangeon, 2009b. [49] I. Giannopulu and G. Pradel, “Multimodal interactions in free game play of children with autism and a mobile robot,’ NeuroRehabilitation., vol. 27, pp. 305-311, 2010. [50] I. Giannopulu, “Cognitive and emotional interactions between autistic child, mobile toy robot and therapist,” Front Comput Neuro, doi:10.3389/ conf.fncom.2011.52.00002, 2011. [51] I. Giannopulu and G. Pradel, “From child-robot interaction to child-robot-therapist interaction: a case study in autism,” Appl Bio Biomech., vol 9, pp. 173-179, 2012. [52] I. Giannopulu “Embedded Multimodal Nonverbal and Verbal Interactions Between a Mobile Toy Robot and Autistic Children,” Late Breaking Paper, HRI 2013, Proceeding of the 8th ACM/IEEE International Conference on Human-robot Interaction, pp. 127-128, IEEE Press Piscataway, NJ. USA. [53] P.C. Quinn and P.D. Eimas, “The emergence of category representations during infancy: are separate perceptulal and conceptual processes required?” J. Cogn. Dev., vol. 1, pp. 55-61, 2000. 2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org 222 