Playful Interaction with Humanoid Robots for Social Development in Autistic Children: a Pilot Study Enric Cervera!, Angel P. del Pobil’ and Maria-Isabel Cabezudo? Abstract— Children with a diagnosis of Autism Spectrum Disorder (ASD) have serious difficulties in the development of their communicative and social skills. In recent years, robots have been tested in the therapy of autistic children as a promising tool for increasing their interest and motivation in the activities. In this paper we present the results of a pilot study with playful robot-child interaction developed for the therapy of diagnosed children aged between 3 and 5. The children were separated into an intervention and a control group. Their progress in development was measured before and after the intervention. Although the experience was unanimously considered as positive by parents and caregivers, we have found no significative differences between the intervention and control groups. Some observed trends demand more caution and additional studies for identifying not only the advantages but also the possible pitfalls of the use of robots in the therapy of autistic children. I. INTRODUCTION Difficulties in communicative and social interaction are the most notable characteristics among children with a diagnosis of Autism Spectrum Disorder (ASD). In many cases, those children do not look into other people’s face, they do not have communicative intention, they do not present behavior of joint attention, they have difficulties to distinguish non- verbal communication and they also have difficulties in the area of language development [1]. All these aspects result in serious difficulties in initiating and maintaining adequate communication, developing an adequate social interaction, imitating, and acting in collaboration with other children. These difficulties are caused by a dominant visual process over a weaker hearing process. This characteristic way of processing information makes children with ASD show greater interest in images and everything related to new technologies, which has led to the development of novel proposals for intervention in this field. Such is the case of using humanoid robots as supportive partners [2], [3], [4], since they can be a useful and effective tool in the intervention and development of the communication and social skills of children with ASD [5], [6]. The aim of this pilot study is to develop an ecologically valid scenario (i.e. usable in real situations) and analyze *The technological research for this article has been carried out in the Robotic Intelligence Laboratory. The support for this laboratory is provided, in part, by the Ministry of Economy and Competitiveness (DPI2015- 69041-R), Generalitat Valenciana (PROMETEOI/2014/028) and Universitat Jaume-I (UJI-B2018-74). ‘Enric Cervera and Angel P. del Pobil are with Robotic Intelligence Lab, Department of Computer Science and Engineering, Universitat Jaume-l, Castell6, Spain {ecervera, pobil}@uji.es 2 Maria-Isabel Cabezudo is with the Neurorehabilitation Unit of Manises Hospital, Valencia, Spain mcabezudo@hospitalmanises.es the effectiveness of the robot as a support for children with autism between 3 and 5 years, in a real environment, in learning semantic fields (clothes, transports, colors and animals) that had not yet been acquired by the children. Fig. 1. Agents involved in the activity: caregiver, child, and small humanoid robot. The robot is not replacing the caregiver, but it is a new agent involved in the interaction with the child (Fig. 1), attracting the interest in the child for a better involvement in the game and, therefore, in the development process. A. Related work Several studies have been carried out with the NAO robot on ASD children in recent years. Shamsuddin et al. [11] developed some simple HRI modules for testing with 5 children aged between 7 and 13. During the interaction, the robot does head-turn, blinks, talks, moves its arms, and finally plays a song. The total duration is about 14 minutes. To assess the children’s autistic characteristics, the team utilizes a behavior score sheet that is based on the Gilliam Autism Rating Scale-Second Edition (GARS-2). The GARS- 2 iS an autism screening tool developed to assist teachers, parents and other people who observe children to identify and diagnose autism [12]. According to their results, 4 out of the 5 children exhibited a decrease in autistic behavior (communication sub-scale) when the robot is executing HRI modules during the single session of child-robot interaction. In another study with the NAO robot by Tapus et al. [13], the aim was to investigate whether ASD children showed more social engagement when interacting with the NAO robot, compared to a human partner in a motor imitation task. Different behavioral criteria (gaze, free initiations, smile/laughter) were analyzed based on the video data of the interaction. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. Four ASD children aged from 2 years and 8 month to 6 years participated in the study, which took place over a 4- week period (two intervention sessions per day). The results of the study are mixed, showing some effect in some children on some variables and in others on other variables, but not in all four children. Their results indicate a high variability of reactions to the robot. Chevalier et al. [14] developed personalized social inter- action models with a NAO robot to enhance the social and communication skills of ASD persons. Their subject pool was formed by 7 adults and 6 children aged 9-13. Only a first HRI experiment was conducted, the interaction was to present the robot to the participants for a short duration, up to 2 minutes. They analyzed the video recording the participants gaze direction and gestures towards the robot. The children group had gaze direction more focused on NAO and switched less their gaze than the adult groups. They also had more social gestures toward the robot, such as waving back to NAO while it was presenting itself. Besides the description of the behaviors, there are no statistical results nor any long-term comparison of the effect of a therapy with humanoid robots. In a recent study by Sartorato et al. [15], a number of social robots used in therapeutic applications for ASD are reviewed, with a variety of capabilities and appearances, including the NAO humanoid. Particularly, children with ASD spend significantly more time looking at the NAO robot, and the robot was able to facilitate joint attention behaviors. They report a particular case study of a child with ASD, in which the boy avoided a human adult’s gaze but made eye contact readily and easily with NAO. They claim, and we fully agree with them, that studies tend to vary along a number of different dimensions (duration, sample size, qualitative vs. quantitative analysis), and long- term studies are needed to follow children’s progress. Il. METHODOLOGY For the design of the study, we interviewed the caregivers, and their feedback inspired the development of the scenario. They were also involved during the programming and testing of the robot applications. The applications were based on two visual games that were already played in the therapy sessions. First game is an expressive activity: the caregiver shows the child a card with the image of an animal, a vehicle, a cloth, or a vehicle; the child is asked about the name of the item. The second game is an understanding activity: the caregiver shows two cards to the child, one is the correct item, and the other is a different item from the same class. Then, the child is asked to point at the correct item as named by the caregiver. Figure 2 depicts the robot dialogues for both activities. Initially the robot greets the child and asks for a game of choice. Then it iterates for a set of cards, asking the child either the name of the item (expressive), or to point at the correct answer (understanding). An example with vehicles is “EXPRESSIVE GAME” INTERACTION “Hello <name>, how are you? y “What are we playing today?” “Great, | love vehicles!” Y “Which vehicle is it?” od incorrect / no answer “Very well!” “Which vehicle is it?” “That was all, | loved playing with you!” incorrect / no answer “UNDERSTANDING GAME” INTERACTION “Hello <name>, how are you? v “What are we playing today?” “Great, | love vehicles!” y > “Please point at the car / bike/...” ra incorrect / no answer “Very well!” “Please point at...” “That was all, | loved playing with you!” incorrect / no answer Fig. 2. Robot dialogues for the expressive (top) and understanding (bottom) games. shown, but the structure is similar for animals, colors, and clothes. When playing with animals or vehicles, the robot dia- logues are enriched with sound effects: the robot imitates the sound of the animal or the vehicle. The caregiver was in charge of handling the cards to the child. She also controlled the behavior of the robot, since there was no automatic voice recognition. The caregiver observed the child, and signaled the answer to the robot with a small remote command hidden in her hand. The command featured only two buttons for signaling either a correct or incorrect answer. The robot answered to the child according to this signal, as if it had recognized itself the action of the Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. child. The robot used in the sessions is a small humanoid robot, the NAO by Softbank Robotics (formerly Aldebaran Robotics) [7]. It is 57 cm high, and weighs only 4.5 kg, thus being adequate and safe for small children. It has 25 DOF, voice synthesis and recognition capabilities, and on-board vision processing. il. PILOT STUDY The actual therapy sessions were carried out during ten months, starting on March 2016 and ending in January 2017. The sample consisted of 14 children with ASD (5 in the control group and 9 in the intervention group) aged between 3 and 5, with similar level of cognitive development, with a diagnosis of ASD (according to the criteria of the DSM 5 and the ADOS-G scale [8]) and absence of language. The type of intervention that was carried out during the study was similar in all cases with a number of logo-therapy sessions (once per week). 1) Within the session, an intervention scenario was cre- ated for the group with the robot, in which a structured intervention was carried out, divided into two blocks of 15 minutes each (expressive and understanding, respectively) and working in four different semantic fields: colors, type of transport, clothes and animals (see Fig. 3). 2) The intervention of the control group was _ similar except for the robot support, i.e. the caregiver played the same game alone with the child. 3) The selection of participants in one group or another was random. 4) The actual duration of the pilot study was 10 months, measurements were taken at the beginning and end of the study, and data were analyzed. 5) Intergroup and intragroup analysis were performed and compared over time. 6) The variables were based on observation: two experi- enced professionals recorded the sessions and labeled the images when the children were watching, pointing, or uttering. IV. RESULTS The evolution of children was measured before and after the 10-month therapy. Measurements consisted of video recording and annotation during the interaction with the robot and caregiver (Table I, discussed in section IV-A), and a developmental index (Table I, discussed in section IV-B). A. Measurements of interaction The results indicate significant differences in gazing be- tween the control group and the group with the robot, yet those differences diminish with time: Fig. 4 (top) depicts in box plots the total number of gazes before and after the 10- month intervention, for the control (no robot) group, and the group using the robot in the therapy. It seems obvious that the robot attracted the attention of the child, and this impression is confirmed by the measurements Fig. 3. Robot scenario for the understanding game with animals: two cards are shown to the child, and the robot asks him to point at the requested item. of the targets of gazing. As seen in Fig 5 (top), the children in the robot-assisted group looked at the robot more than to the caregiver (therapist) who was present in the session. However, the results are not so positive for other mea- surements: the control group (without robot) exhibits better numbers in pointing (mid plots of Fig. 4) and uttering (bot- tom plots) than the group with the robot, and the difference slightly increases with time. It is also worth to mention that the difference of targets does not hold for utterances: children only utter slightly more towards the robot than towards the caregiver, as shown in Fig. 5 (bottom). In any case, the number of utterances is quite small, except for outliers, due to the fact that the children have not yet acquired language skills. B. Analysis of development The Battelle Developmental Inventory (BDI) [9] measures the progress of development for children through age seven, when they acquire skills and behaviors from simple to complex. It is based on a combination of sources such as observation of the child, and interviews with parents and caregivers. The BDI has been used as a screening tool to identify children with ASD, and the results can be used to determine treatment targets [10]. In this study, we have assessed the social, communication, and cognitive skill sets, before and after the intervention (Fig. 6), i.e. within an interval of ten months. Due to the small size of the population, the results are not statistically significant (non-parametric analysis yielded no difference between groups). However, some trends can be observed in the plots: for the cognitive domain (left column of Fig. 6), both the robot and control group behave similarly, with a slight increase with time. This behavior is compatible with a proper cognitive development, with increasing scores in skills like discrimination, memory, reasoning and concepts. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. TABLE I MEASUREMENTS OF GAZING, POINTING, AND UTTERING BEFORE AND AFTER THE 10-MONTH INTERVENTION. Participants Robot group Control group 1 2 3 4 5 6 7 8 9 1 2 3 4 5 Therapist 0 4 1 0 2 5 0 12 8 9 5 12 6 0 BEFORE Robot 2 15 11 16 10 10 14 9 15 0 0 0 0 0 NUMBEE OF may Total 2 A992 16 214A 22 28 Bd gazes Therapist 0 2 1 2 0 5 0 5 1 15 12 6 11 3 AFTER Robot 6 13 16 15 12 8 9 7 13 0 0 0 0 0 Total 6 15 17 17 12 13 9 12 14 15 12 6 11 3 Number of BEFORE 0 8 3 16 1 2 1 12 4 13 2 19 8 11 pointings AFTER 3 16 2 20 18 1 4 5 17 15 20 19 12 12 Therapist 0 0 0 0 0 1 1 8 0 12 1 16 0 16 BEFORE Robot 1 13 0 16 1 0 1 0 0 0 0 0 0 0 NUMBEE OF nan ee a ee ee ae utterances Therapist 0 0 0 0 0 1 0 4 0 20 19 21 1 11 AFTER Robot 0 16 0 18 3 0 0 1 0 0 0 0 0 0 Total 0 16 0 18 3 1 0 5 0 20 19 21 1 11 TABLE II BDI RESULTS BEFORE AND AFTER THE 10-MONTH INTERVENTION. Participants Robot group Control group 1 2 3 4 5 6 7 8 9 1 2 3 4 5 Discrimination 27 27 27 27 27 27 27 27 27 68 32 27 27 27 7 Memory 27 27 #27 «+27 «+27 «27 = « 27:~«27)~« 62706 627) 687) (O27) OTs ante Reasoning 39 27 #27 «+27 «27 «27 ~«270~«027)06 (27) 6 389)06~(627)0 (27) 27839 Concepts 27 27 #27 «+27 «27 + « 27~«27)~«627)06 627) 627) (27) 2727857 uunnanne Total A ee er eT eT AT AT AT AT BB AT AT AT aT B Interaction w. adults 27 27 27 27 27 27 27 27 27 27 27 27 27 27 E Expression of feelings 27 27 27 27 27 27 27 27 27 27 27 27 27 27 5 Self-concepts 27 27 27 27 27 27 27 27 27 29 27 27 27 27 R Social Domain Interaction w. partners 27 27 27 27 27 27 27 27 27 35 27 27 27 27 = Collaboration 27 27 27 27 34 27 27 27 27 40 34 $j. 27 27 Social role 27 27 27 #27 «27 27 = « 27)~«27)0~ 627) 627) (27) 27) 27s nnn Total A ee er eT aT aT AT AT AT AT AT AT AT aT oo. Reception 27 27 27 27 27 27 27 27 27 27 27 27 27 27 commmunicalve Expression 27 27 27 «+27 «+27 «27 >= « 27~ «27 )~6«627)~6 627) (27) 27) 27s ons a a Discrimination 27. 34 27 «27 «46 «27 0«6340634060=Cia27 6si“CiTtti‘ tCTté« A 7 Memory 27 27 +27 «+27 «+27 «27 « ©840638406U2706 68106C«27~—s—i isi woanive Reasoning 27 27 +27 +31 32 #27 +«39:«#239:«©27 06 «63606(l27 56) «(U27:) «(C58 Concepts 27 27 27 34 31 27 27 36 27 40 27 53 27 50 suntan Total AE ee er eT 27 27 BL a7 27 86 27 AO 27 A A Interactionw.adults 27 27 £27 £4227 427 427 27 27 27 = =©270— 627) 663 lh 7 FE Expression of feelings 27 27 27 27 27 27 27 27 27 27 27 48 27 27 T Self-concepts 27 27 27 #27 «27 «27 « 27)~« «270602706 627) (27) 4827s E Social Domain Interaction w. partners 27 27 27 27 27 27 27 27 27 27 27 41 27 27 R Collaboration 27 27 27 27 27 27 27 27 27 27 27 34 27 48 Social role 27 27 +27 «+27 «27 +« 27~«227)~6«627)06 627) (27) 27) B832s—i2T~s—sio8 “couse Total AE 2 er 27 AT AT AT 27 AT AT 27 AL 27 27 i Reception 27. 27 27 27 «27 #« 27~«627)06(27)0 (27) 629)6(lU27) «64802738 communicaive Expression 27 27 27 «+27 «+27 «27 ~« 270~« «2270627 6420627) (81COTséi oman Total 27 -27«27)27-siTsisi sisi Ti s“‘i TT! 8B OTD Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. After Before a ao Ow ol cr a —_ Tm a — fal ——— a I So So - 2 =) = = = (Ee .n | a l I P —_L iT [ae a oa ao Ol ol ——— i ae) i 3) i = suuaguu ees l uo c Tf . - . —~ a oo = —_ ae) = = LT e mam «i Wo °° Ke a — oS S SS oY | ie) o x ——_—_. c uw un Gy TT oe = = = . - = = Bs} E = — in ua to oO _ a qj no robot robot no robot robot Fig. 4. Measurements of gazing, pointing, and uttering before and after the 10-month intervention, for the control group and robot group (left and right boxes respectively, on each axes). Before Ll Leo : || a i 62 o baa _- ; ™ cs) Fy a=} E Lil Le 2 0 =) = wi 8 Ww wn - = 1 = fs ha PS a = = _ _ [= o a uu aa} E ow wn = rs o |W Co o Therapist Robot Therapist Robot Fig. 5. Gazing and utterances before and after the 10-month intervention to caregiver (therapist) and robot (left and right boxes on each axes). Yet in the communicative and social domains, the robot group shows mostly no variation before and after the in- tervention (Fig. 6, middle and right). In the control group, with less children, a few of them show changing values. As mentioned before, social and communication are hard challenges for ASD children: in these domains, expression and reception skills were measured in the communicative domain, and collaboration, interaction, and expression of feelings were considered, among others, in the social domain. Although the numbers are not statistically significant due to the small population, it is somewhat shocking to see zero progress in the robot group, in contrast with the control group (without robot), as if the interaction with the robot actually inhibited the development of those skills. V. CONCLUSIONS According to the literature, robots have shown to generate a number of behavioral benefits in children with ASD, e.g. engagement, increased attention, and decreased social anxiety. In our study, the use of a supportive robot in interventions with young children with autism is positive in some attitudes, e.g. gazing, since they observe more than the control group. But robot-child interaction could be less effective in other aspects like pointing and uttering. The richer interaction with a human caregiver could possibly increase the response of the child in these cases. Therefore, there is no evidence yet that social robots enhance social skills and communication of ASD children, when compared to traditional therapy with a human care- giver. However, more trials are needed in a larger population to confirm the obtained results. ACKNOWLEDGMENT The authors thank Maria-Jesus Lluch, Celia Tena, Carmen Clemente, Maria Motos, Virginia Perez, and the rest of the therapist team of the Child Neurorehabilitation Unit of the Manises Hospital for their work in this pilot study. REFERENCES [1] P. Menyuk and K. Quill, “Semantic problems in autistic children,” in Communication Problems in Autism. Springer, 1985, pp. 127-145. [2] L. Boccanfuso and J. M. O’Kane, “CHARLIE: An adaptive robot design with hand and face tracking for use in autism therapy,’ International Journal of Social Robotics, vol. 3, no. 4, pp. 337-347, 2011. [3] J.-J. Cabibihan, H. Javed, M. Ang, and S. M. Aljunied, “Why robots? a survey on the roles and benefits of social robots in the therapy of children with autism,” [International Journal of Social Robotics, vol. 5, no. 4, pp. 593-618, 2013. [4] K. Dautenhahn and I. Werry, “Towards interactive robots in autism therapy: Background, motivation and challenges,” Pragmatics & Cog- nition, vol. 12, no. 1, pp. 1-35, 2004. [5] B. Scassellati, “How social robots will help us to diagnose, treat, and understand autism,’ in Robotics Research. Springer, 2007, pp. 552- 563. [6] Z. E. Warren, Z. Zheng, A. R. Swanson, E. Bekele, L. Zhang, J. A. Crittendon, A. F. Weitlauf, and N. Sarkar, “Can robotic interaction improve joint attention skills?” Journal of Autism and Developmental Disorders, vol. 45, no. 11, pp. 3726-3734, 2015. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. Discrimination Concepts Reasoning Total Cognitive =) ° ct ° Pat No robot Beeenea OO~rIMUCoNn— Reception 28 30 32 34 36 38 40 28 30 32 34 36 38 40 Expression 30 35 40 45 50 £55 30 35 40 45 50 £55 Total Communicative io Before No robot Interaction with adults Expression of feelings a, 3 8 8 z ¢g 8 3 x t=] nN mM 3 oo o 28s s — 8 a Fig. 6. for cognitive, communicative, and social domains. [7] [8] [9] [10] [11] D. Gouaillier, V. Hugel, P. Blazevic, C. Kilner, J. Monceaux, P. Lafour- cade, B. Marnier, J. Serre, and B. Maisonnier, “Mechatronic design of NAO humanoid,” in Robotics and Automation, 2009. ICRA’09. [EEE International Conference on. WEEE, 2009, pp. 769-774. J. L. Matson and R. L. Goldin, “Diagnosing young children with autism,” Jnternational Journal of Developmental Neuroscience, vol. 39, pp. 44-48, 2014. J. Newborg, J. Stock, L. Wnek, J. Guildubaldi, and J. Svinicki, “Battelle developmental inventory with recalibrated technical data and norms: Examiner’s manual,” Allen, TX: DLM, LINC Associates, 1984. M. Sipes, J. L. Matson, and N. Turygin, “The use of the Battelle De- velopmental Inventory — Second Edition (BDI-2) as an early screener for autism spectrum disorders,’ Developmental Neurorehabilitation, vol. 14, no. 5, pp. 310-314, 2011. S. Shamsuddin, H. Yussof, L. I. Ismail, S. Mohamed, F. A. Hanapiah, and N. I. Zahari, “Humanoid robot nao interacting with autistic chil- dren of moderately impaired intelligence to augment communication [12] [13] [14] [15] Collaboration 0 8 4 4 0 8S 40 4 Total Social 28 30 32 34 36 38 40 27 2&2 © HM NH # 28 30 32 34 36 38 40 27 2B BW WH H PR ° Before BDI results for the children of the robot group (9 individuals) and the control group (no robot, 5 individuals) before and after the intervention, skills,’ Procedia Engineering, vol. 41, pp. 1533-1538, 2012. J. M. Montgomery, B. Newton, and C. Smith, “Test review: Gilliam, j.(2006). gars-2: Gilliam autism rating scale—second edition. austin, tx: Pro-ed,’” Journal of Psychoeducational Assessment, vol. 26, no. 4, pp. 395-401, 2008. A. Tapus, A. Peca, A. Aly, C. Pop, L. Jisa, S. Pintea, A. S. Rusu, and D. O. David, “Children with autism social engagement in interaction with NAO, an imitative robot: A series of single case experiments,” Interaction studies, vol. 13, no. 3, pp. 315-347, 2012. P. Chevalier, B. Isableu, J.-C. Martin, and A. Tapus, “Individuals with autism: Analysis of the first interaction with NAO robot based on their proprioceptive and kinematic profiles,’ in Advances in robot design and intelligent control. Springer, 2016, pp. 225-233. F. Sartorato, L. Przybylowski, and D. K. Sarko, “Improving therapeutic outcomes in autism spectrum disorders: Enhancing social communi- cation and sensory processing through the use of interactive robots,” Journal of psychiatric research, vol. 90, pp. 1-11, 2017. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 17:48:29 UTC from IEEE Xplore. Restrictions apply. 