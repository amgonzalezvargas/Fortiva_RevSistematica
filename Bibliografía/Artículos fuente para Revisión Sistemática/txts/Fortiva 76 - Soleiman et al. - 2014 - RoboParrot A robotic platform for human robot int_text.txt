Proceeding of the 2nd RSI/ISM International Conference on Robotics and Mechatronic: October 15-17, 2014, Tehran, Iran RoboParrot: A Robotic Platform for Human Robot Interaction, case of Autistic Children Pegah Soleiman', Sohail Salehi', Maryam Mahmoudi*, Morteza Ghavami*, Hadi Moradi', Hamidreza Pouretemad* ' Advanced Robotics and Intelligent Systems Laboratory, CIPCE, School of ECE, College of Engineering, University of Tehran *Social Networks Laboratory, School of ECE, College of Engineering, University of Tehran 3Department of Psychology, Allameh Tabatabai University “School of Psychology, Shahid Beheshti University, Tehran, Iran Pgh.soleirman@ut.ac.ir, Sohail.uv@gmail.com, mahmoody_m@alumni.ut.ac.ir,m.ghavami@ut.ac.ir, moradih@ut.ac.ir, h- pouretemad@sbu.ac.ir Abstract—This paper presents a robotic platform suitable for Human-Robot Interactions (HRI), with focus on_ verbal interactions. It is obvious that interactive and social skills are two indispensable requirements in many application areas where robots and humans need to interact with each _ other. Consequently, we have developed a cognitive robot companion, L.e. a parrot like robot, with main focus on verbal interaction with humans. A possible educational or therapeutic aspects of this robot for children who suffer from Autism Spectrum Disorders (ASD) have been considered. In other words the robot is designed intended to comfort and emotionally interact with autistic children. Different types of functionalities are introduced and discussed in the light of their potential investigation in human- robot experiments. The platform is intended for research in other HRI applications, such as concept learning and robotainment. The initial results show the attractiveness of the designed robot for humans and its great potential for success in using this platform for rehabilitation in social interaction, edutainment and entertainment. Keywords—Autism Spectrum Disorders; Robot-Assisted Therapy; Human-Robot Interaction; Social Intelligence I. INTRODUCTION Throughout the years social robots have been introduced and developed in order to ease Human-Robot Interaction (HRI). These robots are being designed to interact with human beings in order to satisfy certain social needs. From a wide variety of applications, recently, social robots have been used in the applications related to Robot-Assisted Therapy (RAT). One of the utilizations of robots in RAT is Autism Therapy [1]-[2]. Autism spectrum disorder is a neurodevelopmental disorder characterized by three main deficits in social interaction, verbal and non-verbal communication, and unusual restricted, repetitive and stereotyped patterns of behaviors [3]. The concept of using robots for autism therapy comes from the fact that robots are non-threatening [4], adaptable devices, and they can perform predictable acts along with making specific sounds. Considering that normal therapy is time consuming and labor extensive, robots, as companions, can help therapists and reduce 978-1-4799-6743-8/14/$31.00 ©2014 IEEE Fig. 1. The RoboParrot the load on the therapist that can increase the performance. Furthermore, these robots can be used at homes to help the parents work with their autistic children. A critical capability in human development and social interaction 1s communication. Impairments in communication can generate difficulties in conversation with others and consequently, this can lead to disruptions in the process of learning [5]. In particular, the voice-based communication is approximately one-third to one-half of autistic individuals does not develop normally. As a result they cannot deal with problems in order to meet routine affairs [6]. Those autistic individuals who reveal difficulties in speech, may show fluctuation in tone and pitch or may demonstrate repetitive and stereotyping pattern in their speech [7]. Since robots are interesting and can help autistic children to engage in a simple social interaction while not being threatened [8], we decided to study the idea of using robots to improve autistic children’s social and verbal abilities. It should be also 711 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. mentioned that we have used an animal like robot since autistic children tend to interact with animals much better than humans. Furthermore, we have chosen parrot, as the animal of interest, since it is famous for its verbal abilities that can be attractive and useful for teaching verbal communication to autistic children. In this paper, we report the novel design of a parrot-like robot (Fig. 1) which can be used for imitating games, directing attention and other useful tasks that will be discussed in the Methodology and Approach section. The robot has been designed, implemented, and tested. It has been tested on a few autistic children to get their response to the robot. This novel design allows the researchers to use this platform beyond the autism screening and therapy. It can be used to test concept learning in human-robot interaction. Furthermore, it can be used as an entertainment platform. This design 1s one of the few designs inspired from birds. ll. RELATED WORK Today, HRI is a new and attractive concept in autism therapy [9]. Recently intelligent robots have been used to improve social and interactive skills of autistic children [9]. In autism therapy the focus is to improve imitative game playing, overall use of language, social behavior, concentration, and turn-taking skill [10]-[11]. Some of these robots focus on face tracking such as CHARLIE [12] and Keepon [13]. Autistic children are mostly impaired to follow the gaze and direction of activities. Robins et al. [14] developed a humanoid robotic doll called Robota that uses a tele-operate mode and works as a dancing toy. This robot provides fun movements for autistic children with the purpose of developing their joint attentional skills. This will work with the need to share the interest with others. Researchers have also worked on Robot-assisted therapy (RAT) to improve the effectiveness of treatment for children who has ASD. Robota and the humanoid robot made by Mataric’s research group at USC [15] explored specific therapeutic issues for improving social interactions of autistic children by activities such as imitating games. It is believed that the eye contact is an important item in social behavior. To investigate the response time in the eye contact of autistic children with humanoid robot NAO, Cabibihan et al. [16] use NAO to improve the eye contact duration of children with a humanoid robot. In another simpler use of NAO in RAT [17], the humanoid robot repeats a hand movement and meanwhile plays a song. The initial response of autistic children stereotyped behavior is observed and clinically evaluated. Ul. THE ROBOPARROT PLATFORM Our RoboParrot is based on a toy from Hasbro Toy Company. To control the robot, a hardware is added to provide the communication between the robot and the computer. All the motors and sensors are controlled through this controller. A user interface 1s developed which provides the needed tools for an operator to control the robot. RoboParrot is designed such that it can be controlled by a remote operator, who can be an autism expert if the robot is used for autism therapy. The control system and the user interface has been designed such that the operator can see an autistic child through the camera and interact with him/her verbally or by wee ee em em ew em ee eee ee er KK Ks | Body Motor | Head Motor IR Sensor f Touch Sensor | Microphone I I ] I I ] I I I I I i | | Microcontroller Hardware | I I ] I I I I I | I I ] I I Body, Head, Wings, Beak, Eyelids, Microphone, Speaker Fig. 2. The RoboParrot schematics platform. The blue and the green blocks were added to the original toy and in the pink blocks the touch sensor, microphone and speaker were upgraded. A. Mechanical and Electronic System This robot composed of two main mechanical motors that are used to control the motions of the whole body and the head (Fig. 3). The body motor controls the motion of the wings, the legs, and the neck. The head motor controls the motions of the eyes and the beak of the RoboParrot (Fig. 4). Our robot 1s capable of closing and opening its eyelids, beak, and wings. Also it can First position Move to the first position Move to the right ,: ‘ Move to the | Close the wings ° 4 Open the wings », Move the head down Move the head up Fig. 3. A sequence of the robot body movements that start from a start position 712 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. Counterclockwise movement of motor Clockwise movement of motor Fig. 4. Closing-opening the eyelids with clockwise movement of the head motor (right) - Closing-opening the beak with counterclockwise movement of the head motor (left) move its body in three directions and its neck back and forth or left and right. The RoboParrot has a few sensors such as a microphone, an IR-sensor, and a Hall effect sensor in its beak that allows the robot to detect the closeness of a hand on his head and beak. The IR-sensor on its chest would allow to sense if a person tries to touch his chest. A speaker is also mounted in the robot that allows the operator to communicate with others through it. To make the robot look more in a natural setup, it is placed inside a cage that will provide us a space to place our controller hardware and it will also protect the robot from being harmed by children (Fig. 5). We have placed a webcam on the cage so the operator can see what happens and how a child reacts. Furthermore, the images can be stored for further analysis such as face recognition, and mood and emotion analysis. B. Hardware Control system consists of hardware microcontroller board and software Graphical User Interface (GUI). Since there are not much room in the robot’s body to place extra control board, the hardware is broken into two part to be able to place the necessary header board inside of the robot and the main microprocessor controller (Fig. 6). A wooden base was built under the robot for embedding the main board and induce the beauty and naturalness of the robot (Fig. 7). Currently our robot has only the tele-operated mode. However, our final design will be able to operate in both remote- operated mode and autonomous mode. In remote- operated mode an autism therapist will control the system from a personal computer (PC). Fig. 5. RoboParrot is very attractive which attracts the attention of normal kids too. The socket connected to the robot’s internal board Motor driver Serial connection Fig. 6. The components of the main controller board of the robot The overall specification of the robot is given in Table I. TABLE I. HARDWARE AND SOFTWARE FEATURES OF ROBOPARROT Height 50 cm Width 10 cm Degree of freedom Actuators Microcontroller Sensors Power supply Softwares Accessories Opening-closing the wings (about 15 degree), moving head up and down, moving body left and right, opening-closing the eyelids and the beak Two DC motors, geras, shaft encoder Atmegal6 Touch, IR, switches 5V,0.4A OS: Windows 7, visual C# (GUI), serial port (RS232—9600 baudrate), matlab (voice morphing) Speaker, microphone, webcam, video camera Fig. 7. Embedded Hardware Package Placement underneath of the robot 713 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. Fig. 8. The RoboParrot User Interface. The top-left boxes are the control for the body and head motors. The top-middle box, with the parrot head, shows the states of the robot’s eye and beak. The top-right box is the camera view. The bottom-left gauge shows the sounds level. The bottom- middle box are different songs that can be played for a child. The bottom- right box are specific controls that the operator can select such as moving left or right and opening-closing wings C. Robot Software a) Graphical User Interface: A user friendly software interface (Fig. 8) 1s designed for communication between the PC and the controller hardware in order to send commands to the robot and receive data from camera, sensors, microphone, and motors. This interface provides several functionalities such as the robot movements, the camera view and playing three different childish sounds. The camera shows the child’s behavior and the operator can observe these behaviors and use the GUI to give appropriate orders to the robot. In this operation mode therapist can use the microphone and speaker in order to interact with the child. To ensure the operator that the correct command is sent to the robot and check the validity of the robot’s functionality, the interface shows the RoboParrot’s State. b) Voice Morphing: In order to make the robot more realistic and attractive to children, the operator’s voice is filtered and changed to become closer to a parrot’s voice. In other words, the pitch of the voice is changed to get closer to the pitch of a parrot’s voice. IV. HUMANAN-ROBOT INTERACTION SCENARIO WITH AUTISTIC CHILDREN In this section we have presented our method that we considered to test the effectiveness of the robot. Thus the samples, the scenarios, and the results are presented briefly. Sample. We observed 5 children including three autistic children (N=3; age average 3.6) and two normal children (N=2, age average, 3.7). Scenario. The sessions were designed unstructured to let the subject be on their own, and it allows becoming familiar with interaction between child and the robot without any previous design. Each session lasted for about 8 to 12 minutes in which the subject was accompanied with his/her parent(s). The subjects only interacted with the robot in a single session and parents were told that this procedure is an experiment in order to study the interaction of their children with the robot. We informed parents that they should not tell their children that they are participating in an experiment and they should not comment on their children’s acts. They could only encourage their children whenever they received a request from the remote operator. Each child with his or her mother entered the experiment room, which was a typical therapy room in the clinic that they were treated. The robot’s interaction scenario 1s set as follows: First, the robot is silent for few second, and then the scenario randomly runs, that 1s, first in some cases motor stimulus run, and in other cases, auditory ones. Being fixed and silence position in the robot at the beginning of the scenario was because of that robot’s apparent attractiveness was characterized for children. In addition, randomly presentation order of stimulus was due to children’s reaction were not influenced by order of stimulus presentation. In addition, most robots that have been built so far, usually were dependent to motor features, while, verbal communication is a special feature which considered in this robot, because a main feature in autism is language impairment. Thus, operator runs a few movements of the robot, such as blinking, flounder, and opening-closing the robot’s beak, shaking the robot’s body as well. Next, music was played through the robot’s speakers. After that, the robot initiated a communication by using words such as salute, calling the name of each child and involving in a dyadic communication and asking about the play and interest of child. If the child did not want to cooperate or neglected the robot, a third person (caregiver) had to encourage the child to communicate with the robot. Finally, the robot appreciated the child and asked him or her whether he or she wanted to play with him again, and if the answer was no the robot said goodbye. With comparison of two groups of autism and normal, we found different interaction that is described in the following paragraphs. V. PRILIMINARY RESULTS In this section we have presented the findings by comparing children in the same age group. The severity of autism in these children can be categorized into very mild and mild according to Gilliam Autism rating scale (GARS) scores. It should be stated that all these children showed awareness to the presence of the robot; even for a few seconds. All of them looked at the robot, however, they have had differences in maintaining their attention to focus on the robot and its behaviors. These considerations are described in details in the following sections. Autistic children A 2.7-year-old child: when music was played, the child did not pay much attention to the robot, even he stood in the opposite direction to the robot. When the music was paused, child turned around and stood toward the robot, and then with initialization of the movements, the child was more attracted to the robot. When the robot blinked, the child looked at the robot, smiled, and stopped walking for a few seconds and kept on looking at the robot with a sense of happiness. During the session, the child kept a distance (about 1.5 meters) from the robot and did not get very close to the robot and he was around 714 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. her mother and next to a chair. When the robot initiated verbal communication, by saying hello, the child glimpsed at the robot. In response to the vocalizations of robot, using parrot-like sounds, calling the child, and asking him a few questions about playing and his interest to this robot. The child then expressed stereotyping vocalization and sometime it seemed that the child wants to imitate the robots actions. For example the child tried to express words that their tome was the same as what the robot was expressing. This point may be indicating that in autistic children there are tendencies to communicate, however, they have problems in finding the appropriate way in order to communicate. In addition, it should be noted that this child had a poor development of language skills, and this factor may cause poor verbal communication or stereotyping vocalization. In sum, for this 2-year-old autistic child, 1t seemed that the speech and movements of the robot were more attractive than musical feature of the robot. A 5.9-year-old child: he entered the room, immediately said hello to the robot, the robot responded to the child immediately after the child’s greeting. After that the child was walking around the room, while occasionally glimpsing at the robot. When the robot performed an action that was a movement, the child saw the action and became so anxious and he left the experiment room. It was probably due to the way this scenario ran. With regard to the child’s early greeting which was to initiate a communication, the scenario began very faster than the pace which the child could deal with. The scenario started with two different presentations (speech and movement) of the robot one after another in the short period of time. In addition, his parent explained that he had shown the same reaction due to an experience with a natural parrot. His parents described that once he wanted to take a picture with a big parrot, the parrot had moved suddenly, and its movement has scared their child. Additional observation cannot be provided because the child left the room early. A 2.6-year-old child: at first, he did not approach the robot, but when he was encouraged by his mother for interaction with robot, he went near the cage. Then after the robot started talking, the child laughed and emotionally taped the cage, and again laughed loudly after each of the robot’s actions. This child could not speak, and already this child was shown no vocalization, whereas in response to the robot’s verbal actions, child began to vocalize. This was interesting and amazing for his parent, because it was for the first time the boy started vocalization. Normal siblings of autistic children A 2.6-year-old child: This child showed various reactions and playful interactions. He approached the robot and looked at it. Some features of the robot were funny for him. He responded to the communication that was initiated by the robot by answering to its questions. He responded to the robot when it was calling his name. When the robot asked child a wrong question, he repeated the question and then he laughed. After that, he decided to annoy the robot, then turned on a fan, which was in the room, and put it toward the parrot-like robot and again started to laugh. He moved the cage and frapped it for several times while he was laughing. This child during the session was moving and walking during the session, but showed little attention to his father. He felt comfortable and secure. In addition, he was attracted more to speech feature of the robot rather than its movements (unlike autistic children). A 5-year-old child: This child looked at the robot and was fully attracted to the robot’s behaviors. With presentation of each factor in the scenario, the child reacted joyfully and showed referential look and shared attention to her mother. At first the child showed inhibitory behaviors for approach or responded verbally to the robot, but as the time passed and after that her mother prompted her, she started to communicate with the robot. This child remained near her mother. She pointed at the robot’s eyes and said that its eyes sounds like a camera that takes a picture, it 1s not alive! (Because when the robot blinked, it was generating a sound that was similar to the shutter sound that we hear while we take a picture with a camera). The robot was attractive for the child and she spent time with it in a happy mood, but finally, when the robot asked her if she likes to play with the robot or whether she likes to play with a doll, the girl’s response was doll. This point maybe shows that the robot needs to be more attractive and it needs more variety in its actions, stimulus and programs in order to be more popular among normal children. VI. CONCLUSION AND FEATURE WORK This research demonstrates the development of an attractive and friendly social robot platform that can be used in robot- assisted autism screening and therapy. Currently the robot prototype 1s ready to be used for clinical trials. In this research, we focused on the issue of predictability of humans’ behavior in response to the robot’s actions, which is the advantage of using robots for therapeutic interactions compared to humans. In the case of the autistic children, the predictability is particularly challenging since it is not possible to rely on anthropomorphism and empathic responses which usually can make a robot interesting in the eyes of observers. Since it 1s necessary to find out acceptability of the robot among autistic children, and even among normal children, we investigated the primary child-robot interaction in a few cases, which include both normal and autistic children. The two groups, 1.e. normal and autistic children, showed interest in the robot, but the few tested autistic children hesitated to approach the robot and needed to be encouraged by their parents. However, when they were accompanied by their parent(s), they showed more interaction with the robot, but still with limited behavioral repertoire and varieties. The normal children engaged in triadic relation, i.e. child-parent-robot relation, as children engaged their parent(s) in their new experience when they saw the robot. This behavior was never seen in the autism group. One of the designed restrictions that we had in these tests was the placement of the robot in its cage. It was intentional and planned to avoid the robot being damaged by autistic children. Consequently, it was impossible for the children to communicate with the robot physically. In contrast, since the robot was safe in the cage, the children could have a very close 715 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. interaction with it which is normally not allows in the interaction with other robots used in similar studies. Furthermore, since all of the autistic children are dependent to visual processing the cage was placed on a desk to make it easy for the children to access the robot and visually inspect it at a very close distance. It should be mentioned that we do not intend to replace the human therapists by robots in a short term. Our goal is to develop complementary system to help therapists to teach autistic children. The reported observation and tests would be used to design the appropriate program for communication in autism group. For our future work, we would consider the following areas. As mentioned by the past researches, it 1s better to use structured scenarios [18]. Our work was an unstructured one, because this work was the primary study to gain more experience in HRI without any prejudices. We also tend to do more tests and increase our sample size so that the comparison between autistic and normal people become more reliable. Additional comparison is needed among preferences of autistic and normal groups toward verbal or motor stimulus, as well as between autistic children with high and low functions in the items. Finally, the platform should be fully developed based on the results gathered from the trials. Furthermore, the outcome of the trials will also help us to explore the role of the robot as a mediator. The final prototype will have more applications such as autonomous operating mode and diagnosis of autism based on voice processing. In autonomous operating mode, the robot will perform operations such as giving predefined orders to the child and observe the child’s behavior to see whether the child has obeyed the order or not. Having more cameras in the robot’s eyes and analyzing the video streams can help in the evaluation of the eye contacts and the general affects of the children. REFERENCES [1] J. A. Atherton, and M. A. Goodrich, “Supporting Clinicians in Robot- Assisted Therapy for Autism Spectrum Disorder: Creating and Editing Robot Animations with Full-Body Motion Tracking” In Human-Robot Interaction: Perspectives and Contributions to Robotics From the Human Sciences Workshop at Robotics Science And Systems. June 2011. [2] B. Robins, K. Dautenhahn & P. Dickerson, “From Isolation to Communication: A Case Study Evaluation of Robot Assisted Play for Children with Autism with a Minimally Expressive Humanoid Robot” IEEE computer society, Second International Conferences on Advances in Computer-Human Interactions. 2009. [3] American Psychiatric Association, “Diagnostic and statistical manual of mental disorders (4th Ed.)” Washington, DC: American Psychiatric Association. (Text revision). 2000. [4] L. Dickstein-Fischer, E. Alexander, X. Yan, H, Su, K, Harrington, & G. S. Fischer, “An affordable compact humanoid robot for autism spectrum disorder interventions in children. 33rd Annual International Conference of the IEEE EMBS. Boston, Massachusetts USA, August 30 - September 3, 2011. [5] D. C. Llaneza, S. V. DeLuke, M. Batista, J. N. Crawley, K. V. Christodulu, & C. A. Frye, “Communication, interventions, and scientific advances in autism,” A commentary, Physiology & Behavior, 100, 268— 276, 2010. [6] I. Noens, I. Van Berckelaer-Onnes, R. Verpoorten, andG. Van Duin, “The ComFor: an instrument for the indication of augmentative communication in people with autism and intellectual disability” J [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] A. Cashin, andP. Barker, “The triad of impairment in autism revisited,” Journal of Child and Adolescent Psychiatric Nursing, 22 (4):189-193, 2009. B. Scassellati, H. Admoni, & M. Mataric, “Robots for Use in Autism Research,” Annu. Rev. Biomed. Eng, 14:275—94, 2012. E. S. Kim, R. Paul, F. Shic, and B. Scassellat, “Bridging the Research Gap: Making HRI Useful to Individuals with Autism,” Journal of Human- Robot Interaction | (1):26-54, 2012. G. Pioggial, M. L. Sical, M. Ferro, R. Igliozzi, F. Muratori, A. Ahluwalial, and D. De Rossi, “Human-Robot Interaction in Autism: FACE, an Android-based Social Therapy,”. 16th IEEE International Conference on Robot & Human Interactive Communication, 2007. K. Dautenhahn,, I. Werry, “Issues of Robot-Human Interaction Dynamics in the Rehabilitation of Children with Autism,” Proc. From animals to animates, the sixth international conference on the simulation of adaptive behavior (SAB2000), 519-528, 11-15 septamber, Paris, France, 2000. L. Boccanfuso, J. M. O’Kane, “CHARLIE: An Adaptive Robot Design with Hand and Face Tracking for Use in Autism Therapy,” Int J Soc Robot, 3:337—347, 2011. doi: 10.1007/s12369-011-0110-2. H. Kozima, PM. . Michalowski, C. Nakagawa, “Keepon A Playful Robot for Research, Therapy, and Entertainment,” Int J Soc Robot, 1: 3-18, 2009. doi 10.1007/s12369-008-0009-8. B. Robins, K. Dautenhahn,, R. Te Boekhorst, A. Billard, “Robotic assistants in therapy and education of children with autism:can a small humanoid robot help encourage social interaction skills?,” Univ Access Inf Soc, 4: 105-120. , 2005. doi 10.1007/s10209-005-01 16-3. D. Feil-Seifer and M. MataricO, “Robot-assisted therapy for children with Autism Spectrum Disorders,” In :Proc. IDC '08 Proceedings of the 7th international conference on Interaction design and children, pp 49-52, 2008. doi 10.1145/1463689.1463716. L. Idzhar Ismail, S. Shamsudin, H. Yussof, F. Akhtar Hanapiah,, N. Ismarrubie Zahari, “Estimation of Concentration by Eye Contact Measurement in Robotbased Intervention Program with Autistic Children” Procedia Engineering, 41, 1548 — 1552, 2012. L. Idzhar Ismail, S. Shamsudin, H. Yussof, F. Akhtar Hanapiah, N. Ismarrubie Zahari, “Robot-based Intervention Program for Autistic Children with Humanoid Robot NAO: Initial Response in Stereotyped Behavior,” Procedia Engineering, 41, 1441 — 1447, 2012. J. J. Cabibihan, H. Javed, M. Ang Jr, and A. S. Mariam, “Why Robots? A Survey on the Roles and Benefits of Social Robots for the Therapy of Children with Autism,” International Journal of Social Robotics, 5(4),593-618, 2013. doi 10.1007/s12369-013-0202-2. 716 Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 23:07:39 UTC from IEEE Xplore. Restrictions apply. 