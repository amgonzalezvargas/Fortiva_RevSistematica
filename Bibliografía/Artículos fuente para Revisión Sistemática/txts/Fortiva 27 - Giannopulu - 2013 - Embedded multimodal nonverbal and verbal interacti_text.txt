Embedded Multimodal Nonverbal and Verbal Interactions Between a Mobile Toy Robot and Autistic Children Irini Giannopulu, Ph.D & Dr.Sc Cognitive Neuroscience UCP & UPMC Paris, France e-mail: igiannopulu@psycho-prat.fr Abstract—We studied the multimodal nonverbal and verbal relationship between autistic children and a mobile toy robot during free spontaneous game play. A range of cognitive nonverbal criteria including eye contact, touch, manipulation, and posture were analyzed; the frequency of the words and verbs was calculated. Embedded multimodal interactions of autistic children and a mobile toy robot suggest that this robot could be used as a neural orthesis in order to improve children's brain activity and incite child to express language. Keywords-component multimodal interactions; autism; mobile toy robot; spontaneous game play; neural orthesis; expressive language I. INTRODUCTION Robot human interactions are of effective use in the education of autistic children. The aim of the present study is to analyze the relationship between multimodal nonverbal and_ verbal interactions in autistic children. Autism spectrum disorder is a complex and heterogeneous neurological deficit which affects cognitive functioning but also emotional and social behavior as well as language development [1]. Language problems appear early and persist. Half the population of children with autism do not develop expressive language. However, when autistic children do acquire expressive language, it is often lacking any depth, it is echolalic and it is characterized by a lack imagination [2]. Genetic studies have highlighted the complexity of the genetic architecture underlying autism [3]. Post-modern analysis has demonstrated evidence of altered brain development which strongly affects the formation of a neural network. Functional neuroimaging studies have given evidence of: reduced activity in amygdala neural development [4]; impaired integrity of white matter tracking development connections among temporal areas [5]; an increase in activation of primary motor and sensory processing [6]; atypical network activity and connectivity within temporal and orbitofrontal brain growth [7]. Multimodal in nature, these cortical areas are involved in complex cognitive functions such as perception, emotion, social communication and language. Consequently autistic children show difficulty in their play activities, as play activities necessitate interaction [8]. Different approaches are being utilized to better understand the capacity of autistic children to interact with a robot. The Aurora’s project aim is to create a tool based on an autonomous robot (Labo-1, Kaspar, Robota doll, for example) that convinces autistic children to 978-1-4673-3101-2/13/$31,00 © 20 Authorized licensed use limited to: UNI Are engage in a process of interaction [9]. Tito [10], Roball [11], Keepon [12], were employed in social interaction; Roboto caused behavior imitation on the part of the autistic child [13]; Pleo reinforced social behavior [14]. These studies have shown that animate robots, humanoid or not, using different stimulations encourage interaction in autistic children. All these studies have used fixed robots (with the exception of Labo-1, Roball and GIP Y-1) which essentially reduce the child’s spontaneity and self-expression in game play. Using a multimodal nonverbal cognitive approach (visual, tactile, manipulation, posture) [15] which was also related to an emotional one [16], we have shown that a mobile toy robot “GIPY I” could be used as a neural mediator to bring neurocognitive improvements to an autistic child. These multimodal cognitive and emotional interactions could be thought of as the building block from which expressive language could emerge. In order to test this hypothesis, we used a new mobile toy robot named “POL” which incites the child to engage in interaction and express language. On the hypothesis that autistic children will be in quasi-constant interaction with the robot which could give the child the possibility to express him/her self, the relationship between multimodal nonverbal criteria (visual, tactile, manipulation and posture) with expressive language behavior (positive or neutral) was analyzed in the free spontaneous game play. II. METHOD A. Participants Eleven children (8 boys and 3 girls) are planned participants in this study. As this study is currently underway, we present preliminary findings taking into account 5 (4 boys and 1 girl) out of the 11 participants in this Late-breaking report. Their chronological ages ranged from 7 to 8 years old (mean 7.3 years; sd 6 months); their developmental age ranged from 5 to 6 years old. The mean age when first words appeared was 38 months (sd 5 months). The children were diagnosed according to the DSM IV-TR criteria of autism [17]. The Childhood Autism Rating Scale [18] had been administrated at the age of 6 years by an experienced psychiatrist. B. Robot A mobile robot, called “POL”, which is animal-shaped, was used: a mobile chicken. An operator manipulated the robot via a RI 2013 Proceedings 127 H DEL ROSARIO. Downloaded on December 13,2023 at 21:38:10 UTC from IEEE Xplore. Restrictions apply. wireless control. The robot could move forward, backward and turn on itself at low speed. C. Protocol: two phases; 10 minutes of duration each The experiment takes place in a room which is familiar to all the children. ‘Baseline’: Children’s observation behavior with the immobile robot placed on the ground beforehand, in the center of the room. There is no game play session. “Experiment”: Children’s observation with the mobile robot. The robot was placed on the ground beforehand, in the center of the room. The game play session began as follows: when the child and the adult entered the room, the teleoperated robot carried out three movements (move forward, move back, 360° swivel). As in real human interaction, the child and the robot altered their responses. All movements were constant and standardized (for more details [15], [16]). D. Analysis For both phases, two dependent variables (DV) were used: a) the duration time of child-robot interaction; b) the frequency of words and verbs the children expressed. For the first DV, four criteria were defined: 1) eye contact, 2) touch, 3) manipulation, 4) posture (see also [15], [16]). In both phases, the duration of each criterion, (onset time and the offset time of each child’s behavior toward the robot) was calculated in seconds and was considered independently. Only the total duration is presented in the results section (see for more details [14], [15]). For the second DV, we have calculated the total number of expressive language (words and verbs, e.g., nice, came her, go away, great, move) and the number of words and verbs which express positive emotion. Two independent judges unfamiliar with the aim of the study completed the observations of the game play skills performing the analyses of video sequences with Elan software. The inter-judge reliability is good (Cohen’s kappa =0.52). Il]. EARLY RESULTATS The median time of child-robot interaction is 102 sec in the *baseline” and 508.3 sec in the “experiment” phase. In other words, the children spent 14% of their time playing with the robot in the ’baseline” phase and more than 84% in ”experiment” phase. In the “baseline” phase, the duration time of all cognitive criteria of robot-child interaction differs among the children. In the “experiment” phase, the duration of “eye contact” and “touching” is similar for all the children; the duration of “manipulating” and “posture” differs. Expressive language was more frequent in the “experiment” phase (10 words and 5 verbs) than in the “baseline” phase (2 words and O verb). In the “experiment” phase, two words and 1 verb express positive emotion whilst there is no language expression of positive emotion in the “baseline”. For five children only, a positive correlation exists between the expressive language (words and verbs) and the cognitive multimodal criteria in the “experiment” phase which approximates statistical significance (Spearman’s Q correlation coefficient 9 de Spearman = 0.7 p = .0597 one-tailed Test). In contrast, there is no positive correlation in the “baseline phase” (@ de Spearman = 0.15; p >.05 one-tailed Test). IV. ERLY DISCUSSION AND CONCLUSION This paper tries to analyze the multimodal nonverbal and verbal interactions’ embeddiment during free spontaneous game 978-1-4673-3101-2/13/$31,00 © 20 Authorized licensed use limited to: UNI U2 — esl Om es) play between a mobile toy robot and autistic children. Consistent with our previous studies ({15], [16]), these early results show, once again, that a mobile toy robot enganges autistic children in multimodal interactions (visual, tactile, manipulation, posture). In addition, the preliminary present data, suggest that multimodal non verbal interactions could be considered as the basis for the emergence of expressive language. Taken together, our previous and current preliminary data converge to say that emerging cognitive, emotional and verbal multimodality could be crucially shaped by the subject’s interactions with the robot. This approach, actually in development, attempts to understand "how" artificial environments could be considered as the root of neuronal organization and reorganization [19]. Based on the brain’s intrinsic properties, neuroplasticity and the fact that the brain is neurodynamic, our studies try to demonstrate that a mobile robot could be used as a neural orthesis, with the ability to improve brain activity in order to support the embodiment of cognitive, emotional and verbal information processing. ACKNOWLEDGMENT To the participants and their parents and the National Department of Education. REFERENCES [1] L. Crane, S.E. Lind and D.M. Bowler, “Remembering the past and imaging the future in autism spectrum disorder,’ Memory, in press. [2] J.B. Plavnick and S.J. Ferreri, “Establish verbal repertoires in children with autism using function-based video medeling”, J. Appl. Beh. Analysis. vol. 44, pp. 747-766. [3] N.H. Sykes and J.A. Lamb, “Autism: The quest for the genes,” Exp. Mol. Med. vol. 9, pp. 1-15, 2007. [4] B.M. Nacewicz, K.M. Dalton, T. Johnstone, M. Long, E.M. McAuliff, T.R. Oakes, A.L. Alexander, and RJ., Davidson, “Amygdala Volume and Nonverbal Social Impairment in Adolescent and Adult Males with Autism,’ Arch. Gen. Psychiatry. vol. 63, pp. 1417-1428, 2006. [5] K.A. Pelphrey and E.J. Caster, “Charting the typical and atypical development of the social brain,” Dev. Psychopathol. vol. 20, pp. 1081-1102, 2008. [6] B.A. Corbett, V. Carmean, S. Ravizza, C. Wendelken, M.L. Henry, C. Carter, and S.M. Rivera, S.M. “A functional and structural study of emotion and face processing in children with autism,“ Psychiatry. Res. vol. 30, 173, pp. 196-205, 2009. [7] L. Brothers, “The social brain: a project for integrating primate behaviour and neurophysiology in a new domain,“ Concepts. Neurosc. vol. 1,27—51, 1990. [8] I. Giannopulu, “Contribution a la compréhension des représentations multimodales chez l’-homme sein et chez des patients avec atteinte neuropsychologique: une approche life span”. H.D.R, UPMC-Paris VI, 2011. [9] K. Dautenhahn, “Socially intelligent robots: dimensions of human-robot interaction,” Philos. Trans. R. Soc. vol. B, 362, pp. 679-704, 2007. [10] T. Salter, I.P. Werry and F. Michaud, “Going into the wild in child-robot interaction studies - Issues in social robotic development,” Int. J. Robot. vol. 1, pp. 93-98, 2007. [11] F. Michaud and S. Caron, “Roball, the rolling robot,” Auto. Rob. vol. 12, pp. 211- 222, 2002. [12] H, Kozima, C Nakagawa, and Y. Yasuda, «Children-robot interaction: a pilot study in autism therapy,” Prog. Brain. Res. vol. 164, pp. 385-400, 2007. [13] J. Nadel, A. Revel, P. Andry, and P. Gaussier, “Toward communication: first imitations in infants, low-functioning children with autism and robots,” Inter. St: Soc. Beh. Commun. Biol. Syst. vol. 5, pp. 45-54, 2004. [14] E.S. Kim, L.D. Berkovits, E.P. Bernier, D. Leyzberg, F. Shic, R. Paul, B. Scassellati, “Social Robots as Embedded Reinforcers of Social Behavior in Children with autism,” J. Autim. Dev. Disord, DOI 10.1007/s10803-012-1645-2, 2012. [15] I. Giannopulu and G. Pradel, “Multimodal interactions in playful encounters of children with autism and a mobile robot,’ NeuroRehabilitation. vol. 27, pp. 305-311, 2010. [16] I. Giannopulu and G. Pradel, “From child-robot interaction to child-robot-therapist interaction: a case study in autism,” Appl. Bio. Biomech. vol. 9, pp. 173-179, 2012. [17] DSM-IV-TR Manuel diagnostique et statistique des troubles mentaux, Paris, Editions Masson, 2003. [18] E. Schopler, RJ. Reichler, R.F. De Vellis, and K. Daly, “Toward objective classification of childhood autism: Childhood Autism Rating Scale (CARS),” JADD10, pp. 91-103, 1980. [19] I. Giannopulu, “Multimodal interactions in typically and atypically developing children: natural vs. artificial environments”, 2012 (submitted) RI 2013 Proceedings 128 H DEL ROSARIO. Downloaded on December 13,2023 at 21:38:10 UTC from IEEE Xplore. Restrictions apply. 