The 23rd IEEE International Symposium on Robot and Human Interactive Communication August 25-29, 2014. Edinburgh, Scotland, UK, Rapid Prototyping Framework for Robot-assisted Training of Autistic Children Min-Gyu Kim!, Emilia Barakova! and Tino Lourens Abstract— Research in uptake and actual use of robots in socially assistive tasks is rapidly growing. However, practi- cal applications lack behind due to the enormous effort to create meaningful behaviours. This paper describes a rapid prototyping framework for robot-assisted training of children with Autism Spectrum Disorder (ASD). The main goal of this research is to provide a framework which translates the knowledge from the evidenced Pivotal Response Training to end-user tools, that allow therapists to program/adapt a training program mediated by a robot in order to use it in therapies. The overall structure of the intervention is based on Activity Theory which makes it easy to properly arrange robot actions and decisions. We appended a general end-user robot programming tool with PRT therapy-specific training structures which can be adapted with ease to create almost limitless learning opportunities utilizing a range of training scenarios or games. Pilot tests with children with ASD were performed to assess whether the robot assisted intervention created by this framework is ready for practical use. These showed that only minor adaptations were needed to increase the fluency of the robot-child interaction. I. INTRODUCTION Deploying robots for behavioural training of children with Autism Spectrum Disorder (ASD) and other clinical, educational and domestic tasks is showing a lot of potential [5], [10], [11]. However, creating even the simplest behaviour consumes a huge amount of effort, ranging from cross- domain therapeutic content creation to robot programming. As pointed out in [1], although some easy-to-use tools for programming of robots do exist, the major difficulty is in combining the robot programming expertise/developers with the domain specialists (e.g. therapists) in a way so that robots can be used for state-of-the-art performance by end users. For this purpose we proposed the end-user programming environment presented in [9], [1]. More similar developments have taken place lately [3]. One of the important conclu- sions of research in using robots for autism to date is the need for individualizing such robot systems to the needs of each person, which brings additional challenge to robotics research and to the sets of principles for building training scenarios. While [9], [1], [3] are general purpose frameworks for creating dynamic robot behaviours for real life scenarios, we propose therapy specific modules that would correspond to the thinking patterns and actual needs of the therapists. The concept of the framework was derived from Activity Theory which is a paradigm of representing context and setting in human interaction [8]. Activity Theory provides a psychological framework to represent human activities as socially-situated phenomena. Motivated activity is seen as a hierarchical system in which activity consists of actions that 978-1-4799-6765-0/14/$31.00 ©2014 IEEE 2 have goals, and where action consists of operations that are determined by a set of conditions [8]. The framework devel- oped in our project provides reusable programming modules which are necessary when prototyping the robot assisted intervention based on Activity Theory. The primary modules aim to perform the robot action and decision making. By combining these modules, the therapists can construct activ- ities for the intervention. In addition, the reusable module related to the training method is provided so that it can be deployed at places in the training scenario where the learning opportunities are given to the children with ASD. We also implemented a module for designing robot actions to allow choreography of emotional and intentional expressions. The existing training practices for ASD address specific skills or behaviours like language and communication skills, problem solving skills, daily living skills or socially adaptive behaviours [12], and use a wide variety of approaches and underlying theories. We have chosen the Applied Behavioral Analysis (ABA) framework, which stimulates desirable ac- tions by children through structural positive reinforcement [12]. Pivotal Response Training (PRT) in particular, as part of ABA, introduces the so-called pivotal areas to point out clusters of behaviours which lead to improvements in other behaviours of the children. Research has focused on five pivotal areas: responding to multiple cues, motivation, self- management, self-initiation and empathy [6]. We found the prompts used in PRT to be a promising course to follow, since they need to be delivered in a consistent and struc- tural manner, which makes the use of a robot particularly suitable.[5]. This paper is organized as follows. Section I introduces the environment in which the child interacts with the robot, and the training and games used to implement this method. Section III describes the implementation of the framework within the end user programming software in detail. Section IV shows the evaluation of the developed framework by performing experiments with children with ASD. Il. EXPERIMENTAL FRAMEWORK The effectiveness of dyadic interaction with a robot which helps children with ASD to improve the interactions with other people has been shown by Robins and colleagues [10]. We aim to design an environment where the humanoid robot provides learning opportunities to the children, while the therapist monitors how a child interacts with the robot. The therapist in the experiments executes partial robot control from an unseen place such as a monitoring room. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. The entire robot based training with the PRT technique was developed in comprehensive collaboration with a ther- apist who is specially trained for PRT intervention. The therapist selected the children’s games to be used for therapy and coordinated the therapy contents and activities based on the PRT technique. Moreover, the developed robot based training was investigated by the therapist from a therapeutic perspective. The training environment makes it possible for the child under training to get involved in many different types of sce- nario, such as greetings, opening a box with a combination lock which contains several games from which the child has to choose, saying good-bye, as well as playing the games. Between the child and the robot is positioned a game table for throwing a dice and putting down game cards as seen in Fig 1. A. Training Method The empirically evidenced PRT training has been used as a framework for designing the game scenarios. PRT is a behavioural intervention methodology for autism therapy, which was developed to teach the pivotal behaviour skills (i.e., motivation, self-initiation, responsiveness to multiple cues, empathy and self-management) that bring collateral improvements in a number of non-targeting behaviours [7]. It is also a naturalistic approach to enable children to naturally gain the pivotal skills through play activity in which the contingency is embedded. We particularly considered two primary pivotal areas (motivation and self-initiation) in developing the robot-assisted intervention. The lack of motivation in children with ASD is a diffi- cult problem. Hence, by prompting children with ASD to keep responding until they have completed given tasks, the children’s motivation to respond to those tasks is increased. The motivational strategies of PRT include providing choices which a child can take, varying and interspersing main- tenance tasks, reinforcing attempts and using natural rein- forcers [6]. Another strategy of PRT is teaching children with ASD to initiate interactions. This strategy gives chil- dren with ASD the opportunities to practice initiating and maintaining interactions with others. Training in question- asking promotes information-seeking initiations such as the name and location of items [6]. Children with ASD also learn how to request or protest, making statements to expand conversation skills. Two robot assisted activities based on PRT were imple- mented in game selection and first turn decision, keeping the children motivated to participate in the training. During the intervention, whenever a game is completed, the children need to decide whether they will play another game or repeat playing the same game. Several games are applied for varying tasks. The opportunities for learning self-initiations such as question asking, protesting and asking for help were arranged over many activities. For example, the robot can teach a child to ask for its name or to ask for a secret code or combination to unlock the box during a games. Another opportunity is to teach a child to protest against the robot by 354 (b) Child B (a) Child A Fig. 1: Children with ASD playing games with the humanoid robot insisting on something contradictory. When a child hesitates about what to do during the intervention, a robot can teach a child to ask it for help. B. Games Three existing games which are typically used for therapy in the clinic were utilized in the play scenarios. Boomgaardje (HabermaaB Inc.) which stands for Orchard in English is a board game. It requires the collaboration of players to harvest all the cherries in a competition with a raven. The game ends as soon as the raven has reached the tree and players lose the game together. If players pick the last cherry before the raven, they win the game together. Memory game 1 (Ravensburger) is a well-known card matching game. Players test how many cards they can correctly remember. Players here play the memory game | with 16 cards (8 pairs). The player who has more pairs than the fellow player wins. Memory game 2 is a collaborative variant of memory game 1. Each player has 8 cards that pairs up with fellow player’s ones. Players flip over one of their own cards in turns to find matched pairs. In addition, we developed a tangible sound based memory game inspired by the usual memory game. The motivation was to propose a collaborative memory game that used animal sounds. Two players play with 16 coloured blocks (8 pairs), and having the same package of sounds on each side, they attempt to find the matching sounds together. Players place a block on a sound dock which plays the sound. By integrating sounds into the blocks (which do not correspond to the colors) we attempt to provide training in multiple cues. III. IMPLEMENTATION A. End user Programming Environment The robot assisted PRT intervention was created by TiViPE which allows the development of sensory driven dynamic behaviours and good synchronization of parallel behaviour (See the details of TiViPE in [9], [1]). TiViPE is a visual programming environment which connects be- havioural components with different levels of complexity to create behaviours and behavioural scenarios. Dynamic states controlled by constant flow of sensory information Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. (a) A series of robot actions: choreography ° =a Cancel Settings of BehaviorDesign. Help Run Ok SO NAOreadyR StatesA 1 as wait (100) e— TIVIPE textual robot command States to activate 1,2 Key Statesé Key robot update NA&Oready IP address 169,254.28.144 ®—— Robot IP address Pall Key update Key states Active states Id Command aft at at Port i ‘id Information for NaoSenselnfo. ra Help Close Clear mover HeadPitch, 4.1, 1000, Head'Yaw, -14.4, 1000, RShoulderPitch, 69.7, 1000, RShoulderRoll, -5.7, 1000, RElbowRoll, 60.0, 1000, RElbow'Yaw, 18.6, 1000, RivVvristvaw, 59.4, 1000, RHand, 55.1, 1000, LShoulderPitch, 92.6, 1000, LShoulderRoll, 22.1, 1000, LElbowRoll, -87.6, 1000, LElbowYaw, -45.7, 1000, LwristYaw, -63.6, 1000, LHand, 0.5, 1000, < Process T¥VPMN aoSenselnf - Generated TiViPE textual robot command Displaying lines 1 to 27 out of 27 lines. (b) Behaviour design modules Fig. 2: TiViPE modules for robot behaviour design enable users to build complex, interactive and autonomous behaviours. B. Behaviour Design Designing robot motion and speech using TiViPE textual commands is straightforward and easy, so end users can create behaviours that are not presented in the behavioural blocks [1]. TiViPE is organized to constantly read the current value of each joint of the robot and generate a textual robot command to control the robot to do the following robot action. Hence, in order to create one gesture, the user can easily make choreography as shown in Fig. 2a. It is possible to test the created choreography by using the network including NaoSense and Naosenseinfo modules as shown in Fig. 2b. C. Therapy-specific Modules The required elements for PRT were designed to give structure of the prompting procedure. Prompting in PRT is a systematic procedure to teach children with ASD to internalize a specific skill by providing or removing prompts. 355 Start = y End * Note: A.R.=Appropriate Response, |.R.=Inappropriate Response, N.A.=Not Attentive, Fig. 3: The structure of a least to most prompt hierarchy provided by robot To help children with ASD acquire the target skill, a prompt is given by making statements/movements, touching, directly performing it or providing information about how to use it. PRT has a specific structure that contains the following three elements: antecedent stimuli (opportunity to respond), child-response and consequence (reward) [7]. Based on this structure, we represented a prompt hierarchy called a “least to most prompt hierarchy” using a flow chart as shown in Fig. 3. The prompt hierarchy consists of four different levels of prompt which are operationalized depending on the amount of help provided by the robot. The least to most prompt hierarchy used in this work is a way to increase the amount of assistance offered by the robot. The primary elements of the prompt hierarchy are the four prompts as defined below. These prompts are introduced during play activity whenever the robot can create learning opportunities for the child to respond to, and the prompt hierarchy is given depending on the child’s response. The primary elements of the prompt hierarchy are the four prompts as defined below. These prompts are introduced during play activity whenever the robot can create the learn- ing opportunities for the child to respond, and the prompt hierarchy is given depending on the child’s response. e Wait prompt: After creating an opportunity to respond, the robot waits for a child’s response without giving any indications. e Supplement prompt: The robot provides an indirect hint about an opportunity for the child to initiate and which Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. -— Oo TIViIPE Settings of PromptAndAttention. ? Run Ok Cancel hs C/m_file/lwp.tet = @— Prompt 2 Ed Time out (in ms) ME Time-delay States to activate when timed out 1 [States to activate ][Keys ][key coupled states] [J[a,n,d][16,4,3] «Decision Id Motion file States to activate Id Motion file C:/m_file/iwaot e+ Attention drawing States to activate 1 Settings of Trial. ? Ei Bh ti & Help Run Ok Cancel Id as [States to activate][Keys][Key coupled states] [][y,n][14,15] e Decision Id Motion file Ci/m_filessttt e+ Reattempt States to activate Id C:/m_file/én.xt e+ Defer Motion file rer States to activate Fig. 4: TiViPE modules for the prompting procedure does not model the target behaviour. e Open question prompt: The robot asks an open-ended question that the child should respond to and which does not model the target behaviour. e Model prompt: The robot provides a model of the desired behaviour for the child to imitate. The prompt hierarchy also contains additional elements. First, the robot must be able to draw and keep the child’s attention to the given task at hand (Attention-drawing). The prompting would not be effective when the child is paying attention to an object in which he or she is interested. Hence, before delivering a prompt it must be ensured that the targeted child is focusing on the task [7]. Second, a time delay between the prompts must be added to the prompt hierarchy. Time delay aims to give the child a chance to respond independently before the prompt is issued. The diamond-shaped decision symbols in the flowchart of Fig. 3 mean that the operator can delay a time (e.g. 7 sec. as required in PRT) to wait for a child’s response. Third, in the case that the child does not respond at all, the robot completes the current learning opportunity by promising to repeat the action next time. The robot does not end the training earlier or allow the child to do another activity (Deferrer). Depending on the situation, the robot offers the same opportunity again to the child to observe the response (Reattempt). In Fig. 3, the yellow coloured boxes are the actions of the robot. These can be implemented with the basic module of TiViPE, CommandState3 which gives an opportunity to add new behaviours into the scenario, such as speech and motion. The green boxes enable decisions for the follow-up actions. Other basic modules named CommandStateSelectByKey and CommandsStateSelectByKeyOrTimeOut provide a interface for the user (the therapist who follows the intervention) to decide which module will be activated. The only difference between two modules is a time-out function which auto- 356 | Start Action 1: Hand shaking Operation 1: Utterance “Hi, Peter. Nice to meet you” cond. 1: child’s attention cond. 2: child’s name —<— cond. 3: stretching its arm to child Not ~~ cond. 4: child holding its hand “attentive — Action 2: Self-introduction Operation 2: Utterance “| will play games with you today...” cond. 1: child’s attention Not ~~ attentive ~ Not ~<— attentive { Statement | for question asking i GotoRobotturn | Fig. 5: The flowchart of robot actions in the greetings activity matically activates the pre-assigned module when timed-out. The first four red boxes from the top containing actions and decisions can be merged with two CommandState3 and one CommandsStateSelectByKey. The merged module (Promp- tAndAttention) is shown in Fig. 4. Finally, the last red box was created as the module (Trial). Four PromptAndAttention and one Trial module are combined as a PRTmodule which is completely reusable in any kind of learning opportunities including motivation, self-initiation and responsiveness to multiple cues. Besides, the user can remove the number of PromptAndAttention in the PRTmodule, depending on the skills already obtained by the children or in order to use the PRTmodule as another type of prompt hierarchy such as a most to least prompt hierarchy. D. Hierarchical Interaction Model for Activities Activity Theory gives a useful framework, not only for human-computer interaction [2] but also for human-robot interaction [4]. Using it as a basis for programming of the robot assisted PRT intervention, we implemented the hierarchical structure of robot behaviours in the form of a flow chart because it is easy to adapt it to TiViPE software. The following description is an example of the hierarchical structures of a greetings prompt which was made for training social greetings and familiarization with the robot. The yel- low coloured boxes marked with a thick line in Fig. 5 indicate the robot actions which are executed when the defined operations were satisfied. In the example of greetings, the robot action of shaking hands can be performed by saying, ‘Hi, Peter. Nice to meet you’, when the child whose name is known to the robot pays attention to the robot and the robot stretches its arm out to the child, holding his hand. The text on the right in the figures show the level of activity consisted Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. - File Modules Control H elp oe oe = 60 STOP a @ ty TiVIPE ee Greetings Boxopening ** Game selection «+ Instruction ee Clean-up Toys «+ Playing game - Goodbye Game 1 Game 3 Fig. 6: The entire Ti ViPE network including play activity and learning opportunities ua Sa EE TIVIPE a robot and the child. When the child meets the robot, they first maou, t exchange greetings with each other with social gesture (e.g. a = hand shaking, high five, etc.). Before starting game playing, [ucreetingsqawitnotion] [yg Fig. 7: The TiViPE network programmed for greetings of a chain of actions where each action contains operations. Activity: Greetings (The motive is to show attention to the child.) Action I: Hand shaking (Goal: physical contact as social cue) Operation I: Utterance (Condition 1: child’s attention, Condition 2: child’s name, Condition 3: stretching its arm to the child, Condition 4: child holding its hand) Action 2: Self-introduction (Goal: sharing personal fea- tures except its name) Operation 2: Utterance (Condition 1: child’s attention) Fig. 6 shows the full TiViPE network demonstrating the highest layer of the program hierarchy. Each module in the network indicates activity which contains a chain of the robot actions in the lower layers. Some structures of the modules such as greetings, deciding first turn and instructions are reusable in other scenarios or games. The interaction flow starts from the greetings between the 357 the child needs to open the locked box containing several games and then to choose a game to play. Depending on the child’s experience on the selected game, the robot can give instructions of how to play or skip the instruction. The robot can stop in the middle of the instruction when the child learns the rule. As soon as the game instruction ends, the child and robot play the game for real. After the game, the child has the opportunity to choose a different game. If the child does not wish to play, the robot can close the training with a goodbye activity. IV. RESULTS We qualitatively evaluated the readiness of the robot assisted intervention created by the rapid prototyping frame- work for practical use. The evaluation consisted of two pilot tests that took place between a child and a robot. The humanoid robot Nao, developed by Aldebaran Robotics, was used for the user confrontation as can be seen from Fig. 1. The robot has an anthropomorphic shape, is 58 cm tall and includes 25 degrees of freedom, with several sensors such as cameras, microphones, ultrasound sensors, inertial board, tactile sensors and pressure sensors. The children involved in the tests met the inclusion criteria of having no resistance to robots and an ability to verbalize. In the first pilot experiment, an child with ASD (male, 7 years old) participated. The robot intervention continued for 45 minutes. The child played three games (Boomgaardje, memory game | and memory game 2). In the second pilot test, another child with ASD (female, 9 years old) was recruited. She played the sound memory game (Fig. 1b) for 45 minutes. The experiments revealed both the weak and strong points of our framework. In both experiments, the expressiveness of gesture and speech was restricted. The robot repeated the Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. same scripts and gestures during the turn-taking if the same action had to take place (e.g., child had to put yet another block in the designated place). This affected the children’s engagement in the game. The module to perform the robot action currently has a function to execute the same action. Hence, a module which can select an action from a set of possible options (much in the way a person would choose from a diverse range of potential responses in the same context) was further implemented. In the second experiment, the robot was supposed to pick a block and the child should help him put the block inside the sound dock to listen to it. This task was not successful because the child always picked the block that she wanted. The robot could not intervene as we had not planned for this situation. Also, when the first game playing was done and the robot asked her to play again, she answered yes. In the interview after the experiment, it was found out that the child had a trouble with giving non-socially expected answers, meaning that if the robot had not stopped her after the second iteration of the game, she most likely would have played again. A therapist would catch on to this immediately, however the robot was unable to deal with this situation. In order to handle such unexpected situations, the framework required an additional module to provide speech to be typed by the therapist and immediately sent to the robot for execution. It was evident that the robot speech needs to be detailed, clear and encouraging to cope with the cases where children with ASD may passively follow the robot instructions. In the first experiment, when the robot did not tell the child to open the box that contained three games, the child did not open the box by himself even though he unlocked the combination lock. Also, because the explanation was unclear, the child did not understand how to arrange one of the toys in the game. On the other hand, the subdivided steps of the instructions disturbed the smooth flow of the interaction. Hence, it is important to offer an appropriate level of detail when instructing the child. In general, the games were properly accomplished by the children. The children waited for the robot to talk and followed the instructions and also understood the purpose of the game. In particular, the children showed self-initiations which were successfully provoked by the robot assisted intervention. The rapid prototyping framework contributed to easily add prompts at appropriate moments. The first and the second pilot tests showed that only adjustments on the speed of the robot reactions and on the level of detail of the instructions that the child needed had to be improved. A third trial with the child that participated in the first pilot experiment took place after the interaction fluency was improved. The child had a much better time with the robot and he enjoyed the game and the interaction more than the first time. V. CONCLUSION The rapid prototyping framework for therapy specific behaviours was created and tested with four games. We built 358 on the existing programming environment TiViPE, which has been already developing large set of modules that are potentially useful in therapies. In this study we developed therapy-specific modules, which are much more complex than an individual module in the way that they consist of a complete PRT hierarchy and can be added at any place where a learning moment needs to be introduced. The only change that has to take place by introducing a new learning moment is to change the text depending on the particular context of the learning moment, which is as simple as typing a text command. The experiments showed that the creation and redesign of training scenarios is a very fast and error prone process now. The improvements will be to redesign the modules that created the interactions to generate different expressions and gestures. ACKNOWLEDGMENT We would like to acknowledge ZonMW, The Netherlands Organization for Health Research and Development (project number 95103010, ZonMW Programma Translationeel On- derzoek). We also would like to thank Jeffrey Uitterhoeve, Quentin Guidet and Thijs ter Velde who developed the sound based memory game at Eindhoven University of Technology. REFERENCES [1] E. I. Barakova, J. Gillesen, B. Huskens, and T. Lourens. End-user programming architecture facilitates the uptake of robots in social therapies. Robotics and Autonomous Systems, 61(7):704—713, 2013. J. E. Bardram. Activity-based computing for medical work in hos- pitals. ACM Transactions on Computer-Human Interaction (TOCH1), 16(2):10, 2009. V. Berenz and K. Suzuki. Targets-drives-means: A declarative approach to dynamic behavior specification with higher usability. Robotics and Autonomous Systems, 2014. C.-M. Huang and B. Mutlu. Robot behavior toolkit: generating effective social behaviors for robots. In Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Inter- action, pages 25-32. ACM, 2012. B. Huskens, R. Verschuur, J. Gillesen, R. Didden, and E. Barakova. Promoting question-asking in school-aged children with autism spec- trum disorders: Effectiveness of a robot intervention compared to a human-trainer intervention. Developmental neurorehabilitation, (Q):1— 12, 2013. R. L. Koegel, L. Koegel, and C. M. Carter. Pivotal teaching interactions for children with autism. School Psychology Review, 28(4):576—-594, 1999. R. L. Koegel, L. Schreibman, A. Good, L. Cerniglia, C. Murphy, L. K. Koegel, et al. How to teach pivotal behaviors to children with autism: A training manual. University of California, Graduate School of Education, 1989. A. N. Leontjev. Activity. consciousness. personality. 1978. T. Lourens and E. Barakova. User-friendly robot environment for creation of social scenarios. In Foundations on Natural and Artificial Computation, pages 212-221. Springer, 2011. B. Robins, K. Dautenhahn, R. Te Boekhorst, and A. Billard. Robotic assistants in therapy and education of children with autism: Can a small humanoid robot help encourage social interaction skills? Universal Access in the Information Society, 4(2):105—120, 2005. B. Scassellati, H. Admoni, and M. Mataric. Robots for use in autism research. Annual Review of Biomedical Engineering, 14:275-294, 2012. R. L. Simpson. Evidence-based practices and students with autism spectrum disorders. Focus on Autism and Other Developmental Disabilities, 20(3):140—-149, 2005. [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 13,2023 at 16:08:15 UTC from IEEE Xplore. Restrictions apply. 