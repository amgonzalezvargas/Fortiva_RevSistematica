Journal of Psychiatric Research 90 (2017) 1—11 Contents lists available at ScienceDirect Journal of Psychiatric Research aI SEVIER journal homepage: www.elsevier.com/locate/psychires [Improving therapeutic outcomes in autism spectrum disorders: (H cvssvet Enhancing social communication and sensory processing through the use of interactive robots Felippe Sartorato °, Leon Przybylowski *, Diana K. Sarko °'‘ * Osteopathic Medical Student (OMS-IV), Edward Via College of Osteopathic Medicine (VCOM), Spartanburg, SC, USA > Department of Anatomy, Southern Illinois University School of Medicine, Carbondale, IL, USA © Department of Psychology, Southern Illinois University School of Medicine, Carbondale, IL, USA ARTICLE INFO ABSTRACT Article history: For children with autism spectrum disorders (ASDs), social robots are increasingly utilized as therapeutic Received 16 November 2016 tools in order to enhance social skills and communication. Robots have been shown to generate a number Accepted 3 February 2017 of social and behavioral benefits in children with ASD including heightened engagement, increased attention, and decreased social anxiety. Although social robots appear to be effective social reinforce- Keywords: ment tools in assistive therapies, the perceptual mechanism underlying these benefits remains unknown. Social robot _ To date, social robot studies have primarily relied on expertise in fields such as engineering and clinical Socially assistive robot (SAR) . . or . aoe . - psychology, with measures of social robot efficacy principally limited to qualitative observational as Speech . - . . . . . . . . Communication sessments of children's interactions with robots. In this review, we examine a range of socially interactive Multisensory robots that currently have the most widespread use as well as the utility of these robots and their Cross-modal therapeutic effects. In addition, given that social interactions rely on audiovisual communication, we discuss how enhanced sensory processing and integration of robotic social cues may underlie the perceptual and behavioral benefits that social robots confer. Although overall multisensory processing (including audiovisual integration) is impaired in individuals with ASD, social robot interactions may provide therapeutic benefits by allowing audiovisual social cues to be experienced through a simplified version of a human interaction. By applying systems neuroscience tools to identify, analyze, and extend the multisensory perceptual substrates that may underlie the therapeutic benefits of social robots, future studies have the potential to strengthen the clinical utility of social robots for individuals with ASD. © 2017 Elsevier Ltd. All rights reserved. Contents 1. ‘Introduction . , .2 2. Sensory perception & integration: ‘deficits & therapeutic targets in ASD . ccc c eee e eee e eee e es Cece eee teen ete eee eeeneeceaa d 2.1. Integration of multiple sensory modalities: challenges and opportunities in ASD Lenn ene n ene eee eee ene e eee eee n eee e eens 2 2.2. Assessing perceptual integration of multisensory cues: the temporal binding WindOW ...............ccc cece eee cee eee eee etn ee eee d 3. The neurobiology of social interaction & communication deficits in ASD ....... 0... ccc cee cece eee eee eee eect teense eee eee eeeeeea D 3.1. The neurobiology of perception of social robots ......... 0.0 ccc ccc cee cee e eee e eee e eee e eee e eee e nett eect teen eee teen ne need A. Bh Spectr OF SOCIS IV ASSISTIVE FODOUS «ss ssvseeeeceressssseeeucesessessesesssssseceseas saseeseeseeceeeeeeeeeeeeeeeececcesececccseses @ 41. Humanoid robots . 4 4.2. Cartoonish robots ......... . .4 4.3. An unsuccessful robot model: ‘avoiding the | ‘uncanny valley” of social robotic design i 4A. Social robots in animal fOrm ........... 0c ccc eee eee n ee Cee eee e eee ne eee eee nett ee ee eee eee eee ee O 4.5. Social robots in robotic fOTM ...... 66. eee eee e ee Cee nee e een e eee ne eee eee e eee eee e eee e eee ee dO * Corresponding author. 1135 Lincoln Drive, Southern Illinois University, Carbondale, IL 62901, USA. E-mail address: dsarko38@siumed.edu (D.K. Sarko). http://dx.doi.org/10.1016/j.jpsychires.2017.02.004 0022-3956/© 2017 Elsevier Ltd. All rights reserved. Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 2 E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 5. Towards an optimal robotic model for use in ASD therapies ........ D Applying systems neuroscience tools to strengthen and extend social ‘robot therapeutic value . beeen cece e eee cece eee eee e teen eens 7. Access to social robot therapies and methodological considerations ........... ccc ccc cc cece eee cee ee ee ene e eee nent eee nee eeees Coon ND References ...... ccc ce ccc cece cece cence ete cence teense ne ceeeeeeenenees bebe neue nent ee eeneeeeeeeeeneeeeneeeeeeeneneeeeeeenenenes 1. Introduction Autism spectrum disorders (ASD) include a continuum of defi- cits characterized to varying extents by difficulties with commu- nication and social interactions, repetitive behaviors, and restricted interests (American Psychiatric Association, 2013; Kanner, 1943; Lord et al., 2000). Social deficits may include a variety of impair- ments during interactions, including difficulty initiating joint attention behaviors and responding to joint attention tasks (Charman et al., 1997; Leekam et al., 1997; Mundy and Sigman, 1989). Children with ASD often exhibit a diminished ability to imitate others (Ingersoll, 2008; Rogers and Pennington, 1991; Williams et al., 2004), which is critical due to the key role that imitation is thought to play in the development of social cognition (Meltzoff and Decety, 2003). In addition, individuals with ASD frequently exhibit reduced gaze fixation (Baron-Cohen et al., 2000; Dalton et al., 2005; Lord et al., 2000) and a reduced ability to recognize and respond appropriately to emotional expressions (Celani et al., 1999), making social interactions frustrating, confusing, and potentially aversive. The prevalence of ASD appears to be increasing, with recent estimates as high as 1 in 68 (Baio, 2014). Since few treatment options currently exist, there is a crit- ical need for establishing novel, effective support tools and thera- peutic intervention strategies. Social robots were recently discovered to be promising tools in the diagnosis and treatment of ASD, particularly due to the fact that individuals with ASD often show an interest in technology (Dautenhahn and Werry, 2004; Diehl et al., 2012, 2014b; Feil-Seifer and Mataric, 2009; Scassellati, 2007). Robots appear to be more effective than interactive software or computer-mediated therapy based on their flexible capacity for interactive play and engaging multisensory design features, including realistic 3-dimensional body movements (Cabibihan et al., 2013; Kim et al., 2013). Both adults and children (typically developing or otherwise) have a natural inclination to anthropomorphize life-like robots, attrib- uting human-like motivations and intentions to robots and relying on human social rules when interacting with them (Hinds et al., 2004; Reeves and Nass, 1996). In fact, typically developing tod- dlers have been shown to treat robots as peers rather than as toys following repeated exposures to, and interactions with, the robots (Tanaka et al., 2007). If our human social rules and interactions can be generalized to interactions with robots, social robots may represent an ideal tool for facilitating the development of social Skills and for delivering interventions that alleviate social diffi- culties for individuals with ASD. Robotic interactions are inherently more controlled, predictable, and simplistic, thereby generating less frustration for individuals with ASD who may have difficulty interpreting and responding to human social interactions. Children with ASD are proactive in initiating interactions with social robots (Dautenhahn, 2007); produce more speech overall in the presence of a social robot (Kim et al., 2013); and direct more speech (social interaction) toward adults in the same room when also in the presence of a social robot (IKim et al., 2013). In addition, robots are effective at attracting gaze (Werry et al., 2001), and interactions with robots have been shown to significantly decrease social anx- iety in children with ASD (Kaboski et al., 2015). Developing early social and communication intervention strategies targeted towards children with ASD is of particular interest because children are especially vulnerable to increasingly complex social demands as they transition to adulthood (Webb et al., 2004). Delays in the development of age-appropriate social communication can be highly detrimental to individuals with ASD, leading to increased social anxiety and depression as well as diminished occupational/ professional success as adults (Gillott et al., 2001; Sterling et al., 2008). 2. Sensory perception & integration: deficits & therapeutic targets in ASD The development of social robots as a therapeutic tool for in- dividuals with ASD has benefited extensively from advances in engineering and adoption by clinical psychologists. Despite the fact that social interactions inherently rely on audiovisual communi- cation, systems neuroscience approaches addressing the mecha- nism and efficacy of the therapeutic utility of social robots remain largely unexplored. Systems neuroscience analyses offer the op- portunity to elucidate critical components of the perception of, and social interactions with, robots for individuals with ASD. This in turn will allow optimization of the sensory cues delivered by robots to generate the greatest degree of behavioral benefits possible. Altered sensory perception is an integral part of ASD sympto- mology, with observations of sensory disturbances dating back to Kanner's first observations (Kanner, 1943). Individuals with ASD often demonstrate a range of reactions to sensory stimuli that are not found in typically developing individuals, including both overstimulation aversions and hyposensitivity (Baranek et al., 2006; Cascio et al., 2015; Grandin, 2000; Kientz and Dunn, 1997; Leekam et al., 2007; O'Neill and Jones, 1997; Puts et al., 2014; Rogers et al., 2003; Talay-Ongan and Wood, 2000; Tavassoli et al., 2016). Although deficits in sensory processing are observed in ASD, enhanced processing of certain sensory cues, particularly “simple” stimuli (e.g., LED flashes and pure tones), have also been observed (Bonnel et al., 2003; Cascio et al., 2008; Mottron et al., 2006; O'Riordan and Passetti, 2006). The deficiencies observed in perceptual processing in ASD are commonly related to more com- plex stimuli (e.g., emotional facial expressions, speech) (Bertone et al., 2005; Boddaert et al., 2004a; Minshew and Hobson, 2008). Visual perception of biological motion is also impaired (Bertone et al., 2003; Blake et al., 2003; Kaiser and Shiffrar, 2009; Spencer et al., 2000) with higher visual motion coherence thresholds (Spencer et al., 2000) and deficits in perception of complex and biological motion (Bertone et al., 2003; Blake et al., 2003). 2.1. Integration of multiple sensory modalities: challenges and opportunities in ASD Beyond perception of a single modality stimulus alone (e.g., visual alone, such as a flash of light from an LED), impairments related to combining signals from multiple sensory modalities (known as multisensory integration) are present in individuals with ASD (e.g., (Donohue et al., 2012; Stevenson et al., 2014b)). Information from multiple sensory modalities must be combined in Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 3 a meaningful way and filtered accurately in order to derive perceptual meaning from our surroundings and respond with appropriate behavior. Multisensory integration is detectable at the neural level (for instance, as a significant increase in neural response/firing rate when an LED and white noise burst are pre- sented together, compared to an LED presented alone or a noise burst presented alone) and at the behavioral level (as faster reac- tion times, improved target detection, enhanced orientation, and increased accuracy in response to multisensory stimuli) (see (Sarko et al., 2013) for review). With its critical role in shaping normal perceptual processes, impairments in effective multisensory inte- gration can generate a profoundly altered sensory environment that is hyperstimulating and overwhelming, characterized by improper filtering of signal vs. noise and binding of multisensory signals that should not be perceptually bound. Emerging evidence suggests that altered multisensory processing may play a contrib- utory role in the etiology of ASD (Ciesielski et al., 1995; Foss-Feig et al., 2010; Kern, 2002; Kwakye et al., 2011; Stevenson et al., 2014b). The structure and function of multisensory brain networks also appear to be compromised in individuals with ASD (Boddaert et al., 2004b; Zilbovicius et al., 2006). In addition, new evidence emphasizes atypical multisensory integration as a contributing factor in the social and linguistic difficulties typically seen in those suffering from ASD (Senkowski et al., 2008). 2.2. Assessing perceptual integration of multisensory cues: the temporal binding window The behavioral benefits of effective multisensory integration are derived from underlying neural operations that result from the convergence and integration of inputs from multiple sensory mo- dalities. In order to determine which information from different senses should be perceptually bound (encoded as belonging to a common source), the brain relies on certain statistical regularities of sensory stimuli, such as the speed of light vs. sound and the relative neural conduction speeds of each sensory modality. Due to differing propagation speeds, the nervous system allows a certain degree of temporal offset (typically ~300ms) in which multisensory stimuli will be perceptually and neurophysiologically bound together and perceived as a coming from a common source (Meredith et al., 1987; Shams et al., 2002). Thus, the timeframe in which multisensory stimuli are highly likely to be integrated and perceived as simultaneous (i.e., belonging to a common source) is known as the “temporal binding window.” This has become a useful construct in assessing an individual's capacity to filter environ- mental stimuli appropriately, determining stimuli that belong A Example Temporal Binding Window % Perceived Synchronous AV Onset Asynchrony (ms) VA together (to a common source) versus those that do not (disparate sources) (e.g., (Foss-Feig et al., 2010; Stevenson et al., 2014a, 2014b)). A study by Foss-Feig et al. demonstrated that for chil- dren with ASD, the temporal binding window was approximately twice as large compared to that of typically developing children in response to certain multisensory illusion stimuli (Foss-Feig et al., 2010), Other studies have shown that the most profound effects of temporal binding window enlargement in adults with ASD are present for speech stimuli (Stevenson et al., 2014b) (Fig. 1). Func- tionally, this diminished ability to accurately filter environmental stimuli has a profound impact on successfully navigating the world around us. Larger temporal binding windows in individuals with ASD may contribute toward the perceptual substrates underlying many pervasive characteristics put forward in the Intense World Theory (Markram et al., 2007; Markram and Markram, 2010). This theory proposes that the hypersensitivity and “sensory overload” that in- dividuals with ASD experience may be due to neuropathology of hyper-active neuronal circuits. By combining multisensory infor- mation that should normally be separated, enlarged, more inclusive temporal binding windows may create an improperly filtered - and therefore more confusing and overwhelming - perceptual world. This in turn may alter the processing of sensory stimuli that would normally be perceived as innocuous (e.g., visits to a movie theater, social encounters) to instead be perceived as acutely unpredictable, aversive, anxiety-inducing, and potentially unbearable. 3. The neurobiology of social interaction & communication deficits in ASD The inherent heterogeneity of autism spectrum disorders leads to difficulty in pinpointing common neural substrates that may cause core deficits. However, certain neurobiological irregularities do appear to be overarchingly characteristic of ASD. Several neural mechanisms have been proposed to underlie the core social and communication deficits observed in ASD. One such network in- volves the mirror neuron system, which facilitates imitation and social communication. In a fMRI experiment studying imitation and observation of emotional expressions, children with ASD exhibited low levels of activity in the mirror neuron regions of the inferior frontal gyrus, pars opercularis, indicating that mirror neuron sys- tem dysfunction may contribute to core social deficits in ASD (Dapretto et al., 2006). Impairments in accurate recognition of emotional facial expressions and emotion communicated through body language, particularly with respect to fear, may be related to abnormalities of the amygdala in individuals with ASD. Bs Temporal Binding Window Widths * 600 | mT @ ASD 400 200 Temporal Binding Window (ms) Flashbeep Tools Stimulus Type Speech Fig. 1. Adults with ASD exhibit wider temporal binding windows (TBWs) for more complex human speech stimuli ((Stevenson et al., 2014b), Copyright 2014, reprinted with permission). A) The temporal binding window is assessed as the width (in ms) at 75% of maximum simultaneity response in a simultaneity judgement task. B) Only complex speech stimuli resulted in significantly wider temporal binding window size in individuals with ASD compared to TD individuals. ASD = autism spectrum disorders, AV = Audio-visual (auditory cue precedes visual cue), TBW = temporal binding window, TD = typically developed, VA = Visual-audio (visual cue precedes audio). Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 4 E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 Neuroimaging and neuropathology studies suggest that amygdala dysfunction may underlie social cognition deficits (Abell et al., 1999; Adolphs et al., 2001; Aylward et al., 1999; Baron-Cohen et al., 1999; Bauman and Kemper, 1985; Hadjikhani et al., 2009; Howard et al., 2000; Nacewicz et al., 2006; Pierce et al., 2001; Schultz, 2005; Schumann and Amaral, 2006) and gaze aversion (Spezio et al., 2007). Individuals with ASD exhibit weak or absent activation in the fusiform gyrus, a brain region involved in face recognition, as well as reduced activation of the inferior occipital gyrus, superior tem- poral sulcus, and amygdala during human face perception tasks (Pierce et al., 2001). Altered functional connectivity has also been demonstrated during human face processing in individuals with ASD, including reduced connectivity between the fusiform face area and the amygdala that correlated with the degree of social impairment (Kleinhans et al., 2008). One study found that instead of activating brain areas typically involved in human face percep- tion, individuals with ASD activated an aberrant and heterogeneous mix of other brain regions (Pierce et al., 2001). This indicates that these individuals perceive faces by recruiting altered neural net- works. Interestingly, a fMRI case study of a boy with ASD who was particularly interested in Digimon cartoon characters revealed that these cartoons activated typical face processing regions (fusiform gyrus and amygdala) but that human faces did not (Grelotti et al., 2005). These findings reveal that the neural circuitry critical to social interactions - specifically, involving face perception - can be recruited by neural networks typically devoted to human faces. The fusiform gyrus also responds to non-facial objects related to visual expertise, possibly subserving some of the restricted interests characterizing individuals with ASD (Foss-Feig et al., 2016). Such neurobiological studies in ASD indicate that the neural circuitry of social interactions is malleable - and potentially highly targetable - for therapeutic interventions through the use of other simplified/ non-human faces such as those of social robots. 3.1. The neurobiology of perception of social robots If robots are to act as therapeutic interventions and social fa- cilitators, it is important to elucidate how robots are perceived, both at behavioral and neural levels. In a recent fMRI study, typi- cally developed adults and those diagnosed with ASD played an interactive game of rock, paper, scissors against 3 different oppo- nents: a person, a humanoid robot (Bioloid), or a random number generator (Chaminade et al., 2012). Typically developed adults exhibited increased activity in pSTG (posterior superior temporal gyrus, involved in social cognition and multisensory integration) when interacting with a person compared to the robotic opponent. This indicates that typically developed adults were able to effec- tively differentiate between humans and robots. Adults with ASD did not demonstrate this differentiation, instead exhibiting com- parable activity in pSTG against both the human and robotic op- ponents. This could be interpreted as an inability to discern the intentionality of the human vs. the robot (Chaminade et al., 2012) or as a reduced ability to perceive the “humanness” of the human opponent (Kuriki et al., 2016). Another potential explanation for reduced pSTG activity in individuals with ASD when confronted with human opponents could be due to altered perception of multisensory cues compared to typically developed individuals. Regardless of which theory (or combination thereof) is correct, there is high therapeutic potential in exploiting the fact that in- dividuals with ASD may perceive robots as interchangeable, acceptable, and perhaps preferable social interaction partners. 4. A spectrum of socially-assistive robots The use of robots for individuals with ASD is a relatively novel therapeutic tool gaining traction over the last decade (Aresti- Bartolome and Garcia-Zapirain, 2014; Coeckelbergh et al., 2016). During that time, researchers and clinicians have developed robotic models with a wide range of appearances, features, and functional capabilities that draw from expertise in fields such as engineering and clinical psychology (Scassellati et al., 2012). Robotic interactive features include various degrees of capability with respect to bio- logical motion (e.g., walking, jumping, or dancing), body language (e.g., shrugging shoulders; tilting, turning, or shaking head), gaze direction to indicate attention, facial expression (e.g., smiling or frowning, lip/eyebrow/eyelid/ear movement), and vocalization (with varying levels of emotional prosody, from more robotic to more human-like speech) (Cabibihan et al., 2013; Pennisi et al., 2016). Such features are varied in order to optimally target and alleviate the deficits associated with ASD (Fig. 2), particularly with respect to social interactions and communication. Below, we will examine a range of interactive robot designs that have been used to target ASD; the therapeutic effectiveness of these robots in working with individuals with ASD; which features of robotic appearance and capability appear to generate optimal clinical utility; and ulti- mately, how systems neuroscience tools may be used to further extend treatment of social and communication symptomology in children with ASD through the use of social robots. 4.1. Humanoid robots In some cases, robotic designs rely on human-like appearances to varying degrees in order to increase realism and evoke engage- ment and interaction. The AURORA (Autonomous mobile Robot as a Remedial tool for Autistic children) project utilized robots to engage children with ASD in play behavior and social interactions (Dautenhahn, 1999). A robotic doll named Robota (Fig. 2A) with a human appearance was capable of limited arm, leg, and head movement; reaction to touch through the use of potentiometers to detect passive deflection; and robotic vocalizations through speech synthesizing. Robota was successfully used to encourage imitation of movements, social interaction, joint attention, and play in chil- dren with ASD (Billard et al., 2007; Dautenhahn and Billard, 2002; Robins et al., 2005). A different humanoid robot model named KASPAR (Kinesics And Synchronization in Personal Assistant Robotics; Fig. 2B) was developed to look like a 3-year-old boy (Dautenhahn et al., 2009), KASPAR had the ability to move its arms and head, to blink and make limited facial expressions (e.g., smiling), and to vocalize using a neutral male human voice. After playing a video game with KASPAR, children with ASD exhibited increased collaborative play with human adults, indicating that KASPAR was effective at enhancing social behaviors and generalized social engagement (Wainer et al., 2010). 4.2. Cartoonish robots Alternative robotic models deviate from a human appearance in favor of designs with the appearance of approachable, cartoonish creatures. A study by Duquette et al. (2008) used a robotic design named Tito with a cartoonish appearance. Tito was capable of some degree of mobility (moving on wheels), arm movement, head movement, facial expressions related to a series of LEDs depicting a mouth, and vocalizations emitted as pre-recorded speech (a male voice that could be neutral, happy, or interrogative). Compared to human interactions, interactions with Tito generated more shared attention (gaze directed towards Tito, physical proximity) and Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 5 Fig. 2. Examples of robots with a variety of capabilities and appearances used in therapeutic applications for autism spectrum disorders. These robots range from appearances that are human-like (Robota, A; KASPAR, B) (images reprinted with permission from (Dautenhahn et al., 2009)); cartoonish (Keepon, C) (image reprinted with permission from (Costescu et al., 2015)); animal-like (PABI, E; Probo, F; and Pleo, G) (images reprinted with permission from (Dickstein-Fischer and Fischer, 2014); (Goris et al., 2010), originally published by INTECH as an Open Access work, http://dx.doi.org/10.5772/8129; and (Kim et al., 2013), respectively); and robotic with human traits (NAO, H) (image reprinted with permission from (Shamsuddin et al., 2012)). Also note the robotic model Infanoid (D), a precursor to Keepon (C) that was considered too overwhelming and generated reactions of anxiety and embarrassment in children with ASD (image reprinted with permission from (Kozima et al., 2007)). imitation of facial expressions in children with ASD (Duquette et al., 2008). Thus, Tito was successful in eliciting social interactions in low-functioning young children with ASD (Duquette et al., 2008). Keepon, an interactive robot with a cartoonish, snowman-like appearance (Fig. 2C) has been shown to successfully engage eye contact and facilitate joint attention (Kozima et al., 2007, 2009). A longitudinal study conducted at a day care center over the course of 4 years found that young children with ASD were motivated to interact with Keepon, and that Keepon could effectively engage their attention (Kozima et al., 2007, 2009). The children exhibited caretaking behavior by placing clothing on the robot and feeding it toy food. Keepon also elicited emotional reactions from the children (e.g., Surprise and joy). Furthermore, the children were motivated to share the interests and emotions resulting from the robot interaction with a human adult, thus increasing human interactions as a result of robot interactions. The authors concluded that Keepon's more simplistic forms of expression (limited to atten- tional direction of head and eyes, and body movements to express emotions such as pleasure, excitement, or fear by rocking side to side, bouncing up and down, or vibrating, respectively — no vo- calizations) allowed the children to detect and respond to socially meaningful cues (Kozima et al., 2007, 2009). In another study, Keepon was used in a reversal learning task to assess cognitive flexibility in children with ASD (Costescu et al., 2015). The task required the children to flexibly adapt their behavioral responses to changing environmental rules. Although the children's cognitive flexibility performance was similar during robot interactions and human interactions, the children exhibited more attentional engagement in the reversal learning task and appeared to enjoy the task more (exhibited positive affect more frequently) during in- teractions with Keepon (Costescu et al., 2015). 4,3. An unsuccessful robot model: avoiding the “uncanny valley” of social robotic design Interestingly, a precursor to the Keepon robot named Infanoid was abandoned in favor of the more simplistic Keepon model. Infanoid's body was an upper torso model, approximately the size of a 4-year-old child, with exposed robotic machinery (Fig. 2D). Infanoid had a much higher degree of complexity with 29 actuators (compared to Keepon's 4) controlling a large degree of movement capability to the arms, face, lips, eyebrows, and ears. This high degree of expressivity appeared to generate an overwhelming amount of stimulation, particularly for young children ages 3 and under with ASD who exhibited anxiety and embarrassment upon first being presented with Infanoid (Kozima et al., 2007, 2009). The authors attributed this reaction to the anthropomorphic but highly mechanistic appearance of Infanoid, as well as the overwhelming number of moving parts providing distracting information that was difficult for the children to integrate into a meaningful, holistic social interaction (Kozima et al., 2007, 2009). The shortcomings of Infanoid are highly informative for at least two reasons. First, they speak to the importance of the degree to which a robot has an approachable, human-like appearance. Infa- noid may have fallen into the “uncanny valley” of robotic design (Mori, 1970). This concept describes the fact that people find robots to be more engaging and approachable as the robots become more realistic, but only up to a point. As a robot approaches a stage just short of perfect realism, its appearance becomes disturbing. For robots with these design features the acceptance of, and comfort level with, the robot plummets (the “uncanny valley”), and the robot instead becomes aversively “creepy” (MacDorman et al., 2009). Neural correlates to the uncanny valley phenomenon have been Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 6 E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 suggested in typically developed adults, particularly with respect to mismatch between the appearance and movements of the robot generating prediction errors that ultimately result in the perception that the robot is aversively “not quite right” (Saygin et al., 2012). Avoiding the uncanny valley is particularly important in tailoring therapies for children with ASD, for whom social interactions can be inherently off-putting (and, interestingly, the uncanny valley may be significantly altered in ASD - see (Ueyama, 2015)). The second informative aspect of Infanoid's shortcomings was that certain design features may be overwhelming for individuals with ASD during human social interactions. Human interactions involve high degrees of complexity, numbers of moving parts, and levels of expression - features also attributable to Infanoid and were found to be detrimental - that can form an overwhelming flood of social and sensory cues for individuals with ASD. The key to interactive robots’ therapeutic value as social facilitators may lie in allowing individuals with ASD to experience social cues through a simplified and predictable version of a human interaction. This creates a more perceptually palatable experience that may opti- mize social learning that can be applied to goal-oriented treat- ments and can then be generalized to facilitate human interactions. 4.4. Social robots in animal form Numerous studies have also examined the utility of social robots in animal form when developing therapies for children with ASD. PABI (Penguin for Autism Behavioral Intervention; Fig. 2E) was recently designed as an inexpensive robot that could be made readily available to families of children with ASD as a therapy tool (Dickstein-Fischer et al., 2011). PABI was able to mimic human emotions while maintaining a simplistic, approachable form. With 11 degrees of freedom, PABI could move its head, eyes, eyelids, beak, and wings. PABI was further able to vocalize through pre- recorded sounds and was equipped with face-tracking capability. PABI has been proposed for use as an early-intervention tool for diagnosis, particularly with respect to measurement of gaze di- rection and social gestures (Dickstein-Fischer and Fischer, 2014). This robot can also be effectively utilized in robot-assisted applied behavior analysis (ABA), a commonly used therapeutic approach in ASD that applies principles of learning and motivation to reduce interfering behaviors, teach new skills, and increase targeted pos- itive behaviors (e.g., self-control, social interaction) (Dickstein- Fischer and Fischer, 2014). In a recent study by Vanderborght et al. (2012), a social robot named Probo, which has the appearance of a stuffed elephant toy (Fig. 2F), was used to tell “Social Stories” to children with ASD. These stories depicted scenarios aimed at helping children to better understand social situations and to generate appropriate social behavior (e.g., “How to Say Hello” teaches the child to say hello when s/he meets someone) (Gray, 2000). Probo was able to direct gaze, generate facial expressions (including eye blinking, ear flap- ping, mouth movement, head nodding/shaking), and deliver pre- recorded vocalizations (a neutral male voice) (Goris et al., 2010). The social performance of children with ASD was found to improve when Probo, rather than a human reader, told the “Social Stories” (Vanderborght et al., 2012), indicating added therapeutic value and facilitated social learning. Probo has also been used to examine the use of social robots during play tasks. During a particular play task (making a fruit salad), children with ASD directed more eye contact towards Probo compared to a human counterpart, although other social interaction measures did not significantly differ (Simut et al., 2016). The use of Probo likely creates a more easily understandable social context in which children can learn social skills through repeated tasks with consistent, controlled, predictable stimuli and rules. Additional robotic designs have focused on other animal forms. Kim et al. (2013) studied the interactions of children with a social robot dinosaur compared to interactions with a human adult or an asocial technology (touchscreen computer game). The dinosaur, Pleo (Fig. 2G), was capable of walking, moving its tail and head expressively, blinking, moving its mouth, and pseudo-vocalizing (e.g., “Heee!” for greeting/satisfaction, “Unh uhn” for “no”). The study found that children with ASD ages 4 to 12 produced more speech overall, and directed more speech toward a human adult in the same room, when interacting with Pleo compared to interact- ing with a person or an asocial technology (Kim et al., 2013). Thus, animal forms of social robots appear to also serve as effective social facilitators that may be used in social and communication therapies. 4.5. Social robots in robotic form Recent studies have examined social interactions between children with ASD and a mini-humanoid robot named Nao (Aldebaran Robotics; Fig. 2H). Nao is capable of 25 degrees of freedom allowing it the ability to walk, generate human-like body language, and move its head. Nao is equipped with touch sensors as well as 2 cameras, one located at its mouth, rendering it incapable of lip or jaw movement during speech. However, Nao is capable of emitting vocalizations, either using its standard robotic voice - which is capable of some prosodic inflection - or a pre-recorded human voice. In addition, each of Nao's eyes is made up of 8 LEDs which can be illuminated in different colors or dimmed differen- tially to produce the appearance of blinking. Nao's “simple” facade is thought to reduce confusion and overstimulation in children with ASD (Huskens et al., 2013). Compared to typically developing children, children with ASD spent significantly more time looking at Nao, and the robot was able to successfully facilitate joint attention behaviors (Bekele et al., 2013). In one particular case study of a child with ASD, the boy avoided a human adult's gaze but made eye contact readily and easily with Nao, particularly if Nao's eyes changed color, or if Nao spoke or moved (Shamsuddin et al., 2012). Compared to interactions with other people in a classroom setting, interactions with Nao also improved the boy's repetitive behaviors, Communication, and social interactions (Shamsuddin et al., 2012). In a different study comparing delivery of ABA inter- vention, Nao was found to be as effective as a person in training children with ASD to self-initiate question-asking (Huskens et al., 2013). Interactions with Nao have been shown to improve body coordination, imitation/praxis (ability to plan and execute gestures and actions), and interpersonal synchrony (coordinating actions with those of another, which requires turn-taking, attention, and imitation skills) (Srinivasan et al., 2015). In addition, Nao has been used in a pilot study robotics camp for typically developing (TD) adolescents and those with ASD (Kaboski et al., 2015). The ado- lescents attending the robotics camp learned to cooperatively program Nao robots to perform a social interaction with a crowd (1 ASD: 1 TD per programming pair, with supervising facilitators). This camp experience increased robotics knowledge, teaching the ado- lescents a potential vocational skill, and was also shown to signif- icantly reduce social anxiety in adolescents with ASD by the end of the week-long camp (Kaboski et al., 2015). 5. Towards an optimal robotic model for use in ASD therapies There are a variety of outcome measures of robot-assisted therapy such as 1) generalization to human interactions; 2) increased cooperation/collaboration; 3) reduction of repetitive behaviors and restricted interests; 4) increased sharing and turn- taking behaviors; 5) enhanced imitation or joint attention Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 7 capabilities; and 6) increased motivation and attentional engage- ment. These outcomes vary according to the traits of the robot being used as well as the severity of symptoms for individuals with ASD (Cabibihan et al., 2013; Costa et al., 2010; Dautenhahn, 2007; Diehl et al., 2012, 2014a; Goodrich et al., 2012; Jordan et al., 2013; Pierno et al., 2008). In an assessment of outcomes using different robot-assisted therapy models for ASD, humanoid robots were found to elicit enhanced generalization of skill sets taught during therapy sessions (e.g., turn-taking, sharing) (Ricks and Colton, 2010). Human-like features such as the presence of facial expres- sions, vocalizations, and moving limbs have been shown to engage attention, increase interaction, and improve utilization of intent- matching facial expressions (Lee et al., 2012). However, non- humanoid robots elicited the most attentional engagement (Ricks and Colton, 2010). Social robots with soft edges and coloration that is bright enough to attract attention, but not too bright to the point of overstimulation, have also been found to strike an ideal appearance (Hoa and Cabibihan, 2012; Michaud et al., 2003). Ro- bots with a simple appearance increase levels of interaction and are more readily accepted by children with ASD (Robins et al., 2006). In addition to these features, the gender of both the robot and the individual for whom the social robot therapy is targeted should be considered as important factors when creating individualized therapy plans and optimizing the impact and success of the therapy (Laue, 2015). For instance, typically developed adults were found to rate a robot of the opposite sex to be more trustworthy, engaging, and credible than a robot matching the gender of the individual (Siegel et al., 2009). Emerging evidence suggests a relatively high co-occurrence between gender dysphoria and ASD (Glidden et al., 2016; Van Der Miesen et al., 2016), making it all the more critical to be accurately attuned to the individual's gender identity when developing an optimal therapeutic plan incorporating social robots. Thus, the perceived gender of the robot, as well as the gender identity of the individual with ASD, must be taken into careful consideration for targeted, individualized social therapy strategies in order to facilitate interactions and maximize beneficial effects. 6. Applying systems neuroscience tools to strengthen and extend social robot therapeutic value Although social robots appear to be effective therapy tools, the perceptual mechanisms underlying these benefits remain largely unknown. Given that social interactions rely on audiovisual communication, it seems likely that social robot stimuli confer added multisensory processing benefits that are lacking in human interactions. These benefits may rely on social robots acting as simplified versions of people, allowing more effective filtering of meaningful perceptual stimuli. Recent studies in our lab have begun to address this question by applying systems neuroscience tools to target the multisensory perceptual substrates that may underlie the therapeutic benefits of robots with respect to social skills and communication. Human stimuli may confer helpful social cues (e.g., body language, emotional prosody of speech) to typically developing individuals, which would facilitate enhanced process- ing and result in narrower temporal binding windows for human stimuli compared to robotic stimuli. Conversely, children with ASD may exhibit enhanced processing (as indicated by narrower tem- poral binding windows) for social robotic stimuli compared to more complex, potentially confusing or overwhelming human stimuli. A better understanding of the perceptual substrates underlying the therapeutic benefits of social robots, utilizing systems neuroscience tools, would allow the development of social & behavioral thera- pies that extend these benefits and are better targeted to alleviate perceptual, social, and communication difficulties for individuals with ASD. This could be accomplished in a variety of ways, but one such promising approach is to first identify the potential perceptual benefits conferred by social robots through a simultaneity judge- ment (SJ) task to analyze temporal binding window size. In the SJ task, participants can be shown short videos of robots or humans in which the auditory and visual components of the stimulus occur at the exact same time (synchronous/simultaneous) or are temporally offset by up to 400 ms with either the auditory or the visual component occurring first (Fig. 3). The participant is asked to report whether the auditory and visual components of each video occurred at the same time or at different times. As would be ex- pected, participants report a high degree of simultaneity when the stimuli are in fact synchronous, and report a low degree of simul- taneity for large degrees of temporal offset (e.g., auditory cue pre- ceding visual cue by 400 ms, or vice versa). The temporal binding window is then quantified as the width (in ms) of this approxi- mately bell-shaped curve at 75% of the maximum simultaneity response for each individual (e.g., (Stevenson et al., 2014a)). This SJ task paradigm has been successfully employed using a range of multisensory stimuli from simplistic (a flash of light paired with a beep sound) to complex (speech involving body/face movement and vocalization) (Stevenson and Wallace, 2013). Temporal binding window size analysis has been used in a wide age range of partic- ipants, from children to elderly adults (Bedard and Barnett-Cowan, 2016; Hillock-Dunn and Wallace, 2012; Hillock et al., 2011; Lew- kowicz and Flom, 2014). It has also been successfully directed to- ward elucidating sensory integration impairments in a number of different clinical conditions (Wallace and Stevenson, 2014), including schizophrenia (Foucher et al., 2007), dyslexia (Hairston et al., 2005), and ASD (Stevenson et al., 2014b). Although such analyses have characterized multisensory inte- gration using a variety of stimuli (Stevenson and Wallace, 2013), they have not yet been directed toward characterizing the perception of multisensory social cues from interactive robots. Using videos of social interactions from a social robot, and comparing temporal binding window size for robotic social stimuli compared to videos of comparable human social stimuli, is one method that has great potential for elucidating the perceptual substrates underlying the therapeutic utility of social robots. This methodology relies on systems neuroscience tools as a novel approach towards identifying the multisensory processing benefits that social robots may confer to individuals with ASD through psychophysical assessment of perceptual outcomes. Beyond characterization of potentially enhanced multisensory integration of social robotic cues in children with ASD, it would be of particular interest to extend these benefits, thereby advancing therapeutic effects. This could be accomplished through sensory training and feedback paradigms that have proven useful in other multisensory integration assessments. The temporal binding win- dow is somewhat flexible, and multisensory integrative capacity is capable of adjusting to the temporal properties of environmental cues. This has been shown in animal studies (Sarko et al., 2012; Stein et al., 2014; Xu et al., 2012, 2015) and through human psy- chophysical recalibration effects (Fujisaki et al., 2004; Keetels and Vroomen, 2007, (Keetels and Vroomen, 2008); Navarra et al. 2005; Stetson et al., 2006; Vroomen et al., 2004) as well as through perceptual plasticity and training (Lee and Noppeney, 2011; Powers et al., 2009; Stevenson et al., 2013). A previous study using simple flash-beep stimuli showed that feedback is capable of significantly narrowing the temporal binding window of typically developed adults with as little as 1 day of training (Powers et al., 2009). Audiovisual training paradigms also resulted in changes in neural activity in auditory and visual cortices as well as the posterior superior temporal sulcus (pSTS) (Powers et al., 2012), a brain area known to be critical in audiovisual integration. Such Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 8 E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 Fig. 3. Example trial paradigm for simultaneity judgement task using a representative social interaction of a robot or human shaking the head while saying “no.” Visual motion stimuli (head shake and lip movement for human stimuli; head shake and eyes lighting up for NAO robot) are presented with corresponding auditory stimuli (e.g., robot head shake with robotic voice saying “no”). For positive stimulus onset asynchrony (SOA) conditions, the visual stimuli are presented first with a variable delay in the auditory stimuli (O—400 ms at 50 ms increments, VA conditions; also see Fig. 2A, right side of graph for visual-preceding SOAs). For negative SOA conditions, the auditory stimuli are presented first with a variable delay in the visual stimuli (0O—400 ms at 50 ms increments, AV conditions; also see Fig. 2A, left side of graph for auditory-preceding SOAs). multisensory training paradigms could be applied toward robotic and human social interactions by incorporating similar feedback and training to hone the temporal binding window for individuals with ASD. Through training and feedback informing participants of response accuracy, temporal binding windows could be narrowed, allowing individuals with ASD to more optimally filter the some- times confusing and overwhelming sensory world around them. Through enhancement of the perceptual benefits of social robots, these benefits might ultimately be extended to improving human social interactions and communication. 7. Access to social robot therapies and methodological considerations Although early intervention strategies using social robot thera- pies appear to be effective, this efficacy is somewhat hindered by a lack of affordable, commercially available robots for in-home use accessible to families of children with ASD. For practical reasons, it is also beneficial for the robot to be portable, easy to operate to ensure its utility for children with ASD and their families, and du- rable enough to withstand occasional rough play from children. In an effort to address these issues, more recent robotic models with low manufacturing costs such as PABI (Penguin for Autism Behav- ioral Intervention, described above) have been developed with the goal of increasing affordability and accessibility (Dickstein-Fischer et al., 2011; Dickstein-Fischer and Fischer, 2014). Robotic models that are more complex, more expensive, and require more extensive training to operate - such as the Nao robot, with a current cost of approximately $10,000 - are more amenable to availability in designated clinical sites and research or treatment facilities. Although in such cases geographical proximity may be an issue hindering accessibility to social robot therapy, such availability al- lows social robots to reach a greater number of children with ASD, and in a more controlled and observable assessment environment. Studies involving social robots tend to vary along a number of different dimensions, including the number of interactive sessions, Sample size, free-form vs. structured interactions, and qualitative vs. quantitative analysis. Longitudinal studies are needed to follow children's progress as they advance through the increasingly complex social milieu to adulthood. Standardized measures of targeted behavioral outcomes (e.g., eye contact, turn-taking, imitation, joint attention, triadic interactions, emotion recogni- tion/expression, Self-initiated interactions, attentional engage- ment) are also needed to allow cross-study comparisons of robot design and social interaction efficacy. In addition, increased focus on generalizability of robotic therapies to human social interactions should be emphasized in order to maximally improve daily life. References Abell, F, Krams, M., Ashburner, J., Passingham, R., Friston, K., Frackowiak, R., Happe, F., Frith, C., Frith, U., 1999. The neuroanatomy of autism: a voxel-based whole brain analysis of structural scans. Neuroreport 10 (8), 1647—1651. Adolphs, R., Sears, L., Piven, J., 2001. Abnormal processing of social information from faces in autism. J. Cogn. Neurosci. 13 (2), 232—240. Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 9 American Psychiatric Association, 2013. Diagnostic and statistical manual of mental disorders, 5th ed. Aresti-Bartolome, N., Garcia-Zapirain, B., 2014. Technologies as support tools for persons with autistic spectrum disorder: a systematic review. Int. J. Environ. Res. Public Health 11 (8), 7767—7802. Aylward, E.H., Minshew, N.J., Goldstein, G., Honeycutt, N.A., Augustine, A.M., Yates, K.O., Barta, P.E., Pearlson, G.D., 1999. MRI volumes of amygdala and hippocampus in non-mentally retarded autistic adolescents and adults. Neurology 53 (9), 2145—2150. Baio, J., 2014. Prevalence of autism spectrum disorder among children aged 8 Years — autism and developmental disabilities monitoring network, 11 sites, United States, 2010. Surveill. Summ. 63 (SSO2), 1—21. Baranek, G.T., David, FJ., Poe, M.D., Stone, W.L., Watson, L.R., 2006. Sensory Expe- riences Questionnaire: discriminating sensory features in young children with autism, developmental delays, and typical development. J. Child. Psychol. Psy- chiatry 47 (6), 591-601. Baron-Cohen, S., Ring, H.A., Wheelwright, S., Bullmore, E.T., Brammer, M_J., Simmons, A., Williams, S.C., 1999. Social intelligence in the normal and autistic brain: an fMRI study. Eur. J. Neurosci. 11 (6), 1891-1898. Baron-Cohen, S., Tager-Flusberg, H., Cohen, D., 2000. Understanding Other Minds: Perspectives from Developmental Cognitive Neuroscience. Oxford University Press, Oxford. Bauman, M., Kemper, T.L., 1985. Histoanatomic observations of the brain in early infantile autism. Neurology 35 (6), 866—874. Bedard, G., Barnett-Cowan, M., 2016. Impaired timing of audiovisual events in the elderly. Exp. Brain Res. 234 (1), 331-340. Bekele, E.T., Lahiri, U., Swanson, A.R., Crittendon, J.A., Warren, Z.E., Sarkar, N., 2013. A step towards developing adaptive robot-mediated intervention architecture (ARIA) for children with autism. IEEE Trans. Neural Syst. Rehabil. Eng. 21 (2), 289—299. Bertone, A., Mottron, L., Jelenic, P., Faubert, J., 2003. Motion perception in autism: a “complex” issue. J. Cogn. Neurosci. 15 (2), 218—225. Bertone, A., Mottron, L., Jelenic, P., Faubert, J.. 2005. Enhanced and diminished visuo-spatial information processing in autism depends on_ stimulus complexity. Brain 128 (Pt 10), 2430—2441. Billard, A., Robins, B., Nadel, J., Dautenhahn, K., 2007. Building Robota, a mini- humanoid robot for the rehabilitation of children with autism. Assist. Tech- nol. 19 (1), 37—49. Blake, R., Turner, L.M., Smoski, M.J., Pozdol, S.L., Stone, W.L., 2003. Visual recognition of biological motion is impaired in children with autism. Psychol. Sci. 14 (2), 151-157. Boddaert, N., Chabane, N., Belin, P., Bourgeois, M., Royer, V., Barthelemy, C., Mouren- Simeoni, M.C., Philippe, A., Brunelle, F, Samson, Y., Zilbovicius, M., 2004a. Perception of complex sounds in autism: abnormal auditory cortical processing in children. Am. J. Psychiatry 161 (11), 2117—2120. Boddaert, N., Chabane, N., Gervais, H., Good, C.D., Bourgeois, M., Plumet, M.H., Barthelemy, C., Mouren, M.C., Artiges, E., Samson, Y., Brunelle, F, Frackowiak, R.S., Zilbovicius, M., 2004b. Superior temporal sulcus anatomical abnormalities in childhood autism: a voxel-based morphometry MRI study. Neuroimage 23 (1), 364—369. Bonnel, A., Mottron, L., Peretz, I., Trudel, M., Gallun, E., Bonnel, A.M., 2003. Enhanced pitch sensitivity in individuals with autism: a signal detection analysis. J. Cogn. Neurosci. 15 (2), 226—235. Cabibihan, J.-J., Javed, H., Ang, M., Aljunied, S.M., 2013. Why robots? A survey on the roles and benefits of social robots in the therapy of children with autism. Int. J. Soc. Robotics 5 (4), 593—618. Cascio, C., McGlone, F., Folger, S., Tannan, V., Baranek, G., Pelphrey, K.A., Essick, G., 2008. Tactile perception in adults with autism: a multidimensional psycho- physical study. J. Autism Dev. Disord. 38 (1), 127—137. Cascio, C.J., Gu, C., Schauder, K.B., Key, A.P., Yoder, P., 2015. Somatosensory event- related potentials and association with tactile behavioral responsiveness pat- terns in children with ASD. Brain Topogr. 28 (6), 895—903. Celani, G., Battacchi, M.W., Arcidiacono, L., 1999. The understanding of the emotional meaning of facial expressions in people with autism. J. Autism Dev. Disord. 29 (1), 57—66. Chaminade, T., Da Fonseca, D., Rosset, D., Lutcher, E., Cheng, G., Deruelle, C., 2012. fMRI study of young adults with autism interacting with a humanoid robot. IEEE RO-MAN: the 21st IEEE International Symposium on Robot and Human Interactive Communication. Sept. 9—13, Paris, France. Charman, T., Swettenham, J., Baron-Cohen, S., Cox, A., Baird, G., Drew, A., 1997. In- fants with autism: an investigation of empathy, pretend play, joint attention, and imitation. Dev. Psychol. 33 (5), 781—789. Ciesielski, K.T., Knight, J.E., Prince, R.J., Harris, R.J., Handmaker, S.D., 1995. Event- related potentials in cross-modal divided attention in autism. Neuropsychologia 33 (2), 225—246. Coeckelbergh, M., Pop, C., Simut, R., Peca, A., Pintea, S., David, D., Vanderborght, B., 2016. A survey of expectations about the role of robots in robot-assisted therapy for children with ASD: ethical acceptability, trust, sociability, appearance, and attachment. Sci. Eng. Ethics 22, 47—65. Costa, S., Santos, C., Soares, F., Ferreira, M., Moreira, F., 2010. Promoting interaction amongst autistic adolescents using robots. Conf. Proc. IEEE Eng. Med. Biol. Soc. 2010, 3856—3859. Costescu, C.A., Vanderborght, B., David, D.O., 2015. Reversal learning task in children with autism spectrum disorder: a robot-based approach. J. Autism Dev. Disord. 45 (11), 3715-3725. Dalton, K.M., Nacewicz, B.M., Johnstone, T., Schaefer, H.S., Gernsbacher, M.A., Goldsmith, H.H., Alexander, A.L., Davidson, R.J., 2005. Gaze fixation and the neural circuitry of face processing in autism. Nat. Neurosci. 8 (4), 519—526. Dapretto, M., Davies, MLS., Pfeifer, J.H., Scott, A.A., Sigman, M., Bookheimer, S.Y., Iacoboni, M., 2006. Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders. Nat. Neurosci. 9 (1), 28-30. Dautenhahn, K., 1999. Robots as social actors: aurora and the case of autism. Proc. Third Cogn. Technol. Conf. 359—374. Dautenhahn, K., 2007. Socially intelligent robots: dimensions of human-robot interaction. Philos. Trans. R. Soc. Lond B Biol. Sci. 362 (1480), 679—704. Dautenhahn, K., Billard, A., 2002. Games children with autism can play with Robota, a humanoid robotic doll. In: Universal Access and Assistive Technology: Pro- ceedings of the Cambridge Workshop on AU and AT. Springer, London, pp. 179—190. Dautenhahn, K., Werry, I., 2004. Towards interactive robots in autism therapy: background, motivation and challenges. Pragmat. Cognition 12 (1), 1—35. Dautenhahn, K., Nehaniv, C.L., Walters, M.L., Robins, B., Kose-Bagci, H., Mirza, N.A., Blow, M., 2009. KASPAR - a minimally expressive humanoid robot for human- robot interaction research. Appl. Bionics Biomechanics 6 (3—4), 369-397. Dickstein-Fischer, L., Fischer, G.S., 2014. Combining psychological and engineering approaches to utilizing social robots with children with autism. Conf. Proc. IEEE Eng. Med. Biol. Soc. 2014, 792—795. Dickstein-Fischer, L., Alexander, E., Yan, X., Su, H., Harrington, K., Fischer, G.S., 2011. An affordable compact humanoid robot for Autism Spectrum Disorder in- terventions in children. Conf. Proc. IEEE Eng. Med. Biol. Soc. 2011, 5319—5322. Diehl, J.J., Schmitt, L.M., Villano, M., Crowell, C.R., 2012. The clinical use of robots for individuals with autism spectrum disorders: a critical review. Res. Autism Spectr. Disord. 6 (1), 249—262. Diehl, J.J., Crowell, C.R., Villano, M., Wier, K., Tang, K., Riek, L., 2014a. The clinical applications of robots in the diagnosis and treatment of autism spectrum dis- orders (ASD). In: Patel, V.B., Preedy, V.R., Martin, C.R. (Eds.), A Comprehensive Guide to Autism. Springer, Berlin. Diehl, J.J., Crowell, C.R., Villano, M., Wier, K., Tang, K., Riek, L.D., 2014b. Clinical applications of robots in autism spectrum disorder diagnosis and treatment. In: Patel, V.B., Preedy, V.R., Martin, C.R. (Eds.), Comprehensive Guide to Autism. Springer, New York, pp. 411—422. Donohue, S.E., Darling, E.F, Mitroff, S.R., 2012. Links between multisensory pro- cessing and autism. Exp. Brain Res. 222 (4), 377—387. Duquette, A., Michaud, F., Mercier, H., 2008. Exploring the use of a mobile robot as an imitation agent with children with low-functioning autism. Aut. Robots 24 (2), 147-157. Feil-Seifer, D., Mataric, M.J., 2009. Toward socially assistive robotics for augmenting interventions for children with autism spectrum disorders. Exp. Robot. 54, 201—210. Foss-Feig, J.H., Kwakye, L.D., Cascio, CJ., Burnette, C.P., Kadivar, H., Stone, W.L., Wallace, M.T., 2010. An extended multisensory temporal binding window in autism spectrum disorders. Exp. Brain Res. 203 (2), 381—389. Foss-Feig, J.H., McGugin, R.W., Gauthier, I., Mash, L.E., Ventola, P., Cascio, CJ., 2016. A functional neuroimaging study of fusiform response to restricted interests in children and adolescents with autism spectrum disorder. J. Neurodev. Disord. 8, 15. Foucher, J.R., Lacambre, M., Pham, B.T., Giersch, A., Elliott, M.A., 2007. Low time resolution in schizophrenia Lengthened windows of simultaneity for visual, auditory and bimodal stimuli. Schizophr. Res. 97 (1—3), 118-127. Fujisaki, W., Shimojo, S., Kashino, M., Nishida, S., 2004. Recalibration of audiovisual simultaneity. Nat. Neurosci. 7 (7), 773—778. Gillott, A., Furniss, F., Walter, A., 2001. Anxiety in high-functioning children with autism. Autism 5 (3), 277—286. Glidden, D., Bouman, W.P., Jones, B.A., Arcelus, J., 2016. Gender dysphoria and autism spectrum disorder: a systematic review of the literature. Sex. Med. Rev. 4 (1), 3-14. Goodrich, M.A., Colton, M., Brinton, B., Fujiki, M., Atherton, J.A., Robinson, L., 2012. Incorporating a robot into an autism therapy team. IEEE Intell. Syst. 52—59, Goris, K., Saldien, J., Vanderborght, B., Lefeber, D., 2010. Probo, an intelligent hug- gable robot for HRI studies with children. In: Chugo, D. (Ed.), Human-robot Interaction. Intech. Grandin, T., 2000. My Experiences with Visual Thinking, Sensory Problems, and Communication Difficulties. Autism Research Institute. Gray, C., 2000. The New Social Story Book. Future Horizons, Inc. Grelotti, D.J., Klin, A.J., Gauthier, I., Skudlarski, P., Cohen, D.J., Gore, J.C., Volkmar, F.R., Schultz, R.T., 2005. fMRI activation of the fusiform gyrus and amygdala to cartoon characters but not to faces in a boy with autism. Neuropsychologia 43 (3), 373-385. Hadjikhani, N., Joseph, R.M., Manoach, D.S., Naik, P. Snyder, J., Dominick, K., Hoge, R., Van den Stock, J., Tager Flusberg, H., de Gelder, B., 2009. Body ex- pressions of emotion do not trigger fear contagion in autism spectrum disorder. Soc. Cogn. Affect Neurosci. 4 (1), 70—78. Hairston, W.D., Burdette, J.H., Flowers, D.L., Wood, F.B., Wallace, M.T., 2005. Altered temporal profile of visual-auditory multisensory interactions in dyslexia. Exp. Brain Res. 166 (3—4), 474—480. Hillock, A.R., Powers, A.R., Wallace, M.T., 2011. Binding of sights and sounds: age- related changes in multisensory temporal processing. Neuropsychologia 49 (3), 461—467. Hillock-Dunn, A., Wallace, M.T., 2012. Developmental changes in the multisensory Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 10 E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 temporal binding window persist into adolescence. Dev. Sci. 15 (5), 688—696. Hinds, PJ., Roberts, T.L., Jones, H., 2004. Whose job is it anyway? A study of human- robot interaction in a collaborative task. Human-Computer Interact. 19 (1), 151-181. Hoa, T.D., Cabibihan, J.-J., 2012. Cute and soft: baby steps in designing robots for children with autism. Proc of the workshop at SIGGRAPH, Asia, Singapore. Howard, M.A., Cowell, P.E., Boucher, J., Broks, P., Mayes, A., Farrant, A., Roberts, N., 2000. Convergent neuroanatomical and behavioural evidence of an amygdala hypothesis of autism. Neuroreport 11 (13), 2931—2935. Huskens, B., Verschuur, R., Gillesen, J., Didden, R., Barakova, E., 2013. Promoting question-asking in school-aged children with autism spectrum disorders: effectiveness of a robot intervention compared to a human-trainer intervention. Dev. Neurorehabil 16 (5), 345—356. Ingersoll, B., 2008. The social role of imitation in autism: implications for treatment of imitation deficits. Infants Young Child. 21 (2), 107-119. Jordan, K., King, M., Hellersteth, S., Wiren, A., Mulligan, H., 2013. Feasibility of using a humanoid robot for enhancing attention and social skills in adolescents with autism spectrum disorder. Int. J. Rehabil. Res. 36 (3), 221—227. Kaboski, J.R., Diehl, J.J., Beriont, J., Crowell, C.R., Villano, M., Wier, K., Tang, K., 2015. Brief report: a pilot summer robotics camp to reduce social anxiety and improve social/vocational skills in adolescents with ASD. J. Autism Dev. Disord. 45 (12), 3862—3869. Kaiser, M.D., Shiffrar, M., 2009. The visual perception of motion by observers with autism spectrum disorders: a review and synthesis. Psychon. Bull. Rev. 16 (5), 761—777. Kanner, L., 1943. Autistic disturbances of affective contact. Nerv. Child. 2, 217—250. Keetels, M., Vroomen, J., 2007. No effect of auditory-visual spatial disparity on temporal recalibration. Exp. Brain Res. 182 (4), 559—565. Keetels, M., Vroomen, J., 2008. Temporal recalibration to tactile-visual asynchro- nous stimuli. Neurosci. Lett. 430 (2), 130—134. Kern, J.K., 2002. The possible role of the cerebellum in autism/PDD: disruption of a multisensory feedback loop. Med. Hypotheses 59 (3), 255—260. Kientz, M.A., Dunn, W., 1997. A comparison of the performance of children with and without autism on the sensory profile. Am. J. Occup. Ther. 51 (7), 530—537. Kim, E.S., Berkovits, L.D., Bernier, E.P., Leyzberg, D., Shic, F., Paul, R., Scassellati, B., 2013. Social robots as embedded reinforcers of social behavior in children with autism. J. Autism Dev. Disord. 43 (5), 1038—1049. Kleinhans, N.M., Richards, T., Sterling, L., Stegbauer, K.C., Mahurin, R., Johnson, L.C., Greenson, J., Dawson, G., Aylward, E., 2008. Abnormal functional connectivity in autism spectrum disorders during face processing. Brain 131 (Pt 4), 1O00—1012. Kozima, H., Nakagawa, C., Yasuda, Y., 2007. Children-robot interaction: a pilot study in autism therapy. Prog. Brain Res. 164, 385—400. Kozima, H., Michalowski, M.P., Nakagawa, C., 2009. Keepon: a playful robot for research, therapy, and entertainment. Int. J. Soc. Robot. 1, 3—18. Kuriki, S., Tamura, Y., Igarashi, M., Kato, N., Nakano, T., 2016. Similar impressions of humanness for human and artificial singing voices in autism spectrum disor- ders. Cognition 153, 1—5. Kwakye, L.D., Foss-Feig, J.H., Cascio, CJ., Stone, W.L., Wallace, M.T., 2011. Altered auditory and multisensory temporal processing in autism spectrum disorders. Front. Integr. Neurosci. 4, 129. Laue, C.L., 2015. Considering the effects of gender in child-robot interaction studies: comment on Srinivasan, et Al. (2013). Percept. Mot. Ski. 120 (1), 336—342. Lee, H., Noppeney, U., 2011. Long-term music training tunes how the brain temporally binds signals from multiple senses. Proc. Natl. Acad. Sci. U. S. A. 108 (51), E1441—E1450. Lee, J., Takehashi, H., Nagai, C., Obinata, G., Stefanov, D., 2012. Which robot features can stimulate better responses from children with autism in robot-assisted therapy? Int. J. Adv. Robotic Syst. 9 (72), 1-6. Leekam, S., Baron-Cohen, S., Perrett, D., Milders, M., Brown, S., 1997. Eye-direction detection: a dissociation between geometric and joint attention skills in autism. Br. J. Dev. Psychol. 15 (1), 77—95. Leekam, S.R., Nieto, C., Libby, S.J., Wing, L., Gould, J., 2007. Describing the sensory abnormalities of children and adults with autism. J. Autism Dev. Disord. 37 (5), 894—910. Lewkowicz, D.J., Flom, R., 2014. The audiovisual temporal binding window narrows in early childhood. Child. Dev. 85 (2), 685—694. Lord, C., Cook, E.H., Leventhal, B.L., Amaral, D.G., 2000. Autism spectrum disorders. Neuron 28 (2), 355—363. MacDorman, K.F., Green, R.D., Ho, C.C., Koch, C.T., 2009. Too real for comfort? Un- canny responses to computer generated faces. Comput. Hum. Behav. 25 (3), 695-710. Markram, K., Markram, H., 2010. The intense world theory - a unifying theory of the neurobiology of autism. Front. Hum. Neurosci. 4, 224. Markram, H., Rinaldi, T., Markram, K., 2007. The intense world syndrome—an alternative hypothesis for autism. Front. Neurosci. 1 (1), 77—96. Meltzoff, A.N., Decety, J.. 2003. What imitation tells us about social cognition: a rapprochement between developmental psychology and cognitive neurosci- ence. Philos. Trans. R. Soc. Lond B Biol. Sci. 358 (1431), 491—500. Meredith, M.A., Nemitz, J.W., Stein, B.E., 1987. Determinants of multisensory inte- gration in superior colliculus neurons. I. Temporal factors. J. Neurosci. 7 (10), 3215—3229. Michaud, F., Duquette, A., Nadeau, I., 2003. Characteristics of mobile robotic toys for children with pervasive developmental disorders. Proc IEEE Int. Conf. Syst. man Cybern. 2938—2943. Minshew, N.J., Hobson, J.A., 2008. Sensory sensitivities and performance on sensory perceptual tasks in high-functioning individuals with autism. J. Autism Dev. Disord. 38 (8), 1485-1498. Mori, M., 1970. Bukimi no tani [the uncanny valley]. Energy 7, 33—35. Mottron, L., Dawson, M., Soulieres, I., Hubert, B., Burack, J., 2006. Enhanced perceptual functioning in autism: an update, and eight principles of autistic perception. J. Autism Dev. Disord. 36 (1), 27—43. Mundy, P., Sigman, M., 1989. The theoretical implications of joint-attention deficits in autism. Dev. Psychopathol. (3), 173—183. Nacewicz, B.M., Dalton, K.M., Johnstone, T., Long, M.T., McAuliff, E.M., Oakes, T.R., Alexander, A.L., Davidson, R.J., 2006. Amygdala volume and nonverbal social impairment in adolescent and adult males with autism. Arch. Gen. Psychiatry 63 (12), 1417-1428. Navarra, J., Vatakis, A.. Zampini, M., Soto-Faraco, S., Humphreys, W., Spence, C., 2005. Exposure to asynchronous audiovisual speech extends the temporal window for audiovisual integration. Brain Res. Cogn. Brain Res. 25 (2), 499—507. O'Neill, M., Jones, R.S., 1997. Sensory-perceptual abnormalities in autism: a case for more research? J. Autism Dev. Disord. 27 (3), 283—293. O'Riordan, M., Passetti, F, 2006. Discrimination in autism within different sensory modalities. J. Autism Dev. Disord. 36 (5), 665—675. Pennisi, P., Tonacci, A., Tartarisco, G., Billeci, L., Ruta, L., Gangemi, S., Pioggia, G., 2016. Autism and social robotics: a systematic review. Autism Res. 9 (2), 165-183. Pierce, K., Muller, R.A., Ambrose, J., Allen, G., Courchesne, E., 2001. Face processing occurs outside the fusiform 'face area’ in autism: evidence from functional MRI. Brain 124 (Pt 10), 2059—2073. Pierno, A.C., Mari, M., Lusher, D., Castiello, U., 2008. Robotic movement elicits visuomotor priming in children with autism. Neuropsychologia 46 (2), 448—454. Powers 3rd, A.R., Hillock, A.R., Wallace, M.T., 2009. Perceptual training narrows the temporal window of multisensory binding. J. Neurosci. 29 (39), 12265-12274. Powers 3rd, A.R., Hevey, M.A., Wallace, M.T., 2012. Neural correlates of multisensory perceptual learning. J. Neurosci. 32 (18), 6263—6274. Puts, N.A., Wodka, E.L, Tommerdahl, M., Mostofsky, S.H., Edden, R.A., 2014. Impaired tactile processing in children with autism spectrum disorder. J. Neurophysiol. 111 (9), 1803—1811. Reeves, B., Nass, C., 1996. The Media Equation: How People Treat Computers, Television, and New Media like Real People and Places. Center for the Studies of Language and Information Publications, Stanford, CA. Ricks, D.J., Colton, M.B., 2010. Trends and considerations in robot-assisted autism therapy. Robotics and Automation (ICRA). IEEE Int. Conf. 4354—4359, Robins, B., Dautenhahn, K., Te Boekhorst, R., Billard, A., 2005. Robotic assistants in therapy and education of children with autism: can a small humanoid robot help encourage social interaction skills? Univers. Access Inf. Soc. 4 (2), 105—120. Robins, B., Dautenhahn, K., Dubowski, J., 2006. Does appearance matter in the interaction of children with autism with a humanoid robot? Interact. Stud. 7, 479—512. Rogers, S.J., Pennington, B.F., 1991. A theoretical approach to the deficits in infantile autism. Dev. Psychopathol. 3, 137—162. Rogers, S.J., Hepburn, S., Wehner, E., 2003. Parent reports of sensory symptoms in toddlers with autism and those with other developmental disorders. J. Autism Dev. Disord. 33 (6), 631-642. Sarko, D.K., Nidiffer, A.R., Powers, I.A., Ghose, D., Hillock-Dunn, A., Fister, M.C., Krueger, J., Wallace, M.T., 2012. Spatial and temporal features of multisensory processes: bridging animal and human studies. In: Murray, M.M., Wallace, M.T. (Eds.), The Neural Bases of Multisensory Processes. Boca Raton (FL). Sarko, D.K., Ghose, D., Wallace, M.T., 2013. Convergent approaches toward the study of multisensory perception. Front. Syst. Neurosci. 7, 81. Saygin, A.P., Chaminade, T., Ishiguro, H., Driver, J., Frith, C., 2012. The thing that should not be: predictive coding and the uncanny valley in perceiving human and humanoid robot actions. Soc. Cogn. Affect Neurosci. 7 (4), 413-422. Scassellati, B., 2007. How social robots will help us diagnose, treat, and understand autism. Robotics Res. 28, 552—563. Scassellati, B., Admoni, H., Mataric, M., 2012. Robots for use in autism research. Annu. Rev. Biomed. Eng. 14, 275—294. Schultz, R.T., 2005. Developmental deficits in social perception in autism: the role of the amygdala and fusiform face area. Int. J. Dev. Neurosci. 23 (2—3), 125-141. Schumann, C.M., Amaral, D.G., 2006. Stereological analysis of amygdala neuron number in autism. J. Neurosci. 26 (29), 7674—7679. Senkowski, D., Schneider, T.R., Foxe, J.J., Engel, A.K., 2008. Crossmodal binding through neural coherence: implications for multisensory processing. Trends Neurosci. 31 (8), 401—409. Shams, L., Kamitani, Y., Shimojo, S., 2002. Visual illusion induced by sound. Brain Res. Cogn. Brain Res. 14 (1), 147—152. Shamsuddin, S., Yussof, H., Ismail, L.., Mohamed, S., Hanapiah, F.A., Zahari, N.I, 2012. Initial response in HRI-a case study on evaluation of a child with autism spectrum disorders interacting with a humanoid robot Nao. Proc. Eng. 41, 1448-1455. Siegel, M., Breazeal, C., Norton, M.I., 2009. Persuasive robotics: the influence of robot gender on human behavior. Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '09), St. Louis, MO, Oct. 10- 15, 2563—2568. Simut, R.E., Vanderfaeillie, J., Peca, A., Van de Perre, G., Vanderborght, B., 2016. Children with autism spectrum disorders make a fruit salad with Probo, the social robot: an interaction study. J. Autism Dev. Disord. 46 (1), 113—126. Spencer, J., O'Brien, J., Riggs, K., Braddick, O., Atkinson, J., Wattam-Bell, J., 2000. Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. E Sartorato et al. / Journal of Psychiatric Research 90 (2017) 1—11 11 Motion processing in autism: evidence for a dorsal stream deficiency. Neuro- report 11 (12), 2765—2767. Spezio, M.L., Huang, P.Y., Castelli, F, Adolphs, R., 2007. Amygdala damage impairs eye contact during conversations with real people. J. Neurosci. 27 (15), 3994—3997. Srinivasan, S.M., Kaur, M., Park, I.K., Gifford, T.D., Marsh, K.L., Bhat, A.N., 2015. The effects of rhythm and robotic interventions on the imitation/praxis, interper- sonal synchrony, and motor performance of children with autism spectrum disorder (ASD): a pilot randomized controlled trial. Autism Res. Treat. 2015, 736516. Stein, B.E., Stanford, T.R., Rowland, B.A., 2014. Development of multisensory inte- gration from the perspective of the individual neuron. Nat. Rev. Neurosci. 15 (8), 520—535. Sterling, L., Dawson, G., Estes, A., Greenson, J., 2008. Characteristics associated with presence of depressive symptoms in adults with autism spectrum disorder. J. Autism Dev. Disord. 38 (6), 1011—1018. Stetson, C., Cui, X., Montague, P.R., Eagleman, D.M., 2006. Motor-sensory recali- bration leads to an illusory reversal of action and sensation. Neuron 51 (5), 651-659. Stevenson, R.A., Wallace, M.T., 2013. Multisensory temporal integration: task and stimulus dependencies. Exp. Brain Res. 227 (2), 249—261. Stevenson, R.A., Wilson, M.M., Powers, A.R., Wallace, M.T., 2013. The effects of visual training on multisensory temporal processing. Exp. Brain Res. 225 (4), 479—489. Stevenson, R.A., Ghose, D., Fister, J.K., Sarko, D.K., Altieri, N.A., Nidiffer, A.R., Kurela, L.R., Siemann, J.K., James, T.W., Wallace, M.T., 2014a. Identifying and quantifying multisensory integration: a tutorial review. Brain Topogr. 27 (6), 707—730. Stevenson, R.A., Siemann, J.K., Schneider, B.C., Eberly, H.E., Woynaroski, T.G., Camarata, S.M., Wallace, M.T., 2014b. Multisensory temporal integration in autism spectrum disorders. J. Neurosci. 34 (3), 691—697. Talay-Ongan, A., Wood, K., 2000. Unusual sensory sensitivities in autism: a possible crossroads. Int. J. Disabil. Dev. Educ. 47, 201—212. Tanaka, F., Cicourel, A., Movellan, J.R., 2007. Socialization between toddlers and robots at an early childhood education center. Proc. Natl. Acad. Sci. U. S. A. 104 (46), 17954—17958. Tavassoli, T., Bellesheim, K., Tommerdahl, M., Holden, J.M., Kolevzon, A., Buxbaum, J.D., 2016. Altered tactile processing in children with autism spec- trum disorder. Autism Res. 9 (6), 616—620. Ueyama, Y., 2015. A bayesian model of the uncanny valley effect for explaining the effects of therapeutic robots in autism spectrum disorder. PLoS One 10 (9), e0138642. Van Der Miesen, A.I., Hurley, H., De Vries, A.L., 2016. Gender dysphoria and autism spectrum disorder: a narrative review. Int. Rev. Psychiatry 28 (1), 70—80. Vanderborght, B., Simut, R., Saldien, J., Pop, C., Rusu, A.S., Pintea, S., Lefeber, D., David, D.O., 2012. Using the social robot Probo as a social story telling agent for children with ASD. Interact. Stud. 13 (3), 348—372. Vroomen, J., Keetels, M., de Gelder, B., Bertelson, P., 2004. Recalibration of temporal order perception by exposure to audio-visual asynchrony. Brain Res. Cogn. Brain Res. 22 (1), 32—35. Wainer, J., Dautenhahn, K., Robins, B., Amirabdollahian, F., 2010. Collaborating with Kaspar: Using an Autonomous Humanoid Robot to Foster Cooperative Dyadic Play Among Children with Autism. IEEE, pp. 631—638. Wallace, M.T., Stevenson, R.A., 2014. The construct of the multisensory temporal binding window and its dysregulation in developmental disabilities. Neuro- psychologia 64, 105—123. Webb, BJ., Miller, S.P., Pierce, T.B., Strawser, S., Jones, W.P., 2004. Effects of social skill instruction for high-functioning adolescents with autism spectrum disor- ders. Focus Autism Other Dev. Disabil. 19 (1), 53-62. Werry, I., Dautenhahn, K., Harwin, W., 2001. Investigating a robot as a therapy partner for children with autism. Procs AAATE 6. Williams, J.H., Whiten, A., Singh, T., 2004. A systematic review of action imitation in autistic spectrum disorder. J. Autism Dev. Disord. 34 (3), 285—299. Xu, J., Yu, L., Rowland, B.A., Stanford, T.R., Stein, B.E., 2012. Incorporating cross- modal statistics in the development and maintenance of multisensory inte- gration. J. Neurosci. 32 (7), 2287-2298. Xu, J., Yu, L., Stanford, T.R., Rowland, B.A., Stein, B.E., 2015. What does a neuron learn from multisensory experience? J. Neurophysiol. 113 (3), 883—889. Zilbovicius, M., Meresse, I., Chabane, N., Brunelle, F., Samson, Y., Boddaert, N., 2006. Autism, the superior temporal sulcus and social perception. Trends Neurosci. 29 (7), 359-366. Descargado para Anonymous User (n/a) en University of Rosario de ClinicalKey.es por Elsevier en diciembre 13, 2023. Para uso personal exclusivamente. No se permiten otros usos sin autorizacion. Copyright ©2023. Elsevier Inc. Todos los derechos reservados. 