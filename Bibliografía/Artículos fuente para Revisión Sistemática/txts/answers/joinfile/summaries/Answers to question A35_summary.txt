There were 81 papers that incorporated robot control systems in their studies, while 15 papers did not include such systems. The analysis reveals extensive use of various robot control mechanisms across different research implementations.

The most commonly implemented control systems were expressive body movement control and movement capability control. Many studies utilized humanoid robots, particularly the NAO robot, which features comprehensive movement control systems including head turning, arm gestures, and full-body movements (Alnajjar et al., 2021; Conti et al., 2020; Santos et al., 2023). These systems were primarily employed to facilitate social interaction and engagement with participants.

Several studies incorporated sophisticated control mechanisms for facial expressions and eye movements. For instance, animated eye movement control and gaze expression control were implemented in multiple studies (Wood et al., 2017; Yun et al., 2016; Abdelmohsen & Arafa, 2021) to enhance social communication and joint attention skills. Some robots featured LED-based expression systems to convey emotions and enhance social interaction (Silvera-Tawil et al., 2018; Yin & Tung, 2013).

Touch-reactive response systems were also present in several implementations, particularly in studies focusing on physical interaction and motor skills development (Brivio et al., 2021; Bonarini et al., 2016). These systems allowed for responsive interaction based on physical contact with the robot, enhancing the interactive experience.

Life-like expression generation was implemented in various studies through combinations of movement, sound, and visual feedback systems. For example, some robots were programmed with complex behavioral patterns that mimicked human-like expressions and responses (Sakka & Gaboriau, 2017; QTrobot in Tartarisco et al., 2022). The QTrobot, specifically, featured 12 degrees of freedom for upper-body gestures, enabling natural-looking movements and expressions.

The sophistication of these control systems varied significantly across studies, ranging from basic movement controls in simpler robots like the Bee-Bot (Chaldi & Mantzanidou, 2021) to complex, multi-modal control systems in advanced humanoid robots. This variation in control system complexity appears to be aligned with the specific therapeutic or educational objectives of each study.