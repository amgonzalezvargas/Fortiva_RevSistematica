There were 50 papers out of 97 that focused on developing or evaluating social cognition skills in individuals with intellectual disabilities, representing approximately 52% of the analyzed studies. The research efforts concentrated on various aspects of social cognition, with particular emphasis on fundamental social interaction capabilities.

Joint attention emerged as a prominent focus area, with multiple studies specifically targeting this skill (Scassellati, 2018; Alnajjar et al., 2021; Carlson et al., 2018; Charron et al., 2017; Kajopoulos et al., 2015). These studies implemented structured interventions using social robots to facilitate the development of joint attention abilities, which are crucial for social interaction and learning.

Facial expression recognition and emotional understanding were also extensively studied. Several researchers (Costa et al., 2014; Lebersfeld et al., 2018; Li et al., 2020; Tartarisco et al., 2022) developed robot-assisted interventions specifically designed to enhance participants' ability to recognize and interpret facial expressions. These studies often utilized humanoid robots with programmable facial features to create controlled learning environments.

Imitation skills received significant attention in the literature, with multiple studies (Valadao et al., 2016; Bonarini et al., 2014; Conti et al., 2020; Marathaki et al., 2022; Simlesa et al., 2022) implementing robot-based protocols to develop these fundamental social learning abilities. The research typically employed humanoid robots that could demonstrate actions and gestures for participants to replicate.

Visual perspective-taking and mentalizing skills were addressed in several studies (Marino et al., 2020; Wood et al., 2017; Wood et al., 2019), with researchers developing specific protocols using humanoid robots to help participants understand others' viewpoints and mental states. These interventions often incorporated structured activities that required participants to consider different perspectives and interpret social situations.

Gesture recognition and body language interpretation were also investigated (Abdelmohsen & Arafa, 2021; Tobar et al., 2021; Rakhymbayeva & Sandygulova, 2021), with researchers developing interactive scenarios where robots demonstrated and responded to various gestures and body movements. These studies typically employed sophisticated sensing systems to track and evaluate participants' responses to social cues.

The research methodologies predominantly utilized humanoid robots, particularly the NAO robot platform, which appeared frequently across studies due to its programmable features and ability to demonstrate human-like social behaviors. The interventions generally combined structured activities with interactive elements, allowing for both controlled skill development and naturalistic social interaction practice.