25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) August 26-31, 2016. Columbia University, NY, USA Robotic Behavioral Intervention to Facilitate Eye Contact and Reading Emotions of Children with Autism Spectrum Disorders Sang-Seok Yun, JongSuk Choi, Sung-Kee Park Abstract—Social skills training of children with autism spectrum disorders (ASD) is not an easy problem enough to typically spend a lot of time and repetitive efforts. As means of assistance, we propose and examine the feasibility of a robotic behavioral intervention system to facilitate social development of the children with ASD and relieve operational burden during training process. To this end, based on well-known behavioral treatment protocols, the robot system incorporates robotic stimulation design, recognition modules for human activities, and reinforcement procedure in the interaction scheme design. Using these configuration, it repeatedly perform a role of training eye contact and reading emotions targeted at preschoolers with a high functioning level in the planned training process. Through showing an advantage in a comparative analysis with control group taught by humans, we verified that the proposed system can contribute to evoke positive response of children with ASD and_ provide labor-saving effect on the clinical environment. I. INTRODUCTION Autism spectrum disorders (ASD) features translate into difficulties in engaging in social activities and its proportion in children is now a rising trend according to the recent report of the Centers for Disease Control and Prevention (CDC), which estimates 1 in 68 children has been identified with ASD in the United States [1]. To address the need for appropriate treatment for children with ASD, a range of social skills intervention techniques have been performed over a series of years [2], and the American Psychological Association recommends that clinicians use medication and behavioral interventions to help children cope with autism as treatment options [3]. From simple toys to human-like playmates, features of the robot’s appearance have captured the interest, curiosity, and attention of both children with autism and _ typically developing children [4]. In addition, studies using robots *This work was supported by the National Research Council of Science & Technology (NST) grant by the Korea government (MISP) (No. CRC-15-04-KIST) and by the Implementation of Technologies for Identification, Behavior, and Location of Human based on Sensor Network Fusion Program through the Ministry of Trade, Industry and Energy (Grant No. 10041629). Sang-Seok Yun is with the Center for Robotics Research, Korea Institute of Science and Technology (KIST), Seoul 136-791, Republic of Korea (e-mail: yssmecha@gmail.com). JongSuk Choi is with the Center for Robotics Research, Korea Institute of Science and Technology (KIST), Seoul 136-791, Republic of Korea (e-mail: cjs@kist.re.kr). Sung-Kee Park is with the Center for Robotics Research, Korea Institute of Science and Technology (KIST), Seoul 136-791, Republic of Korea (Corresponding author to provide phone: +82-2-958-5626; e-mail: skee@kist.re.kr). 978-1-5090-3929-6/16/$31.00 ©2016 IEEE 694 therapeutically for children with autism have shown their strengths and effectiveness as interesting mediators of social interaction, therapeutic tools, and mitigated manual operation [5, 6]. In particular, recent researches reported that robots provide positive reinforcement for correct responses [7] and reduce negative avoidance behaviors by improving children’s attention through mutual distances [8]. From the viewpoint of the human-robot interaction (HRI) design, the clinical application of robot technologies to autism treatment is essential because of problems for the broad spectrum, long-term care, and the therapist’s workload for repetitive behaviors. However, most robots utilized in therapy have been remotely controlled by the therapist or the operator who fully understands the HRI environment [7, 8]. Furthermore, Diehl et al. [9] reported that there is still little information on the utility of robot feedback (automatic or not) in interventions for individuals with ASD. Above all, the critical issue in the use of robots is how to effectively provide social stimuli by their discretion, and simultaneously cope with responses by targeting children with ASD in a certain area. Accordingly, the well-designed instructional approaches of the robot system can be emphasized by basically configuring to a friendly appearance, specialized training program, targeted behaviors, robotic interaction technologies, efficient training process, and evidence-based observational monitoring, which are key elements in the facilitation of specific social skills of children with ASD. The purpose of this study is to propose a configuration of the behavioral intervention system using robots and investigate its effectiveness for training social skills targeting preschooler. To this end, the proposed system is built on the interaction scheme design with a highly structured schedule of activities based on well-known behavioral treatment protocols. In the design, the system requests two training tasks of eye contact and reading emotions respectively through robotic stimulation design, estimates the response of the children by eye contact detection and user input, and automatically accomplishes pre-allocated acts given by a reinforcement procedure with coping strategy. For the interaction flow with humans, we constitute robotic interaction technologies capable of performing gaze control, relational discourse, and praise with a children’s song to the designated person in each situation in order to attract a positive response of children with ASD. Using these configurations, we verify system feasibility capable of providing positive effects on clinical trials as a practical approach and performing repetitive robot feedback on behalf of the humans. This paper is organized as follows: Section II introduces robotic intervention system for autism therapy, Section II Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. outlines the clinical experiment, Section IV describes the experimental results, and Section V presents the conclusion and future works. II. ROBOTIC INTERVENTION SYSTEM A. Interaction Scheme Design with Treatment Protocols As effective practice methods, behaviorally based interventions build on the interest of the child, extensive use of visuals to accompany instruction, a highly structured schedule of activities, and transition planning and follow-up. In addition, there has been an increase in the number of university hospitals and research institutions focusing on the early diagnosis of autism and making use of behavioral intervention approaches such as applied behavior analysis (ABA), naturalistic methods, and milieu teaching through empirical studies [10, 11]. Accordingly, we designed a robot system for autism treatments that executes training programs for social interaction skills by using the discrete trial teaching (DTT) protocol, a socially validated method for individualizing and simplifying instruction to enhance children’s learning and establish social interaction with them [12]. The DTT protocol is done through the presentation of an antecedent stimulus Sa, which elicits an acceptable response Ra, which itself elicits a consequence stimulus Sc to bring out a target behavior. In other words, it can achieve the treatment goal by inducing desired response toward a positive reinforcement through stimulation configuration [13]. Social training elements | Training element generation Human-Robot Interaction Zone | ] (a “Hi. Min-Ho” “Hello!- 9: Behavior, : 4 “input > 2 - =e of human activity x User input Robotic Behavioral Intervention System ST > | Rewa rd mode ouragement mode Pause m 4. follow-up mn er Coping-mode selection Action execution Figure 1. A human-robot interaction scheme based on the DTT protocols. Using the presented treatment protocol, we configured the four interaction modules of the training element generation, recognition of human activity, coping-mode selection, and follow-up action. Its interaction scheme can be briefly explained as follows: The robot first conducts training elements Sa, which is usually chosen in advance by the therapist, to a child; by measuring children’s responses Ra to the Sa, the robot selects one of the pre-allocated response modes of reward, encouragement and pause. And then it performs subsequent actions Sc belonging to the mode, which provides interest and motivation to the child as a positive reinforcement (see Fig. 1). B. Robotic Stimulation for Social Training To teach social skills of children with ASD in the interaction scheme, two training elements of eye contact and reading emotions are designed through consultation with therapist. First, eye contact allows them to learn more about aligning with the eyes of others and following the line of sight by providing more clear communication signals [14]. In addition, the reliable analysis of the child’s facial gaze is a significant cue in child-robot interaction to analyze the degree 695 of the children’s interest from the viewpoint of cognitive science. Second, according to Clark et al. report [15], the identification of emotion from rapidly presented stimuli involving facial expressions in an activity session can be a good indicator for social development including rapid mimicry and empathy. In addition, this element will help to secure the quantitation for children with ASD. To enhance outcomes in the interaction scheme design, we prepared robotic stimulation configuration to have a convincing effect on the clinical use of robots as follows. The element that builds attention is composed of the intended actions such as rapid acts, speaking rapidly, response time limit, and performing an act differentiated depending on the difficulty. In particular, there is a good example for inducing the attentional situation using a clinical mental stress test, called the ‘Stroop effect’ as the contradiction between font color and the meaning of the words presented [16]. In addition, several variations of the Stroop task have been used to study the relations between the speed of processing and executive functions with working memory and cognitive development in various domains [17]. Thereby we applied the Stroop paradigm to the reading emotions as one of the stimulating tools via the contradiction between facial expressions and its questioning type. In addition to provide much more effective tension and motivation to children, we configured that the robot coordinates the pre-configured script with three query types Orypr, aS answer requests for facial expressions, the speaking speed S'spp, the number of expression changes Neyp, the expression time-limit 7;yp, and the response time-limit Tres of children in the Ra, depending on the configuration of the four levels of task difficulty, as shown in Table I. TABLE I. STIMULATION CONFIGURATION OF READING EMOTIONS TRAINING IN EACH LEVEL Sa Level a OrypE Sspp Nexp exp Tres l Confirmation Normal Once Long Long 2 Induction Fast Once | Middle Middle 3 Contradiction Top Once Short Short 4 Contradiction Top Twice | Middle Short For example, in level 3, the robot asks for the correct answer for one emotional expression to the children within a short time by providing the question type of contradiction between a facial expression on the robot face and meaning of the speaking words presented, with top speed and short expression time-limit, as a control factor. C. Recognition of Human Activity With respect to the recognition module, we incorporate three recognition techniques of an eye contact detector, object detector and tracker, and object classifier for human behaviors into the system. First, the robot system detects whether to make eye contact with the children from a certain distance by using a Haar-cascade classifier [18]. As one of our complementary items in the previous study [19], detecting a pair of eyes by rotating images is added to the system in order Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. Object Detection BGS-Based Template Matching- Based Object Classification Blob Size—Based Thresholding Object Tracking Particle Filtering Internal robot camera External 3D camera Input images Eye Contact Detection arr-cascade classifier Visual Recognition Part Input Part Figure 2. A flow chart of the recognition module for human activity. to cope with children’s head tilting. Second, an object detector and tracker have three working modules to estimate the position of the moving objects (1.e., the child, therapist, and robot) by sensing an RGB-D image stream of a Kinect sensor. For the robot detection, a template-matching algorithm [20] is applied to estimate the position of the robot since the robot has unaltered color and shape (see Fig. 2). For the human detection, the background subtraction (BGS) technique with the background (BG) modeled by an adaptive Gaussian mixture model using depth images 1s first applied to estimate the position of the humans [21]. Filtered using edge information from color images, the foreground regions are then labeled as extracted motion regions or blobs. In turn, some of the blobs are assigned as humans after blob filtering. The detected objects are tracked by using a particle-filtering algorithm. Third, while the detected moving objects are being tracked, the object classifier easily labels the objects as the therapist or child based on the difference in sizes of the two objects. To identify the child’s voice response about the reading emotions, a sound source localization and a keyword recognition are initially planned to implement to the recognition modules. But the performance result was not yet satisfactory for implementation into the system. Instead, we set up the user handler reflecting the remote decision input of positive or negative response by the therapist who best knows the correct circumstances via a commercial wireless presenter. D. Robotic Reinforcement To elicit less anxiety and more attention of the children in the interaction scheme, we applied a reinforcing element to the robot system according to the antecedent-response- consequence format. The element that builds intimacy is composed of meaningful actions such as a sound effect (e.g., rejoinder, melody), intimate kinesic acts (e.g., nodding, waving, bodily expressions, moving closer, singing along with dance routine), displayable contents (e.g., friendly image or color, movie clips of children’s song), and even material rewards for the robot-based social training tasks. Using these properties in the Sc, the robot determines one of the pre-allocated tasks to be executed within _ three modes—reward, encouragement, and pause—by grasping the 696 response state of the children as a reinforcer. In addition to sustain the positive interaction experience with attentional focus, we constituted the coping strategy capable of manipulating meaningful actions with differentiated attributes according to the children’s reactivity by successive answer, as a highly structured schedule of activities (see Table I). TABLE IL. DIFFERENTIATED COPING STRATEGY TO EACH REACTIVITY OF THE CHILDREN WITH ASD Ra Continuity Gaze/Correct Wrong Non-gaze 1 RW1 EN1 EN2 2 RW1+RW2 ENI+ENIL2 | EN2+EN2L2 3 ormore | RW1+RW2+RW3 PAUSE PAUSE If the children positively respond to the Sa, the robot would provide praise with a blinking face LED (RW1), familiar actions (RW2: e.g., moving back and forth, raising up its hands, nodding, waving, coming close, or displaying smile images) and a children’s song (RW3) to them as differentiated rewards. Otherwise, while speaking with high volume (EN1, EN2) in each situation, it exhibits interesting encouragements (EN2L2: e.g., calling the name, raising arms, sound effects) to retain the active participation with attentive gaze or gives comfort with vocal encouragement (EN1L2: e.g., displaying their own picture, head turn, bodily expressions) to children to induce a positive response. If the child exhibits a continued negative response or indifference despite the encouragement, the robot finally initiates the pause mode where it stops its behavior for a period in the therapy session before the therapist’s input to resume. After every child’s answer, the robot makes the different types of rejoinders according to the mode as echoic response on a whim. About the difficulty settings, after 3 or more consecutive right (false) answers, the robot raises (lowers) the level of the Sc. Otherwise, it sustains on the same level in the rest case. Il]. CONFIGURATION OF CLINICAL TRIALS The instructional process for the two training elements is organized into three steps of therapist-robot, child-robot, and therapist-child interaction in a given protocol by reflecting the therapists’ suggestions as shown in Fig. 3. The robot interacts with the therapist for each training element via pre-registered scripts and behaviors to induce the child’s imitation as the HD Frontal face decision by recognizer Answer decision by therapist Child-therapist Eye contact For correct answer a, For wrong/no answer End Sd: Guidance, Practice, [Attempt Sc: ¢ Figure 3. A social training process with eye contact and reading emotions. Greet/Reward, € Encouragement/Pause Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. (a) Figure 4. Experimental scenes in the social training process: (a) Configuration of clinical environments, (b) recognition of human activities, and (c) robot training of reading emotions. Autistic a D9 IA - guidance part. Afterwards, the robot moves toward the child and conducts instructional trials in the same manner while forming a kinship with him/her as the practice part. After a certain number of trials, to verify the training effect on the human—human interaction, the robot asks the child to make eye contact with the therapist at the end of the program as the attempt part. While continuing a process, the robot performs a role as a playmate on behalf of humans by applying robotic interaction technologies in which the robot gazes at the designated target by computing a physical angle between subjects to shift the robot’s head, greets them with pre-enrolled personal information and relational discourse via object classifier, and indicates a clear beginning and end of the training elements with a melody to the observer (see Fig. 4(b)). Furthermore, before starting the practice part, the robot uses positive speech to strengthen motivation and increases the expectation of the child’s performance in the training program using the Pygmalion effect, which is the phenomenon in psychology whereby the greater the expectation placed upon people, the better they perform [22, 23]. Once a therapist starts the training process, the robot repeatedly conducts structured instruction routines while appropriately corresponding to the response of children with ASD until a given number of times. Or not therapist can stop the routine by pressing the stop button. By using training process repetitively, the child can reduce own anxiety and have a positive attitude on the social training elements gradually (see Fig. 4). In the social training process, two robots were utilized in order to minimize platform dependencies for our interaction scheme and examine the applicability of different types of robot behavior for delivering assigned same tasks in therapy session. One is a small-sized robot (1RobiQ) developed by Yujin Robotics Co. Ltd. [24]. It provides lots of children’s songs including arm movements that can be adjusted to suit for our demand as a commercial version. Another is a clinical assistive robot (CARO) developed by the Center for Robotics Research at KIST. It is specially designed to perform emotional interplay focused on eye expressions for children with ASD and its appearance wearing a hat was to show the friendly image that can mix with their peers while less daunting. But it performs similar features to the iRobiQ. In the recruitment of participants, trained therapist, with expertise in the diagnosis and treatment of children with autism, particularly selected children who rarely made eye contact with others and who spontaneously grasped or made facial expressions 1n daily life but had a mintmum competency level of age-appropriate cognitive skills (e.g., the ability to 697 distinguish between the expressions). Total fifteen children aged 3-5 years were recruited and finally participated in the social training experiments. During the randomization procedures by therapist, 8 were assigned to the training group (TG) and 7 to the control group (CG). Each session in the training scenarios lasted approximately 30—40 minutes in the triadic interaction of a child, a therapist, and a robot, and consisted of a set of 10 trials for two training elements between the child and robot in the practice part. In addition, to make the subjective decision more consistent, the same therapist was involved in all of the experiments. For each participant, a total of 8 clinical sessions were executed using iRobiQ and CARO equally. Accordingly, each child completed approximately 80 epochs, which represents eight different days with a one-week period and yielded 0.4-h of data for each child. ITV. EXPERIMENTAL RESULTS The first experiment is to investigate the usability of the robot interaction scheme in autism therapy. For the recognition modules, the eye contact detection, which was learned by 3,320 frontal and non-frontal face images, shows a 85.7% recognition success rate. In the object classification, the experimental results shows a 98.15% recognition success rate, which was trained by 54 image sequences to examine the classification performance in the triadic interaction. Even through there are some misrecognition such as looking downward to see the monitor in eye contact detection, the eye contact detection maintains consistency in specific situations and the system adopted a Majority voting technique so that the detection does not affect on the training process. BLevyel2 OSLevel3 MO Level 4 SLevel 1 4 PROPORTION OF THE LEVEL (%) Bolo Distribution results of the robotic stimulation by the reading emotions in TG. Figure 5. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. ——TG --=--0G > a188 92.50 ge 100 e958 97.08 PH 7e96 8980.00 a7 99 < ag bo ~e ag Sebi eer” 7 ae eae ite aL ==—._ ee i €0 657 70.71 69.05 “ly 6s.81 65.95 = co 40 a) = 20 o 1 2 3 4 5 6 7 s SESSION (a) Eye contact ——E— Tp =<-—--(1G 120 £ x 10 9643-897 03 93.69 38.00 o7 SC 7 —_" asin 95-70 an 91.16 z 27912 72.25 = 60 i = 40 b 3 20 a) ca a 4 SB 5 (b) Reading emotions Figure 6. Experimental results of social training elements in each group Figure 5 shows the proportion of the total usage of robotic stimulation with four levels through reading emotions in TG. A proportion of the level 1 shows a constant value, the level 3 shows a high proportion in the first session, and then the percentage of the level 4 is increasing steadily according to the session progress. In this regard, we deduce that most children experienced difficulties in reading emotions of level 3 because of the Stroop effect. However, they actively participated in the training without losing interest by the coping strategy and then gradually began to answer questions to be given in level 4. Accordingly, it was confirmed that the interaction scheme can offer an effective means of inducing positive response for children with ASD. The following experiment is to verify the effectiveness of the proposed system through comparative analysis with CG. Figure 6 shows the quantitative evaluation of participants for two social training elements. In Fig. 6(a), the eye contact rate of the TG (average 86.82%) is declining gradually and reaches near the CG (average 69.82%) depending on the session progress despite a great gaps between 96.46% in TG and 68.57 % in CG on the first session. It is noted that participants tend to show a relatively high interest and curiosity for the robot instruction. However, the notable point is that the falling tendency in TG may be caused by the child trying to spontaneously imitate desired actions or a dance routine including non-gaze situation, steadily sharing the interest point with the therapist, and even deliberately avoiding eye contact by increasing familiarity 1n some cases. As an individual case, another reason comes from the sensitivity and 698 negative attitude of the child in accordance with the robot replacement with changing the types of facial expressions. In the Fig. 6(b), average correct answer rate shows similar trends in both groups (86.43% in TG and 90.68% in CG). In addition, both of them generally show a growing trend depending on the session in progress even though there is temporarily decreased in the 5th session by the robot replacement and type change of facial expressions. Accordingly, it is noted that the instructional approach with robotic interaction technologies can offer an effective means of active participation of children with ASD; nonetheless, individual differences are present. Another important thing is that group difference is reducing as session goes on and this result means that participants can gradually be familiar with the robot training of reading emotions as much as humans do. Therefore, we confirmed the possibility of robot assistance on behalf of humans in clinical trials although it took 8 training sessions. + © Fe Je . © (c) Figure 7. Scenes of children’s reactions for each training stimulation: (a) positive and (b) negative reaction to eye contact request, and (c) positive and (d) negative reaction to a request about the facial expressions. In the individual cases, most participants who rarely made eye contact with others in TG reacted positively to the eye contact (Fig. 7(a)). But any participant occasionally exhibited a limited interest in a particular stimulus (Fig. 7(b)). In the training of reading emotions, many participants took an active part in the clinical trials while reaching a high level of achievement (Fig. 7(c)) excepting cases where any child do not respond properly by poor attention (Fig. 7(d)). In particular, 2 out of 8 participants attempted to talk to the robot on a voluntary basis. One child even took an interest in other people’s face in daily life, asked about this part to parents, and even exercised various facial expressions. Another child expressed his disappointment to robot replacement in the 5th session, but he adapted satisfactorily in the next session. Accordingly, the difference in the size and appearance of a robot did not generally have much effect on performing training program. In the system perspective, three main findings emerged. First, the training achievement of participants can be linked closely with the adequacy of the behavioral intervention with Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. the robotic stimulation design, coping strategy, and interaction technologies while checking two social training elements. Second, the configured system can be useful in implementing automated robot feedback for autism therapy by successfully performing consistent instructional routine with children with ASD in training process during 8 weeks. Third, the clinical application of robot interaction technologies to autism treatment can contribute to settle an issue about therapist’s burden for repetitive behaviors. However, the proposed intervention approach is vulnerable to failure in exceptional cases such as a child-centered approach to teaching or unilateral verbal expression toward the robot. In addition, there are some questions about whether the children with ASD can perform social interaction with the robot without the therapist. Nonetheless, we are confident that these results can be attributed to the positive effect of social skills training with the interactive robots. V. CONCLUSION In this study, we proposed a robotic behavioral intervention system based on the DTT protocols. By the implementation of the interaction scheme, the robot offer training elements of eye contact and reading emotions and subsequently accomplishes reinforcing procedure depending on the children’s response in child-robot interaction. The experimental results in clinical trials prove that the proposed system can have a positive effect on the training process and provide labor-saving effect through a comparison with CG. For future work, while including medical analysis by a clinician, we are planning to perform evidence-based clinical studies in behavioral interventions for suitable participants with an enlarged sample size and long-term treatments. In addition, the proposed architecture with better robot autonomy will be applied to the attention-training course based on context awareness, such as joint attention and pretend play, to ensure more clear objectivity. ACKNOWLEDGMENT We are grateful to Dr. Hee Jeong Yoo and Gui-Young Bong, staff members at Seoul National University Bundang Hospital, for their cooperation and assistance on clinical trials with insightful discussions. REFERENCES Center for Disease Control and Prevention, Prevalence of autism spectrum disorder among children aged 8 years-autism and developmental disabilities monitoring network, 11 sites, United States, 2010, MMWR Surveillance Summaries, 63(2) (2014) 1-21. S.J. Rogers, Interventions that facilitate socialization in children with autism, Journal of Autism and Developmental Disorders 30 (5) (2000) 399-409. American Psychological http://www.apa.org/topics/autism/ [1] [2] [3] Association, K. Dautenhahn, “Robots as social actors: Aurora and the case of autism,” In: Proceedings of the Third Cognitive Technology Conference, San Francisco, California, pp. 359-374, 1999. B. Robins, K. Dautenhahn, R. Boekhorst, A. Billard, Robotic assistants in therapy and education of children with autism: can a small humanoid [4] [5] 699 [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] robot help encourage social interaction skills?, Universal Access in the Information Society 4 (2005) 105-120. B. Scassellati, H. Admoni, M.J. Matari¢c, Robots for use in autism research, Annual Review of Biomedical Engineering 14 (2012) 275-294. H. Kozima, C. Nakagawa, Interactive robots as facilitators of children’s social development, Mobile Robots Towards New Applications (2006) 269-286. M. Villano, C.R. Crowell, K. Wier, K. Tang, B. Thomas, N. Shea, L.M. Schmitt, J.J. Diehl, DOMER: a wizard of oz interface for using interactive robots to scaffold social skills for children with autism spectrum disorders, in: Proceedings of IEEE International Conference on Human-—Robot Interaction, HRI, 2011, pp. 279-280. J.J. Diehl, L.M. Schmitt, M. Villano, C.R. Crowell, The clinical use of robots for individuals with autism spectrum disorders: a critical review, Research in Autism Spectrum Disorders 6 (2012) 249-262. S.R. McConnell, Interventions to facilitate social interaction for young children with autism: review of available research and recommendations for educational intervention and future research, Journal of Autism and Developmental Disorders 32 (5) (2002) 351-372. L.A. Vismara, S.J. Rogers, Behavioral treatments in autism spectrum disorder: what do we know?, Annual Review of Clinical Psychology 6 (2010) 447-468. T. Smith, Discrete trial training in the treatment of autism, Focus on Autism and Other Developmental Disabilities 16 (2) (2001) 86—92. R.L. Simpson et al, Autism spectrum disorders: interventions and treatments for children and youth, Thousand Oaks, CA: Corwin Press (2005). S.R. Leekam, B. Lopez, C. Moore, Attention and joint attention in preschool children with autism, Developmental Psychology 36 (2) (2000) 261-273. T.F. Clark, P. Winkielman, D.N. Mclntosh, Autism and the extraction of emotion from briefly presented facial expression: stumbling at the first step of empathy, Emotion, 8(6) (2008) 803-809. J. Zhai, A.B. Barreto, C. Chin, C. Li, Realization of stress detection using psychophysiological signals for improvement of human-robot interacitions, in: Proceedings of IEEE Southeast Conference, 2005, pp. 415-420. A. Demetriou, C. Christou, G. Spanoudis, M. Platsidou, The development of mental processing: efficiency, working memory, and thinking, Monographs of the Society for Research in Child Development, 67 (2002) 1-156. P. Viola, M. Jones, Robust real-time face detection, International Journal of Computer Vision 57 (2) (2004) 137-154. S.S. Yun, S.K. Park, J.S. Choi, A robotic treatment approach to promote social interaction skills for children with autism spectrum disorders, in: IEEE International Workshop on Robot and Human Interactive Communication, RO-MAN, 2014, 130-134. J.P. Lewis, Fast normalized cross-correlation, Vision Interface 10 (1) (1995) 120-123. C. Stauffer, W.E.L. Grimson, Adaptive background mixture models for real-time tracking, in: Proceedings of Computer Vision and Pattern Recognition, CVPR, 1999. R.S. Feldman, T. Prohaska, The student as Pygmalion: effect of student expectation on the teacher, Journal of Educational Psychology 71 (4) (1979) 485-493. R. Rosenthal, and L. Jacobson, Pygmalion in the classroom, The Urban Review, 3(1) (1968) 16-20. iRobi Q, http://yujinrobot.com/portfolio-item/irobi-q/ Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:50:05 UTC from IEEE Xplore. Restrictions apply. 