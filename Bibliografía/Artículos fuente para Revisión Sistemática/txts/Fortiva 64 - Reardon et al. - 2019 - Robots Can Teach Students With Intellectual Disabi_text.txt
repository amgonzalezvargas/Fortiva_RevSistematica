—_—_—_—_——_—_ By Christopher Reardon, Hao Zhang, Rachel Wright, and Lynne E. Parker n the face of a worldwide teacher shortage and, in the United States, a critical short- age of special education teachers, there is an urgent demand for appropriate educa- tional resources. For people with intellectual and develop- mental disabilities (I/DDs), in particular, there is a compelling need to develop educational tools and strategies to facilitate inde- pendence and self-sufficiency and address poor employment out- comes in adulthood. When provided with capabilities to make intelligent decisions, robots and other assistive devices have the potential to address this problem and empower people with disabilities by providing instruction and educational support. Important features of robots and assistive devices, including situated- ness, embodiment, precision, tirelessness, scalability, and context awareness, make them particularly advanta- geous in instructional roles. IMAGE LICENSED BY INGRAM PUBLISHING Robots Can Teach Students With Intellectual Disabilities Educational Benefits of Using Robotic and Augmented Reality Applications Digital Object Identifier 10.1109/MRA.2018.2868865 Date of publication: 15 October 2018 Authorized litensed2useer Mae to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 MET ffom IEE ERCHEFES RASHOHOASADONAZINE ° 79 Intelligent systems, whether robots, augmented reality (AR) systems, or other technologies, need to make decisions when interacting with humans to facilitate instruction. In this article, we introduce the use of response prompting as a basis for this decision making and discuss the construction of a complete system around this cognitive approach, which includes perception and interaction. Our goal is to provide cognitive capabilities for an intelligent robot instructor (IRI) and also demonstrate its generalizability across technologies and modalities. Specifically, we teach participants advanced skills with an IRI. We also explore similar instruction strategies on a different type of hardware through the use of a portable AR assistive device to teach three additional skill sets, including the sim- pler prerequisite skills for the tasks taught by the IRI. We pres- ent the results of a formal study demonstrating the effectiveness of this approach for teaching college-age stu- dents with I/DDs. Our results show that proven education methodologies can be leveraged to provide intelligent autono- mous instruction to students with I/DDs. We expand on sev- eral findings that may be constructive in other efforts to create IRI systems and, finally, discuss open challenge areas. Intelligent Robots for Instruction A strong case exists for investigating the use of IRIs to teach human pupils [1]. The more time a teacher spends with a stu- dent, the better the student learns. If an IRI such as the one in Figure 1 were capable of assisting a human teacher by provid- ing instruction to students in a classroom setting, it could offload some of the teacher's tasks, thereby increasing the amount of time available for the teacher to spend with indi- vidual students. In the face of future teacher shortages and increasing classroom sizes [2]-[4], the ability of an IRI to aug- ment a human instructor's instruction could allow for better use of limited (human) teaching resources. r it Figure 1. A photo of our IRI. Robots have several strengths that can be leveraged in an instructor role. A robot is tireless, and a well-engineered robot could have nearly unlimited energy and provide sustained attention in assisting students. A robots precision enables it to provide perfectly timed instruction and avoid issues and mis- takes to which human instructors are prone. One robot could potentially observe and instruct large numbers of students simultaneously. Pupils may perceive a robot as less judgmental than a human and, therefore, would be more likely to request repeat instruction (e.g., ask the question again) until a lesson was fully learned. To young people already comfortable with using technology for learning purposes, a robot could represent an embodied and more physically interactive tool than a per- sonal computer or mobile device. Indeed, several studies have shown that embodiment is beneficial for human interaction with intelligent systems, for purposes such as robot tutoring [5], engaging cognitively impaired and/or Alzheimers patients for treatment [6], and obeying instructions and affording robots aspects of human interaction such as personal space [7]. We believe that students—and, in particular, those with I/ DDs—have significant potential to benefit from IRIs for sev- eral reasons. Young people with I/DDs entering adulthood today face harsh realities, such as low employment rates, poor wages and benefits, limited community support, and low rates of independent living [8]. In addition to the advantages of an IRI discussed previously, the types of tasks commonly taught to students with I/DDs lend themselves well to robot demon- stration and observation. One area, for example, is the teach- ing of life skills, i.e., knowledge and/or abilities that increase a person's independence in personal terms, for community engagement, and on the job. Particularly relevant to the edu- cational experiments conducted for this article are vocational and functional academic domain task skills one would encounter in daily life. Robots have successfully been used to instruct students. Many studies on the topic have focused on using the robot as an instructional tool, employing Wizard-of-Oz (WoZ) approaches [9], [10] or partial WoZ approaches [11], or using the robot as an embodied recording of speech and gestures following a script [12]. A Nao IRI was used as a decision-tree- type framework to autonomously teach students in [13] and [14]; however, whereas this instruction was for math skills using multiple-choice response types, our work is more ambi- tious, using an IRI to teach a variety of skills involving math, geometry, and object manipulation and also more generaliz- able to other intelligent systems (e.g., an AR device). All of this research shows promise for robotic instruc- tors. The high-level goals of this article are to demonstrate the following: e Established educational methodologies can be adapted to help intelligent systems autonomously make instructional decisions. e Knowledge and representational gaps between what is defined in modern educational methodologies and a work- able implementation for an intelligent, embodied system, such as a robot, can be identified and addressed. Authori8@d fic&iseePaSe trite’ Te MONDE RSISAD DELROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. e Unique aspects of robotic and intelligent systems would strongly benefit populations in need of educa- tional support. This work attempts to address these open issues by adapting proven methods used for instruction in the education field to the decision-making process of an IRI. The approach is then employed to teach students with intellectual disabilities in a one-on-one setting. We have already introduced the response-prompting con- cept for instruction in preliminary work with an IRI [15] and an AR device [16]. Here, we present new prompting strate- gies, additional experiments, expanded results and discussion, and observations and lessons learned over this broader study. We hope that this article and the presented findings will help drive further research into the creation of intelligent instruc- tion systems, particularly for students with elevated needs, such as those with disabilities. Response Prompting for Decision Making To make intelligent decisions in the context of providing instruc- tion, a cognitive framework is proposed that makes use of response-prompting methodologies borrowed from the educa- tion domain [17]. Response prompting is a well-defined, evidence- based collection of teaching practices that involve assessing the environment and acting or providing assistance to stimulate a targeted behavior. By incorporating these proven methodologies into our approach, an intelligent system is able to use the same methods a teacher would use to provide instruction. Prompt/response strategies allow an IRI to perform in mul- tiple modalities. Common prompt modalities are vocal, visual, gestural, modeling (i-e., demonstrations), or physical prompts. Another useful feature of prompting is the ability to modify the intrusiveness of prompts, called fading; more intrusive prompts provide more support, whereas less intrusive prompts allow students to perform the desired behavior independently. Importantly, these methods go far beyond simple instruction- al systems: they involve a complex hierarchy of prompts, with multiple paradigms for arranging, traversing, and fading those prompts based on instructional needs and student performance. These struc- tured designs assure that student perfor- mance moves toward independence. Leveraging response-prompting instructional strategies in the cognitive domain represents a novel approach to an intelligent robotic and AR system for instruction. We believe that exam- ining this approach provides valuable and constructive evidence for instruc- tion by autonomous robots. Introduction Stop Monitor Cognitive Process Overview Figure 2, inspired by [18], illustrates the cognitive framework at a high level. In the cognitive process, it is by taking sensory information from the world and perceiving information salient to the task at hand that we create an interpretation of the states and actions of the world. Then, using contextual knowledge, that interpretation is reasoned about to generate a higher-level representation of the situation: i.e., a decision is made. In the intelligent instruc- tion application, this involves first using the response- prompting methodology to select the correct instruction response (e.g., present stimulus, prompt, consequence, rein- forcement) and then performing the selected action. The general instruction process is shown in Figure 3. The instructional intervention begins with an introduction and general instructions for the scenario. In task instruction, the task is introduced and the target stimulus presented. Next, the prompt is selected. The intrusiveness of the prompt depends on the methodology being used (see the “Response-Prompt- ing Types” section) and the previous prompt/response history (e.g., prior incorrect responses). Next is the student response period, which ends when the student is idle, the task is com- plete, or the response interval has elapsed. The response evaluation determines the outcome of the interaction: a correct answer results in positive reinforcement. For a correct but nonoptimal answer, a correction occurs before Reasoning Sensory Situational = \ Knowle dge Evaluation «— Perception S$ | 2 f Instruction \ Instruction Effector — Strategy / Selection System Decision Making Action Figure 2. The cognitive process flowchart. The information flows from lighter- to darker-shaded process steps. Prompt Selection and Delivery Task Instruction Interval NO Elapsed Lesson Stud Incorrect Differential R uden d Answet/ Reinforcement ®K Correct Esponse al Prompt \Response |_ Observation Escalation Corrected Response Response Evaluation Correction Correct but Nonoptimal Response Figure 3. The overall instruction process based on the response-prompting methodology. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 ETO ffom IEEERGHEFES RASHHAHOASABONHAZINE ° 81 positive reinforcement; in the case of an incorrect answer, the evaluated result information is used as part of the process to select the appropriate feedback. The type of response (correct, incorrect, partially correct, or no response), combined with the known information about the previous prompt and student's state (active or inactive), ultimately determines the appropriate feedback. Only positive reinforcement is used. This reinforce- ment is differential, in that the degree of reinforcement is inversely proportional to the intrusiveness of the required prompt, i.e., the lower the level of prompt intrusiveness required, the more positive the reinforcement. Response-Prompting Types The System of Least Prompts (SLP), System of Most Prompts (SMP), and Constant Time Delay (CTD) [17] are popular and well-validated response-prompting strategies for instruction of Prerequisites Stimulus and Prompt Sequence Consequences/ Reinforcements Student’s Patience | : Estimate Reinforcement Response Interval SLP Trial t Correct Response? chained and discrete tasks. In addition, they have been success- fully used to teach students with I/DDs (Figures 4 and 5). Fur- thermore, these methods are applicable to a wide range of students and have proved to be effective for teaching a wide variety of skills. For this article, we computationally encoded the SLP, SMP, and CTD strategies for use in an IRI systems decision-making process. We also demonstrate generalizability over an AR system. SLP In the SLP method of instruction, a hierarchy of prompts is arranged from least to most intrusive. At the least-intrusive end, no prompt is given. At the most-intrusive end, the con- trolling prompt is given. The controlling prompt is designed to guarantee that the task is successfully performed. The prompt hierarchy is traversed iteratively to provide more support as Trial Steps: 1) Secure Student’s Attention 2) Present Stimulus 3) Wait Predefined Interval 4) Present Current Prompt 5) Wait Response Interval Error Consequence + Escalate Prompt _ Yes At Mexat Tele: Criterion? (a) Prerequisites . SMP Trial 3 Trial Steps: Stimulus and Prompt Sequence Consequences/ Reinforcements Student’s Patience Estimate Response Interval Next Task C Reinforcement + Reduce Prompt Level Correct Response? At Criterion? 1) Secure Student’s Attention 2) Present Stimulus 3) Wait Predefined Interval 4) Present Current Prompt 5) Wait Response Interval Error Consequence + Escalate Prompt (b) Figure 4. Flowcharts for (a) SLP and (b) SMP response-prompting strategies, adapted from [17]. Note that the key difference between SLP and SMP is in the prompt sequence input: SLP is least-to-most intrusive (see the “SLP” section), and SMP is most-to-least intrusive (see the “SMP” section). CTD has only one prompt, the controlling prompt, and the time interval is varied (see the “CTD” section). Authori8éd ficéiseePaSe trite’ te MONDE RSA DEL'ROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. needed. At each iteration, the target stimulus (e.g., the ques- tion) is given with the prompt for the current level. The response is evaluated after the response interval, i.e., the con- stant amount of time before and after each prompt elapses. A correct response is reinforced; an incorrect response results in an escalation of the prompt level and another iteration. The goal of SLP is that, after sufficient repetitions, students require fewer prompts and eventually respond correctly before any prompt is delivered. As the student answers cor- rectly at lower prompt levels, a process of self-fading occurs, where the student's answers determine the rate at which the intrusiveness is decreased. We note here that the occupational therapy technique of graded cueing has been previously used successfully for imita- tion games in therapy for people with autism [19] and is simi- lar to the SLP subtype. Prerequisites Stimulus and Prompt Sequence Consequences/ Reinforcements Yes Student’s Patience Estimate Delay Interval Yes Correct Response? All Trials Complete? SMP SMP is very similar to SLP except that, in SMP, the hierarchy of prompts is arranged from most to least intrusive. The hier- archy of prompts is traversed iteratively in decreasing order of intrusiveness. As with SLP, a constant response interval is used, and reinforcement is provided for correct answers. When an incorrect response is given, the prompt level is esca- lated, as with SLP. The underlying idea for the SMP approach is to guaran- tee that the student first makes a successful response (via the controlling prompt) and then to fade the intrusiveness of the prompt and work toward fully independent behavior. One observed difference between SMP and SLP is that, with SMP, it is highly likely that the entire prompt hierarchy is traversed for each instruction. This could make the time expended for each instruction longer; however, because the Trial Steps: 1) Secure Student’s Attention 2) Present Stimulus 3) Wait Delay Interval 4) Present Controlling Prompt CTD Trial 7 Yes Preprompt Reinforcement (Counts Towards Criterion) Correct Response? Postprompt Reinforcement No Preprompt Error Postprompt Error Consequence Consequence NextTask ——~ At ~ OA WER ‘ Criterion? Figure 5. A flowchart CTD response-prompting strategy, adapted from [17]. Note that CTD has only one prompt, the controlling prompt, and the time interval is varied (see the “CTD” section). Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 ETO ffom IEEERGHEFES RASHHAHOASABONHAZINE ° 83 prompts are arranged from most to least intrusive, errors may be less frequent. CTD In CTD, prompts are delivered after a time delay following a task direction, i.e., a cue or question for the student. Unlike SMP or SLP, there is only one prompt: the controlling prompt. Only the time between the cue and the prompt, known as the prompt delay interval, is varied. Initially, the delay between the task direction and the controlling prompt is zero, in what is termed the zero-second delay trial. The prompt delay interval is constant for a set of instruction trials until the criterion is met; it is then systematically increased. The goal of CTD is a consistently correct response before the prompt. Chained and Discrete Tasks In addition to prompting strategies, the manner in which the steps of the task can be taught is also a consideration. Discrete tasks are tasks for which a single correct response is expected, such as sight words (commonly used words that students are taught to memo- rize as a whole by sight). Some discrete tasks can be subdivided into smaller sequences of tasks as necessary for instruction. Chained tasks are sequential in nature. Instruction on chained tasks is conducted step by step within the sequence. Examples of a chained task include most building tasks, such as building a structure (e.g., from the ground up), assembling an object or puzzle, and so on. Because of their sequential nature, chained tasks can be taught from the beginning of the sequence in what is known as forward chaining or, by iterating from the end of the sequence, backward chaining. Tradeoffs exist for both. This work uses forward and backward chaining as appropriate to the task and examines how they impact suc- cessful learning from intelligent systems. Creation of Prompting Hierarchies The process of creating a prompt hierarchy involves devising a series of prompts and arranging them in a hierarchical structure appropriate for the instruction strategy (e.g., SLP or SMP). The dimensions of this structure are dictated by the student's response space (e.g., correct, partially correct, incor- rect, or no response), the discretization of task steps, and the modalities and intrusiveness of the response prompts. To ensure successful instruction, the prompt content and modalities, as well as the level of intrusiveness, should be appropriate for the students capabilities and diagnoses. For these reasons, we strongly recommend collaboration with an education domain expert for this process. For the following experiments, our interdisciplinary team of authors collaborat- ed closely to ensure a successful and productive experience for the students involved. Experiments Single-Case Experimental Design Experiments were developed for this research using a single- case experimental design (SCED), a common design method in special education research. Rather than comparing groups or subjects, in SCED participants serve as their own control, with performance in at least two experimental phases being compared [20]. SCED methods are used in place of statistical methods for large groups. This is not only because recruiting a large number of participants with I/DDs is infeasible but also because, even if it were possible, the participants’ capabil- ities and diagnoses could be so diverse that drawing even a coarse statistical inference would be challenging. The objec- tive of the SCED is to determine whether a causal or func- tional relationship exists between the delivery of the independent variable (the intelligent instruction system) and significant increases in the dependent variable (the acquisi- tion and maintenance of the skills taught). Two types of SCED designs were used for this research: a combined multiple baseline across participants and a com- bined multiple baseline across skills. These designs allow for the evaluation of intervention effects while controlling for threats to internal validity (i-e., that the learning is due to the instructional intervention) in situations where alternate designs are not feasible, such as those that would require withdrawal of skill knowledge. In experiments using a multiple baseline across skills, skills are taught one at a time, and instruction is introduced for each skill sequentially after the previous one has been learned. In experiments using a multiple baseline across participants, each student is taught one at a time, and instruction is intro- duced to each successive student after the previous student finishes learning the skill. In all cases, baselines are taken before instruction, up to the point where the instruction begins, and probes are made after successful demonstration of the skills to measure retention. By introducing the intervention subsequently across a minimum of three replications, the possibility that any observed change occurrs due to extraneous factors (e.g., prac- tice or history effects) is eliminated. This allows for experi- mental control and establishing a causal relationship [21]. Student Participant Population All studies for this research were performed in accordance with institutional review board protocols and approval. The students who participated in these studies were college age and attendees of a postsecondary education (PSE) program designed for young adults with I/DDs at the University of Tennessee, Knoxville, named FUTURE (more information on the FUTURE program is available at http://futureut-utk .edu). All students 1) were ages 18-34 with an intelligence quotient between 57 and 67, 2) received special educa- tion services throughout school, and 3) earned modified high school diplomas before participating in the FUTURE program. To meet the three replication minimum requirements for evaluating the intervention effects, three students per experi- ment were taught until our criteria were reached, i.e., they mastered the skill being taught. Seven students participated overall, four of whom participated in multiple experiments. Authori8éd ficéiseePaSe tirnitéd te MONDE RSA DEL'ROSARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. Intelligent Robot Instruction Experiments Life skills that require object manipulation and discrimination were taught in these experiments. In our setting, the student and the IRI stand across from each other at a table during instruction, as seen in Figure 6. The IRI autonomously per- forms the instruction, prompting, observation, evaluation, and feedback (correction or reinforcement) loop shown in Figure 3. No WoZ techniques were used for these experi- ments. The complete IRI system was implemented as a suite of C++ and Python software modules, leveraging the Robot Operating System (ROS; http://ros.org) for messaging, inter- process communication, and common robotics libraries. The custom object-tracking system shown in Figure 7 provided the IRI with the ability to observe objects with which both the student and robot interacted and thus accu- rately interpret the student's performance. The object-track- ing system was implemented as a set of custom ROS nodes using OpenCV to process live image streams from a camera mounted under a transparent tabletop, as illustrated in Figure 8. Details of the vision system performance are reported in [15], where we previously introduced response prompting for instruction with an IRI. Interaction and feed- back are provided through synthesized speech, speech rec- ognition, and gestures. The robotic hardware for this research is a Meka Robotics M3 mobile humanoid robot [Figure 8(a)] with 7 degrees-of- freedom (DoF) arms, 5-DoF hands, and a sensor head with 2-DoF movement. For this research, the IRI makes use of one PrimeSense short-range (version 1.09) camera, one universal serial bus camera, a Bluetooth microphone, and stereo speak- ers. The robot is equipped with two personal computers—one providing real-time functionality of the base, arms, hands, and lift and the second dedicated to the vision and audio components. Two skills were taught by the IRI: 1) making change, i.e., given a dollar and a purchase price, first use a calculator to determine how much change is due, then present the IRI with the correct change in coins (originally presented in [15] and summarized in the following) 2) geometric assembly of larger objects from smaller pieces, as shown in Fig- ure 9, for which prerequisite skills were taught using AR instruction (see the “Intelligent AR Instruction Experiments” section). Both skills involved live interaction with objects and demonstration of cor- rect responses. Making change is a life and voca- tional skill that involves calculating the correct quantities and denominations of currency to be exchanged after a cash transaction. The assembly skills taught in our geometric assembly experiment are useful in job settings, and the geometric reasoning aspects are useful in both work and personal life. Instruction strategies appropriate to the skill being taught were selected. For the geometric assembly skill instruction, an SMP prompting strategy was used with backward chaining, along with a multiple-baseline-across-skills experimental Figure 7. The object tracker graphical user interface, with live, adjustable parameters (upper left) and the annotated live image (lower left). The magnified image on the right shows an enlarged view of the annotated image. The annotations include position, orientation, size, centroid location, and bounding box for each object. (b) Figure 8. The table setup for the instructional setting from the (a) student's view and (b) overhead. HD: high-definition. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 UET29 tfom IFEER IFES RASHHAHOAS AD ANEAZINE ° 85 design. For the making change experiment, a combination of SLP and discrete and forward chaining was used. Unlike the geometric assembly and AR experiments, the experi- mental design for the making change experiment used a 0 LAT Diamond Trapezoid Hexagon (a) acs V-Shape Two Houses _ Butterfly abr House Tree Ball (c) Figure 9. The puzzle tasks for the geometric assembly skills: (a) subcomposition, (b) symmetry, and (c) complex assembly. multiple-baseline-across-participants methodology to control for any outside influences affecting the participants’ ability to make change. An example prompt hierarchy for part of the making change task is shown in Table 1. The SLP strategy was used, with prompts arranged from least to most intrusive: verbal cue 1 is the least intrusive; prompt level direction 2 serves as the control- ling prompt. The student responses shown are as follows: no response (NR), partially correct (PC), correct, and incorrect (I). In addition, to evaluate the student volunteers’ attitudes about learning from a robot, Likert-type scale statements and open-ended questions were used to collect subjective data before and after participants interacted with the IRI for the making change experiment. The results of this sur- vey are discussed in the “Subjective Acceptability” section. Intelligent AR Instruction Experiments We also implemented response prompting for intelligent instruction on a portable AR device. AR devices share similar features with IRI instruction, such as context awareness, pre- cision, and tirelessness when situated in an environment with the user. Both are capable of delivering to students visual and auditory prompts that interact with the real environment. Using an AR device for instruction, we demonstrate that our approach generalizes to systems with these overlapping fea- tures but a different physical implementation (ie., a head- mounted AR device versus a humanoid robot). Figure 10 shows an overview of the AR system. When wearing an AR device and learning a new sequential task, the student can ask for help with the next step in the sequence at any time. The AR device captures an image from the student's point of view, processes it, and presents an appropriate instructional prompt to the student via the AR device. In this Table 1. The prompt hierarchy for the making change task using SLP. Prompt Level Response Prompt Description Verbal cue 1 NR Verbal interaction to determine how much change is due PC Verbal encouragement, verbally providing goal C Differential positive reinforcement | Same as NR Verbal cue 2 N Verbal interaction to determine which coin to begin with Verbal encouragement, verbally providing goal and shortage between current state and PC goal C Differential positive reinforcement | Verbal encouragement, providing goal and excess between current state and goal Direction 1 N Gesture to correct first coin, verbally providing goal PC Gesture to correct next coin, verbally providing goal and shortage C Differential positive reinforcement | Gesture to coin to remove, verbally providing excess Direction 2 N Gesture to each coin to add, wait until added PC Same as NR C Differential positive reinforcement | Gesture to each coin to remove, wait until removed, then same as NR Authori8@d ficéiseePaSe tirnitéd te MONDE RSPAS DEL'ROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. experiment, the prompt modalities are an augmented version of the uploaded image as well as the audio. Live video augmentation is outside the perfor- mance abilities of our hardware imple- mentation but could be included in future work. Sensing To provide this instruction, the sys- * Voice , ¢ Photo tem parses the image for relevant information before applying super- vised learning to solve the problem of identifying the correct context of the image. Classifier output combined Interaction with the tasks knowledge model allows the selection of the correct prompt for the next step in the task, which is deliv- ered seamlessly through the AR inter- face to the student. Our AR system implementation consisted of a Google Glass wearable AR device running a simple Android application with a streamlined inter- face. The simple audio command “Okay Glass, what's next?” triggers the app. The user clicks to take a picture, which is uploaded to the cloud server, and an image and audio instructional prompt are provided within 5-10 s via the Glass display and built-in speaker. On the cloud side, intelligent instruction is made possible using OpenCV for image processing and support vector machines trained on extracted visual features for image classification. In the event of a failed or low-probability classification, the user is present- ed with a prompt to try again. Three skills were taught using the AR device: 1) using a copy machine, 2) accessing ones student account statement online, and 3) performing geometric reasoning tasks with puzzle blocks to acquire the prerequisite ablity for the advanced skills taught by the IRI system. Figure 11 shows example annotated image prompts from these experiments. A summary of these experiments appeared in [16]. For the copy machine skill (an office vocational work skill), students were asked to make a specific number of double-sid- ed copies of a document on a commercial copy machine with a complex, less-than-intuitive user interface. For the student Device Perception e Interpret the Context e “What's Next?” Wearable _@ images + i ° Video (om Correct | ie + ly Reasoning and Decision Making ¢ Knowledge Model e Machine Learning " Online Oe a Action Process a Selection ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ Sy . ' =~ 2 Reality Augmentation ~ ~ e Voice Ne + < x I “What do | do next?” Figure 10. The AR system overview. The student is instructed to face the device and ask for assistance. A picture taken from the wearable camera is classified, and an augmented image and audio containing the proper instructional prompt for the next step are delivered. account statement skill (an employment and independent liv- ing skill), the student was asked to log in and retrieve a copy of his or her prepaid student account statement. The third exper- iment, geometric reasoning, taught object manipulation, placement, orientation, and assembly subskills that are highly vocationally relevant. For these experiments, instructional strategies were care- fully designed using the appropriate combination of prompts, prompting strategies, and prompt chaining for each skill taught and the AR technology method (Table 2). These com- binations of methods were selected with expert consultation to match the appropriate prompt strategy and chaining direc- tion to the structure of the skill. All three AR experiments used a multiple-baseline-across- skills design, in which each subskill or step was mastered before the successive one was introduced. Also, in all three, the skills were taught in forward-chained order because the © Table 2. The experiment overview. Multiple baseline across skills Multiple baseline across skills Multiple baseline across skills Multiple baseline across participants Relationship Forward chaining Forward chaining Discrete and forward chaining Discrete and forward chaining Platform Experiment Prompt ARI Copy machine Self-directed Student account Self-directed Geometric reasoning CTD IRI Making change SLP Geometric assembly SMP Multiple baseline across skills Backward chaining Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 UT29 fom IEE ENSIEFES RASTHAHOAO A DANHAZINE ° 87 tasks (e.g., navigating through a copier interface) can only progress in a forward direction. The geometric reasoning skill also used discrete subskills at some steps in the chain. For the prompting strategy, the geometric reasoning skill used CTD. The other two AR experiments used a simplified self-directed method that provided controlling prompts only when the stu- dents requested assistance from the AR device. This was simi- lar to CTD but with the student controlling the time delay. Results and Discussion Results from each experiment showed that, in all cases and for all subjects, using intelligent robot and AR instruction allowed the students to learn the skills to mastery. Results from the IRI-instructed making change skill are shown in Figures 12 and 13. These results demonstrate that ? 4 t { d 01/12/2015 09:16:25 J 0 049472015 11:11:32 | VolPrint#2 WVolCard Accoun $ 01/16/2015 11 yay . dy 4 1/16/2015 11: J 5 ances I di 01/28/2015 10:07:10 oiPrint#2 -—=«s«WolGardAccount = (ssisd|S SS 01/28/2015 10:3 Print #2 i; Seon | i, in’ = Iv — - Me \e o | \¥/y (0172872015 4251.42 | VoiPrint #2 VoIP 0206/2015 09:15:07 _|VolPrint#2 0206/2015 11:15:13 |VolPrint#2_— [Volar Account [$0.10] 02/06/2015 11:16:23 VoiPrint #2 VolCard Account $0.10 021062015 11:17:08 | VolPrintw2 WWoiGard Account “| $040 02/06/2015 11:18:09 | VolPrint #2 lVolCard Account $0.12) RAIRARASE AAs AA Sy erry SCRLeAncone ean T AAA (b) Pyramid A Leave the triangle where it is, and rotate the trapezoid one half turn, so that the short side is on the bottom, to make a boat. (c) Figure 11. The example annotated image prompts from the AR instruction experiments: (a) a step from the copy machine study; (b) a step from the student account statement study; and (c) a step in the geometric reasoning study, where a student is learning the rotate and half-turn subskills. The image prompts are shown to the user via the AR device and accompanied by audio prompts. student 3 had a steeper learning curve due to a more limited understanding of the prerequisite coin value identification and direction-following abilities than students 1 and 2. Despite this, using the SLP methodology combined with for- ward chaining, the IRI was able to provide increasingly sup- portive prompts to help all students to mastery, as discussed in the “SLP and Forward Chaining” section. The results from the IRI-instructed geometric assembly skill and the AR-instructed skills are shown in Figures 13 and 14. Performance in the geometric assembly [Figures 13(a) and 14(a)] shows strong success that can be largely attributed to the structure of task instruction using SMP with backward chain- ing, as discussed in the “SMP and Backward Chaining” section. The results from the AR instruction experiments [Fig- ures 13(b) and 14(b)] verify the generalizability of the pro- posed approach to other interaction domains. Indeed, as discussed in the “Efficiency of Self-Directed AR Instruction” section, students were able to make rapid gains with AR instruction, which we attributed to the self-directed prompt control combined with the immediacy of intelligent, context- aware instruction in AR. The results presented here are a significant expansion of preliminary work [15], [16] that intro- duced the IRI concept. To enable a comparison across the diverse skills and exper- imental configurations, ‘Table 3 summarizes the total number of errors students made before mastering the corresponding skill or subskills in the making change and geometric assem- bly experiments (Figure 9). The values in Table 3 represent the total number of errors each student made across all trials for each skill. Although it is not possible to determine a superior strategy that generalizes to all cases, we can observe that error rates are influenced by the complexity of the skill. Lower error rates occurred with simpler skills, such as the copy machine skill, and higher rates occurred with the highly complex making change skill, which was divided into subskills for correct use of a calculator and correct exchange of coins. In addition, whereas the outcomes were very positive for those students involved, careful decisions were made to combine the best response-prompting strategies, experi- mental design, and prompt relationship with each skill being taught to achieve the optimal performance, as summarized in Table 2. Therefore, beyond validating our approach, we believe that an additional valuable contribution of these experiments can be found in key findings discussed in the following subsections, which we hope can constructively inform future work in designing intelligent robotic and AR instruction technologies. SLP and Forward Chaining The first key finding is that SLP with forward chaining allows students to present an open-ended response, which can be challenging to accommodate in the IRI’s perception system. In the making change experiment, this manifested as allowing the student to present any combination of coins (however incorrect, in some cases), for which the robot had to have a Authori88d ficéiseePaSe tirnitéd te MONDE RSISAD DEL'ROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. clear prompt. We found that, despite this challenge, the strength of the methodology allows the robot to provide increasingly intrusive prompts that can be designed to pro- gressively limit the response space. Then, by concluding with the controlling prompt, which allows for only the correct response, success is guaranteed. SMP and Backward Chaining Importantly, we found that backward chaining, combined with SMP, is highly appropriate for instruction from a robot. This is because the state space of responses is restricted by design (i.e., it avoids the open-ended response challenge of the SLP and forward-chaining method described previously) and because of a robots advantages in performing repetitive tasks. Backward chaining and most-to-least-intrusive prompting means that the skill is taught backward from a nearly complete example to total independence. The prompts delivered at each step begin with the con- trolling prompt and decrease in intrusiveness from there. For example, in the geometric assembly experiment, students were first presented with a puzzle having one piece missing and told explicitly where to put which piece. Then, the prompt was decreased for that step down to an independent Baseline A five-point Likert-type scale was used for each statement, and optional open-ended follow-up prompts appropriate to each statement (e.g., “Why or why not? or “Please explain’) were posed. To ensure a uniform understanding of the ques- tions, surveys were performed orally by experts; visual aids were provided for response anchor points, with responses from “strongly disagree” scored at —2 to “strongly agree” scored at +2. The preassessment survey consists of 18 state- ments divided into eight categories. The postassessment sur- vey consists of 30 statements in 14 categories. There are two to three statements in each category, and a summative analysis was applied. This study found mixed enthusiasm before instruction by an IRI and positive opinions of the overall experience and performance of the IRI after instruction. In Table 4, we see categories from the preinstruction and postinstruction Likert-type survey results. The initial results of the assessment of students’ opinions prior to working with a robot instructor showed mixed enthusiasm for the experi- ence; however, postinstruction results show a positive opinion of the overall experience and performance of the robot. Com- pared with the students’ lower levels of willingness to work Intervention —— Skill 1 | — Skill 2) Student 1 le ele cleat eels elias iets ies Cetin ieeieatin Dell Student 2 prompt (e.g., “Try it yourself”). This 30 | was repeated with one fewer piece in 80 - the puzzle until the student was finally 70° asked to assemble the puzzle him or 60° ' herself from scratch. 0 | It is worth noting that, in the 30. : results shown in the last row of Table 3, 20. : all errors that occurred in the complex assembly subskill involved assembling 0) ae r the “ball” hexagon-shaped object [Fig- 90 ure 9(c)], which has many possible “| hexagon-shaped but incorrect sub- © 60. compositions; students had no diffi- 8 50 culty assembling the other figures in 40 this subskill. 20 ; ; 20° In light of these observations, we 10. believe that the SMP and backward- 0 . ; ; 100 » chaining approach, while very time-con- 90 - suming and perhaps tedious and more 80. mistake-prone for a human instructor, is OO | a perfect match for the tirelessness and 50 . precision of an IRI. Additionally, this 40 high degree of repetition can greatly 50 | benefit students with I/DDs. 10 4 Subjective Acceptability To determine the students’ opinions on being instructed by a robot, an accept- ability study using a Likert-type scale was conducted before and after the students’ successful instruction with the IRI as part of the making change experiment. 123456789 \ Student 3 1011 121314151617 18 1920 21 22 23 2425 26 Trial THLLEEELL Figure 12. The results from the IRI-instructed making change experiment using a multiple baseline across participants. Data are collected in two phases, shown separated by dashed lines: baseline, measuring each participant's performance prior to instruction; and intervention, where students performed the task with instruction as needed. The skill was divided into two subskills: 1) identifying the correct amount of change and 2) providing the correct combination of coins. The scoring methodology is detailed in [15]. Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 ETO ffom IEEERGHEFES RASHHAHOASABONHAZINE ° 89 3} B]qwiasse 0} payse si JUaPN}s ay} [UN SaseasU! Sda}s JUapUadapu! 9109 ajqissod jo JaquuNU au} ‘poyjyeW BUIUIeYd-pseMmyeq pUe IVS ay} 8ulsn UBM ‘asnedaq ‘sJOMa S}Uasaidal Ajjesauas aouewwopiad 8ulseasUIUON “(6 2JNBI4 Bas) |]bjs Jad sajzznd aauy} YUM ‘JYBNe} aJaM S|INJS Bd} ‘Alay ‘s}NsaJ |jPys Ajquuasse Dj}aW0AB JY] AYL (2) :Z pue | SJUapNys “E] unBi4 co lo Oc 6| StL Zi OF GL VL EL Ch LE OL UIUOSB8Y O}@WOS4) junoooy JUspPNIS (q) 6 8 £49 G %U € 6 ‘s}dwiojd UMO J19U4} [01}U0D Ady} aJayM ‘aseyd yUapUadapu! Ue Aq pamojjo} ‘Ajpayiad |[pjs ay} WUOpad ysnwW Adu} aJaym ‘auljaseg Jaye aseyd UO NJJsUI UP UDAIS ale SJUDPNJS ‘S}]NSaJ |[PJS SuUlUOSedJ DJ@WOS3 pue ‘JUNODIe JUapN}s ‘auIyDeW Adod JYY aUL (q) ‘AjJUaPUddapuU! ain asNUA | r eaulyoe| Adoy | -#——e e—__e_e_e_e'¥ ¥' juapuedepu] -e- UOONsU] —-~ oulleseg — co lo Oc 6I SIL ZI OL GL VIL EL CL tL OL 6 8 2Z9QMIGFp Ee g@ t ‘Buluoseey oujewoey s—“—s—s—s— sua ' ‘yunosoyjuapnig i i ss——CS ! ee ee ee ee a a 7 a asuiusew Adopt t—COCCC a JUepuedepu| -e- UOHONJsuU] -—- ouljeseg —= eof ojojogolososojoxjoke ODOTN OCODOOTA rT rT yOSIIOD JUSIISd eZoxoxcoke) oorn OOl ODOODOO90 O00 0 OOTN ODOTN rT <) © © — eZoxoxcoke) oorn OOl d JyOSIIOD USI C L @—_—_ | Alquiassy : 4—_———_ edeyus-A 1 SOSNOH OM| -= Ajpoing -e | 4 _ Kiy@WWAS Vv L C | *» 5 a } plozedei| —- - uobexdy = DUOWPIG -+- ° ¥ ' UONUSAJOJU| + SUIEaSsSeg [eu 8 € C L a i 901] i | oSnoH == eg - | Z | Aiquiessy @ L adeys-A | i SOSNOH OM| -= . | A\oying --- : Ay@WIWAS © V | C i plozedes) ze | Uuobexdy -= DUOWPIGq -+- a '—yorlsodwoogns- a UONUSAJO]U] SuUljaseg 0 ae) v0 9°0 8°0 L 0 ae) v0 9°0 8°0 L 0 c 0 v0 9°0 8°0 L 0 co 0 v0 9°0 8°0 L 0 c 0 v0 9°0 8°0 L 0 c 0 v0 9°0 8°0 L }098104D JUBpUsdepy| }0811045 JUBpUadepU| Z juapnis L USPNIS Authori9@d ficéiseePaSe tired te MONDE RSA DEL'ROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. with a robot before instruction, the students showed WN — _ Cb) — greater willingness to work with the IRI again. They 0] = oN 5 5% “1: = =3 £) N @ Ow also trusted the robot, were willing to obey the is 9 co = > « ° . . 4 4 |W cD) = robots instructions, and found the experience posi- = < G So == E tive overall. Perhaps unsurprisingly, student 3, who a 5 =e Sos . . “Ty (essa ema ee eas pss (<D) had the most difficulty, also gave the experience the 6! By 2 = = c = = . | 1 2 lowest scores for how easy it was to learn and how | \) gs OLE . . 0) 0 & much she trusted the robot. Regarding the mixed = 6 evs ; > a ratings of the usefulness of the robot's gestures, one EE © E SD possible explanation for the lower ratings of stu- a | Lo 5 5 G dents 1 and 3 is that, despite giving very positive < |e iF . coe = > Le ok in li cow feedback overall, student 1's higher affinity meant ¢ [ ~ Gws . 5 ' ' (a) ~ Oo she had little need for the IRI’s gestures, whereas S iI 1! ia Sea 6 | paencannnta-—- +-! student 3 felt more frustrated by the longer time to 3 \y a =. 23. ; =) tt a on LY acquire the skill, as reflected in her score on the ease = Ht Jc = 20% of learning question and as discussed previously. = i a |° Oro In open-ended responses, students highlighted L i. le Soa the benefits they perceived in working with the IRIs, < t it BS 5 5 5 5 ee TAY ag t + ©€ ‘_ including improved pace, patient repetition, and D it 09 ¥ i, © ‘i bh Vos relieving the burden on human teachers. a itt = £9 os os s EO el ele ee Ai Oo v © Efficiency of Self-Directed AR Instruction | | 1 10 avec ic |] i n= It is likely that the self-directed nature of the AR [ _ xc 6 Ep instruction system is responsible for the rapid learn- : 552 struction system is responsible for the rapid lea | oo 255 ing in the AR experiments. We found that providing y o 3 the participants with the ability to control their own SES prompts, combined with the intelligent AR environ- = oH ment, likely contributed to increased engagement SOTN SHGSTA SHOTA 2S and efficiency in learning the tasks. In this way, JOBHOD JUSWEd weg because students were able to take control of their “ a = own learning experience, they were able to learn S ® o bo: oS va) more efficiently. A genuine level of satisfaction with 5 5 ° = 5 a. 5 ase o . a = fe) the experience on the part of the students was = s a. 2 2G = 3 ® FES . . = pe =) I = observed, which could also be attributed to the effi- _ |ALe OF >) ea [2TFl o oe . — > ae + t net ety £YeEs ciency of the experience. “se565 ' O_-~ FE & Challenge Areas /\~ a Te OS / \ = aS) = Based on open-ended responses, student perfor- NI I SECs ; ; o % oO mance, and experimenter observations, several areas fe Sexo that are challenging for designing an intelligent FeoL instruction system were also identified. We believe F730 ; ; ’ nN -¢ea the following lessons-learned observations would be c bal E S 6 = informative toward future work in this area: = \ o S 2g e Prompt design is a critical determining factor in > y- 25 oe ; ; , a) ea successful instruction. Intrusiveness, verbiage, i= = o ce and interaction modalities should be designed © os ES , , © lauieherwiiase ae ee kody, with a domain expert. rales evan ; ; ; ; ; Q = ° e Incorporating multiple levels of interaction detail g 2 Try ete 3 ; - ; L plecdenb aba. F & increases efficiency and trust. Different modes of =I ea = = ze a Nay) Oo interaction, e.g., controlling verbosity in repeti- 8 = eC TE nN 3S = = tive interactions, can decrease cognitive load and Pi A 2 | = $ ay negate the appearance of a lack of intelligence, -ootn ow coo + ae -DOtTNO Uess : : - dr = thereby increasing trust. ooo ooo ooo "S5L Sa . JOeu09 Juepuedepyl| fou. e Accurate perception is critical. Vision and speech =o c= we . € }UspNIS V9FRo recognition errors that result in incorrect feed- S598 back from the instructor could be harmful to the zoea Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 ETO ffom IEEERGHEFES RASHHAHOAS AB ONHAZINE ° 91 | ° for a human teacher. However, this Table 3. The experiment results: total errors. necessary step can be difficult for an IRI; failure in this area can result in loss of trust in the IRI’s abilities Total Errors Experiment Student 1 Student 2 Student 3 , a (reported in an open-ended survey Copy machine 0 0 5 response by one student with whom Student account 3 9 : our IRI initially had difficulty engag- Geometric reasoning 4 L 2 ing) as well as missing an instruction. Making Calculator 9 9 6 change Coin response 9 6 14 Limitations of This Work Subcomposition 0 0 2 The primary limitations of this work can occembly. Symmetry § ~—O 3 4 be grouped into issues surrounding the Complex assembly 2 4 11 study population (size, variability, and experience) and the design decisions nec- essary (prompts, interaction modalities, —_—_— CCS 2 and verbiage) to create an IRI. Regarding the first, the population size for this article is not statistical. As noted in the “Experiments” section, this study uses single-subject experimental design meth- Table 4. The acceptance survey summative results. Student 1 Student 2 Student 3 Category (Preinstruction) Do you like computers in general? 2 1 @) ods instead of statistical methods for large Do you like robots? 1 2 0 groups because of the small, diverse pop- Have you been exposed to robots before? -0.33 0.67 = ulation involved. In this methodology, Are robots useful? 15 15 05 three replications are sufficient to estab- Would you learn from a robot? _05 1 ; lish a causal relationship. Although a How comfortable are you with the skill? 2 1.5 0) large-population-sized study is infeasible, How well do you think you perform the skill? 2 0.5 0.5 additional replications would help strengthen understanding of this relation- Category (Postinstruction) ship. Furthermore, the variability of the Was the robot good or bad overall? 1.5 1.5 1.5 population of persons with I/DDs is large. Do you view the robot as an embodied intelligence? 0.75 1.25 0.75 Consequently, future studies should be Did the robot seem to understand your actions? 0 1 1 performed with the understanding that Was the robot knowledgeable? 15 1 5 this variability could impact the rate of Did you trust the robot's instructions? 1.5 1.5 0.5 successful learning. The PSE p rogram ; a , (see the “Student Participant Population Did you follow the robot's instructions? 2 I 1.5 ; ; ; ; section) from which this study's drew par- Was the robot easy to learn from? 2 I -0.5 . , hnol ; 5 5 1 05 ticipants is exposed to technology as part NEEM Relea sen els of the program; this exposure could have Were the gestures the robot made useful? —0.33 1.6 —0.67 influenced performance. How comfortable are you with the skill? 0) I I Regarding the design decisions, as How well do you perform the skill? 0 | 1.5 noted in the “Challenge Areas” section, Do you feel like the robot did a good job? 1.5 1 1.5 an IRI is a complex system. The research- Would you work with the robot again? 2 1.5 2 ers learned early on that even small changes, e.g., in verbiage, can signifi- cantly impact interaction. This is par- student's education and must be minimized. Because of _ ticularly true for the population studied. Our work sought variability in speech recognition performance, for example, to achieve a good-performing design through collabora- we chose to minimize the students’ verbal interaction with tion with experts in the education field. In addition to the robot and encourage interact primarily via objects. being based on such collaborative work, future studies Robust multimodal perception of student behavior is an should seek to define and categorize the types of design open challenge. decisions that could affect study outcomes. e Securing the attention of the student and detecting idle states are essential for intelligent interaction. Determining Conclusion when a student is or is not paying attention and when he _In this article, we described the use of response prompting for or she is idle, either due to uncertainty about the correct cognitive decision making in intelligent instruction, with response or to completion of the response, is a trivial task applications in robotics and AR. We gave an overview of our Authori9éd ficéiseePaSe trite’ te MONDE RSA DEL'ROESARIO. Downloaded on December 12,2023 at 22:20:06 UTC from IEEE Xplore. Restrictions apply. interdisciplinary collaborative efforts in applying this approach to the instruction of students with I/DDs with the long-term goal of empowering this population. We shared the results of studies teaching academic and vocational lessons in life skills, including office vocational, geometric reasoning, and monetary mathematical skills. Our results showed great success using response prompting as part of an overall cognitive framework for intelligent instruction. Although these results are a preliminary attempt to begin addressing some of the issues facing those with I/DDs, we believe they show that this novel approach has merit in many applications. Most importantly, we believe the findings here- in should prove constructive toward future investigations and the development of intelligent instructive technologies, especially those that provide critical assistance to this important population. Acknowledgments We acknowledge the wonderful students, staff, and faculty of the FUTURE PSE program and the College of Education at the University of Tennessee, particularly Prof. Mari Beth Coleman and Prof. David Cihak for technical advice and sup- port for this project. References [1] J. Kennedy, P. Baxter, and T. Belpaeme, “The robot who tried too hard: Social behaviour of a robot tutor can negatively affect child learning; in Proc. Tenth Annu. ACM/IEEE Int. Conf. Human-Robot Interaction, 2015, pp. 67-74. [2] E. Watlington, R. Shockley, P. Guglielmino, and R. Felsher, “The high cost of leaving: An analysis of the cost of teacher turnover,’ J. Educ. Finance, vol. 36, no. 1, pp. 22-37, 2010. [3] T. Wilkin and G. Nwoke, “Career and technical education teacher shortage: A successful model for recruitment and retention, J. STEM Teacher Educ., vol. 48, no. 1, 2011. [4] R. Mckeown, “Teacher education 1992 and 2012 reflecting on 20 years, J. Educ. Sustainable Dev., vol. 6, no. 1, pp. 37-41, Apr. 2012. [5] D. Leyzberg, S. Spaulding, M. Toneva, and B. Scassellati, “The physical presence of a robot tutor increases cognitive learning gains,’ in Proc. Annu. Meeting of the Cognitive Science Society, 2012, pp. 1882-1887. [6] A. Tapus, C. Tapus, and M. Mataric, “The role of physical embodi- ment of a therapist robot for individuals with cognitive impairments, in Proc. IEEE Int. Symp. Robot and Human Interactive Communication (RO-MAN), 2009, pp. 103-107. [7] W. A. Bainbridge, J. Hart, E. S. Kim, and B. Scassellati, “The effect of presence on human-robot interaction,’ in Proc. IEEE Int. Symp. Robot and Human Interactive Communication (RO-MAN), 2008, pp. 701-706. [8] M. Grigal and D. Hart, Think College! Postsecondary Education Options for Students with Intellectual Disabilities. Baltimore, MD: Brookes Publishing Company, 2010. [9] A. Meghdari, M. Alemi, M. Ghazisaedy, A. Taheri, A. Karimian, and M. Zandvakili, “Applying robots as teaching assistant in EFL classes at Iranian middle-schools,’ in Proc. Int. Conf. Education and Modern Educational Technologies (EMET-2013), Venice, Italy, 2013, pp. 67-73. [10] M. Saerbeck, T. Schut, C. Bartneck, and M. D. Janse, “Expressive robots in education: Varying the degree of social supportive behavior of a robotic tutor,’ in Proc. SIGCHI Conf. Human Factors in Computing Systems, 2010, pp. 1613-1622. [11] I. M. Verner, A. Polishuk, and N. Krayner, “Science class with robothespian: Using a robot teacher to make science fun and engage students, IEEE Robot. Automat. Mag., vol. 23, no. 2, pp. 74-80, June 2016. [12] M. Fridin, “Storytelling by a kindergarten social assistive robot: A tool for constructive learning in preschool education, Comput. Educ., vol. 70, pp. 53-64, Jan. 2014. [13] K. R. Liles and J. M. Beer, “Rural minority students’ perceptions of Ms. An, the robot teaching assistant, as a social teaching tool,’ in Proc. Human Factors and Ergonomics Society Annu. Meeting, 2015, pp. 372-376. [14] K. R. Liles, D. G. Bryant, and J. M. Beer, “How can social robots motivate students to practice math?” in Proc. Companion of the 2017 ACM/IEEE Int. Conf. Human-Robot Interaction, 2017, pp. 353-354. [15] C. Reardon, H. Zhang, R. Wright, and L. E. Parker, “Response prompting for intelligent robot instruction of students with intellectu- al disabilities, in Proc. IEEE Int. Symp. Robot and Human Interactive Communication (RO-MAN), 2015, pp. 784-790. [16] C. Reardon, R. Wright, D. Cihak, and L. E. Parker, “Intelligent con- text-aware augmented reality to teach students with intellectual and developmental disabilities,” in Proc. Int. Florida Artificial Intelligence Research Society Conf. (FLAIRS), 2016, pp. 505-509. [17] M. Wolery, M. Ault, and P. Doyle, Teaching Students with Moderate to Severe Disabilities: Use of Response Prompting Strategies. White Plains, NY: Longman, 1992. [18] D. Isla, R. Burke, M. Downie, and B. Blumberg, “A layered brain architecture for synthetic creatures, in Proc. Int. Joint Conf. Artificial Intelligence, 2001, pp. 1051-1058. [19] J. Greczek, E. Kaszubski, A. Atrash, and M. Mataric, “Graded cue- ing feedback in robot-mediated imitation practice for children with autism spectrum disorders, in IEEE Int. Symp. Robot and Human Interactive Communication (RO-MAN), 2014, pp. 561-566. [20] D. L. Gast and A. D. Spriggs, “Visual analysis of graphic data,’ Sin- gle Subject Research Methodology in Behavioral Sciences, D. L. Gast, Ed. New York: Routledge, pp. 199-233. [21] R. H. Horner, E. G. Carr, J. Halle, G. McGee, S. Odom, and M. Wol- ery, “The use of single-subject research to identify evidence-based practice in special education, Exceptional Children, vol. 71, no. 2, pp. 165-179, Jan. 2005. Christopher Reardon, U.S. Army Research Laboratory, Adelphi, Maryland. E-mail: christopher.m.reardon3.civ@mail.mil. Hao Zhang, Department of Computer Science, Colorado School of Mines, Golden. E-mail: hzhang@mines.edu. Rachel Wright, Common Threads Resource Center, Madison, Wisconsin. E-mail: rachelw@commonthreadsmadison.org. Lynne E. Parker, Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville. E-mail: leparker@utk.edu. _ Qh Authorized licensed use limited to: UNIVERSIDAD DEL ROSARIO. Downloaded on December 12,2023 at 22:20:06 UET29 tfom IFEER IFES RASHHAHOAS AD ANEAZINE ° 93 